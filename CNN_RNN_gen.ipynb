{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing the libraries"
      ],
      "metadata": {
        "id": "7dCJM6-ZAfK6"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G99Fhu2GAG3k",
        "outputId": "e3a37452-a724-4edd-8751-2830cb083c5c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.9.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize train and test dataset\n"
      ],
      "metadata": {
        "id": "KZK4jInJAnEh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targetdata =#data that we want to predict\n",
        "dim_targetdata = #number of values that need to be predicted per input point\n",
        "grids = #input igures\n",
        "dimgrids = #dimensionality of the grids\n",
        "train_size = #number of datapoints in the train dataset\n",
        "test_size = #number of datapoints in the test dataset\n",
        "num_feature_maps = #number of feature maps in the convolutional layer\n",
        "kernel_size = #dimension of the kernel (kernel_size x kernel_size)\n",
        "dense_layer_size = #number of units for the dense layer "
      ],
      "metadata": {
        "id": "VK7q_9PmAzP4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexen = range(len(targetdata))\n",
        "X_trainges, X_testges, indexen_trainges_final, indexen_testges_final = train_test_split(grids, indexen, train_size=train_size, test_size=test_size, random_state=333)\n",
        "training_yges = targetdata[indexen_trainges_final]\n",
        "y_testges = targetdata[indexen_testges_final]"
      ],
      "metadata": {
        "id": "c28u5rF6A1CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X1 = np.array(X_trainges).reshape(len(X_trainges), dimgrids,dimgrids,1)\n",
        "Y = np.array(training_yges).reshape(len(training_yges),1, dim_targetdata) \n",
        "#note that it is better to standardize the target data"
      ],
      "metadata": {
        "id": "HCgFo6DwA3Di"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Making the model"
      ],
      "metadata": {
        "id": "PzSMeyRtBLlB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_input = keras.Input(shape=(dimgrids,dimgrids,1))\n",
        "convlaag = Conv2D(num_feature_maps,kernel_size=kernel_size,activation='relu',input_shape=(dimgrids, dimgrids, 1))(params_input)\n",
        "poollaag = MaxPooling2D(2, 2)(convlaag)\n",
        "flatlaag = Flatten()(poollaag)\n",
        "denselaag = Dense(dense_layer_size, activation='relu')(flatlaag)\n",
        "reshlaag = tf.keras.layers.Reshape((1,dense_layer_size), input_shape=(dense_layer_size,))(denselaag)\n",
        "inputGRUlist = []\n",
        "for ii in range(dim_targetdata):\n",
        "  inputGRUlist.append(reshlaag)\n",
        "inputGRU = tf.keras.layers.concatenate(inputGRUlist,axis=1)\n",
        "naRNN = (tf.keras.layers.GRU(1,input_shape=(dim_targetdata,dense_layer_size),return_sequences=True))(inputGRU)\n",
        "\n",
        "model = keras.Model(inputs=params_input,outputs=naRNN)\n",
        "model.compile(optimizer=\"adam\", loss=\"mse\", metrics=[\"accuracy\"])\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "UcYxzpBdBbvR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#training the model\n",
        "hists = model.fit(X1, Y, epochs=100,validation_split=0.2,batch_size=32)"
      ],
      "metadata": {
        "id": "YBm4d-pCFdUb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}