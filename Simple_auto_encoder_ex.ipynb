{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import the libraries that are needed"
      ],
      "metadata": {
        "id": "JBZSddz9_52K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Nkx4nW18xGp",
        "outputId": "446db97b-e18e-40de-a877-6dbe507c6b8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.9.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize train and test dataset"
      ],
      "metadata": {
        "id": "Jx6WYDzh_-uQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targetdata = np.loadtxt('verschilgeschaald.csv',dtype=float,delimiter=',') #data that we want to predict\n",
        "dim_targetdata = 99 #number of values that need to be predicted per input point\n",
        "modinfo = np.loadtxt('modinfo.csv',dtype=float,delimiter=',') #input data for the model\n",
        "dim_modinfo = 4 #number of input parameters per input point\n",
        "train_size = 6300 #number of datapoints in the train dataset\n",
        "test_size = 1000 #number of datapoints in the test dataset\n",
        "dim_latent_space = 5 #dimension of the latent space representation"
      ],
      "metadata": {
        "id": "QfkzvtwFAHeD"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "indexen = range(len(targetdata))\n",
        "\n",
        "#X_trainges, X_testges, training_yges, y_testges = train_test_split(modinfo, verschilgeschaald, train_size=2500, test_size=2400, random_state=333)\n",
        "verschilgeschaald_train, verschilgeschaald_test, indexen_trainges, indexen_testges = train_test_split(targetdata, indexen, train_size=train_size, test_size=test_size, random_state=333)\n"
      ],
      "metadata": {
        "id": "8G_5NjJo__3_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Creating the encoder-decoder"
      ],
      "metadata": {
        "id": "muarWVKxA7bl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(verschilgeschaald_train).reshape(len(verschilgeschaald_train), dim_targetdata)\n",
        "\n",
        "params_input = keras.Input(shape=(dim_targetdata)) #creating the input layer\n",
        "encoder = tf.keras.layers.Dense(dim_latent_space)(params_input) \n",
        "decoder = tf.keras.layers.Dense(dim_targetdata)(encoder)\n",
        "\n",
        "model = keras.Model(inputs=params_input,outputs=decoder)\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.summary()\n",
        "hist = model.fit(X,X,epochs=1000,validation_split=0.2,batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vKl_8jKmA9n7",
        "outputId": "2da595ea-7068-42f7-fcd2-3271dd3a33d6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 99)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 500       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 99)                594       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,094\n",
            "Trainable params: 1,094\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 7.1105 - val_loss: 0.0410\n",
            "Epoch 2/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 6.7822 - val_loss: 0.0409\n",
            "Epoch 3/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 6.4811 - val_loss: 0.0412\n",
            "Epoch 4/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 6.2572 - val_loss: 0.0411\n",
            "Epoch 5/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 6.0760 - val_loss: 0.0408\n",
            "Epoch 6/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 5.8856 - val_loss: 0.0401\n",
            "Epoch 7/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 5.6552 - val_loss: 0.0393\n",
            "Epoch 8/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 5.3394 - val_loss: 0.0382\n",
            "Epoch 9/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 4.9268 - val_loss: 0.0385\n",
            "Epoch 10/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 4.4418 - val_loss: 0.0389\n",
            "Epoch 11/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 3.9512 - val_loss: 0.0416\n",
            "Epoch 12/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 3.5184 - val_loss: 0.0442\n",
            "Epoch 13/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 3.1307 - val_loss: 0.0456\n",
            "Epoch 14/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 2.7964 - val_loss: 0.0489\n",
            "Epoch 15/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 2.5019 - val_loss: 0.0469\n",
            "Epoch 16/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 2.2236 - val_loss: 0.0504\n",
            "Epoch 17/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 1.9285 - val_loss: 0.0534\n",
            "Epoch 18/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 1.6957 - val_loss: 0.0542\n",
            "Epoch 19/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 1.5031 - val_loss: 0.0551\n",
            "Epoch 20/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 1.3241 - val_loss: 0.0566\n",
            "Epoch 21/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 1.1759 - val_loss: 0.0558\n",
            "Epoch 22/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 1.0435 - val_loss: 0.0569\n",
            "Epoch 23/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.8652 - val_loss: 0.0579\n",
            "Epoch 24/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.7216 - val_loss: 0.0587\n",
            "Epoch 25/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.6025 - val_loss: 0.0572\n",
            "Epoch 26/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.5238 - val_loss: 0.0565\n",
            "Epoch 27/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.4557 - val_loss: 0.0604\n",
            "Epoch 28/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.4133 - val_loss: 0.0605\n",
            "Epoch 29/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.3509 - val_loss: 0.0600\n",
            "Epoch 30/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.3054 - val_loss: 0.0591\n",
            "Epoch 31/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.2462 - val_loss: 0.0596\n",
            "Epoch 32/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.2273 - val_loss: 0.0583\n",
            "Epoch 33/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.1909 - val_loss: 0.0561\n",
            "Epoch 34/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1065 - val_loss: 0.0567\n",
            "Epoch 35/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0567 - val_loss: 0.0557\n",
            "Epoch 36/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0606 - val_loss: 0.0554\n",
            "Epoch 37/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0804 - val_loss: 0.0553\n",
            "Epoch 38/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1401 - val_loss: 0.0563\n",
            "Epoch 39/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.3144 - val_loss: 0.0572\n",
            "Epoch 40/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.5172 - val_loss: 0.0528\n",
            "Epoch 41/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.3667 - val_loss: 0.0517\n",
            "Epoch 42/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.2158 - val_loss: 0.0496\n",
            "Epoch 43/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1308 - val_loss: 0.0499\n",
            "Epoch 44/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1034 - val_loss: 0.0485\n",
            "Epoch 45/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0484\n",
            "Epoch 46/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0729 - val_loss: 0.0477\n",
            "Epoch 47/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0746 - val_loss: 0.0476\n",
            "Epoch 48/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0963 - val_loss: 0.0476\n",
            "Epoch 49/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1637 - val_loss: 0.0470\n",
            "Epoch 50/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.2524 - val_loss: 0.0475\n",
            "Epoch 51/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.2836 - val_loss: 0.0456\n",
            "Epoch 52/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.2392 - val_loss: 0.0463\n",
            "Epoch 53/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.2062 - val_loss: 0.0435\n",
            "Epoch 54/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1814 - val_loss: 0.0448\n",
            "Epoch 55/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1457 - val_loss: 0.0429\n",
            "Epoch 56/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1404 - val_loss: 0.0441\n",
            "Epoch 57/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1362 - val_loss: 0.0428\n",
            "Epoch 58/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1534 - val_loss: 0.0428\n",
            "Epoch 59/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1414 - val_loss: 0.0428\n",
            "Epoch 60/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1620 - val_loss: 0.0420\n",
            "Epoch 61/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1458 - val_loss: 0.0422\n",
            "Epoch 62/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1529 - val_loss: 0.0416\n",
            "Epoch 63/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1507 - val_loss: 0.0420\n",
            "Epoch 64/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1949 - val_loss: 0.0411\n",
            "Epoch 65/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1735 - val_loss: 0.0400\n",
            "Epoch 66/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1653 - val_loss: 0.0412\n",
            "Epoch 67/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1415 - val_loss: 0.0393\n",
            "Epoch 68/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1453 - val_loss: 0.0405\n",
            "Epoch 69/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1268 - val_loss: 0.0387\n",
            "Epoch 70/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1420 - val_loss: 0.0397\n",
            "Epoch 71/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1312 - val_loss: 0.0380\n",
            "Epoch 72/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1686 - val_loss: 0.0393\n",
            "Epoch 73/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1679 - val_loss: 0.0375\n",
            "Epoch 74/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1853 - val_loss: 0.0381\n",
            "Epoch 75/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1394 - val_loss: 0.0367\n",
            "Epoch 76/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1454 - val_loss: 0.0374\n",
            "Epoch 77/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1274 - val_loss: 0.0362\n",
            "Epoch 78/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1302 - val_loss: 0.0362\n",
            "Epoch 79/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1054 - val_loss: 0.0352\n",
            "Epoch 80/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1070 - val_loss: 0.0352\n",
            "Epoch 81/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0986 - val_loss: 0.0340\n",
            "Epoch 82/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1241 - val_loss: 0.0345\n",
            "Epoch 83/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1392 - val_loss: 0.0340\n",
            "Epoch 84/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1738 - val_loss: 0.0336\n",
            "Epoch 85/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1509 - val_loss: 0.0318\n",
            "Epoch 86/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1671 - val_loss: 0.0322\n",
            "Epoch 87/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1229 - val_loss: 0.0308\n",
            "Epoch 88/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1159 - val_loss: 0.0311\n",
            "Epoch 89/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1050 - val_loss: 0.0291\n",
            "Epoch 90/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1156 - val_loss: 0.0295\n",
            "Epoch 91/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1128 - val_loss: 0.0274\n",
            "Epoch 92/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1095 - val_loss: 0.0279\n",
            "Epoch 93/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0945 - val_loss: 0.0262\n",
            "Epoch 94/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0920 - val_loss: 0.0269\n",
            "Epoch 95/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.0959 - val_loss: 0.0253\n",
            "Epoch 96/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0923 - val_loss: 0.0255\n",
            "Epoch 97/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.1019 - val_loss: 0.0250\n",
            "Epoch 98/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.1285 - val_loss: 0.0248\n",
            "Epoch 99/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1285 - val_loss: 0.0249\n",
            "Epoch 100/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1342 - val_loss: 0.0249\n",
            "Epoch 101/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1146 - val_loss: 0.0239\n",
            "Epoch 102/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0999 - val_loss: 0.0247\n",
            "Epoch 103/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1006 - val_loss: 0.0229\n",
            "Epoch 104/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1105 - val_loss: 0.0244\n",
            "Epoch 105/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1173 - val_loss: 0.0229\n",
            "Epoch 106/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1240 - val_loss: 0.0237\n",
            "Epoch 107/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1101 - val_loss: 0.0235\n",
            "Epoch 108/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1401 - val_loss: 0.0234\n",
            "Epoch 109/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1265 - val_loss: 0.0233\n",
            "Epoch 110/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1212 - val_loss: 0.0231\n",
            "Epoch 111/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0873 - val_loss: 0.0226\n",
            "Epoch 112/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0722 - val_loss: 0.0224\n",
            "Epoch 113/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0625 - val_loss: 0.0218\n",
            "Epoch 114/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0680 - val_loss: 0.0227\n",
            "Epoch 115/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0867 - val_loss: 0.0215\n",
            "Epoch 116/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1107 - val_loss: 0.0226\n",
            "Epoch 117/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1110 - val_loss: 0.0215\n",
            "Epoch 118/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1159 - val_loss: 0.0221\n",
            "Epoch 119/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1054 - val_loss: 0.0216\n",
            "Epoch 120/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1198 - val_loss: 0.0218\n",
            "Epoch 121/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0971 - val_loss: 0.0223\n",
            "Epoch 122/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1060 - val_loss: 0.0219\n",
            "Epoch 123/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0934 - val_loss: 0.0209\n",
            "Epoch 124/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1037 - val_loss: 0.0213\n",
            "Epoch 125/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0866 - val_loss: 0.0210\n",
            "Epoch 126/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0986 - val_loss: 0.0222\n",
            "Epoch 127/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0829 - val_loss: 0.0207\n",
            "Epoch 128/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0202\n",
            "Epoch 129/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0252 - val_loss: 0.0203\n",
            "Epoch 130/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0259 - val_loss: 0.0198\n",
            "Epoch 131/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.0205\n",
            "Epoch 132/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0196\n",
            "Epoch 133/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0772 - val_loss: 0.0216\n",
            "Epoch 134/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1189 - val_loss: 0.0205\n",
            "Epoch 135/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1764 - val_loss: 0.0206\n",
            "Epoch 136/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1832 - val_loss: 0.0215\n",
            "Epoch 137/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1632 - val_loss: 0.0204\n",
            "Epoch 138/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0917 - val_loss: 0.0202\n",
            "Epoch 139/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0932 - val_loss: 0.0194\n",
            "Epoch 140/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0632 - val_loss: 0.0195\n",
            "Epoch 141/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0710 - val_loss: 0.0190\n",
            "Epoch 142/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0635 - val_loss: 0.0188\n",
            "Epoch 143/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0614 - val_loss: 0.0189\n",
            "Epoch 144/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0649 - val_loss: 0.0185\n",
            "Epoch 145/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0711 - val_loss: 0.0186\n",
            "Epoch 146/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0742 - val_loss: 0.0184\n",
            "Epoch 147/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0936 - val_loss: 0.0184\n",
            "Epoch 148/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1058 - val_loss: 0.0196\n",
            "Epoch 149/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1615 - val_loss: 0.0183\n",
            "Epoch 150/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1386 - val_loss: 0.0193\n",
            "Epoch 151/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1127 - val_loss: 0.0175\n",
            "Epoch 152/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0673 - val_loss: 0.0175\n",
            "Epoch 153/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0590 - val_loss: 0.0173\n",
            "Epoch 154/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0169\n",
            "Epoch 155/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0169\n",
            "Epoch 156/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0166\n",
            "Epoch 157/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0165\n",
            "Epoch 158/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0546 - val_loss: 0.0166\n",
            "Epoch 159/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0833 - val_loss: 0.0164\n",
            "Epoch 160/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1049 - val_loss: 0.0200\n",
            "Epoch 161/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.1407 - val_loss: 0.0168\n",
            "Epoch 162/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1076 - val_loss: 0.0159\n",
            "Epoch 163/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1114 - val_loss: 0.0174\n",
            "Epoch 164/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.0153\n",
            "Epoch 165/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0599 - val_loss: 0.0156\n",
            "Epoch 166/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0148\n",
            "Epoch 167/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0148\n",
            "Epoch 168/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0147\n",
            "Epoch 169/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0143\n",
            "Epoch 170/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0767 - val_loss: 0.0158\n",
            "Epoch 171/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0937 - val_loss: 0.0137\n",
            "Epoch 172/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0901 - val_loss: 0.0142\n",
            "Epoch 173/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0700 - val_loss: 0.0148\n",
            "Epoch 174/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0660 - val_loss: 0.0135\n",
            "Epoch 175/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0533 - val_loss: 0.0130\n",
            "Epoch 176/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0662 - val_loss: 0.0135\n",
            "Epoch 177/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0685 - val_loss: 0.0127\n",
            "Epoch 178/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0765 - val_loss: 0.0128\n",
            "Epoch 179/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.0124\n",
            "Epoch 180/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0123\n",
            "Epoch 181/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0660 - val_loss: 0.0131\n",
            "Epoch 182/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0704 - val_loss: 0.0120\n",
            "Epoch 183/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0744 - val_loss: 0.0127\n",
            "Epoch 184/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0750 - val_loss: 0.0119\n",
            "Epoch 185/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0727 - val_loss: 0.0120\n",
            "Epoch 186/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0560 - val_loss: 0.0119\n",
            "Epoch 187/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0476 - val_loss: 0.0115\n",
            "Epoch 188/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0112\n",
            "Epoch 189/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.0110\n",
            "Epoch 190/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0113\n",
            "Epoch 191/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0714 - val_loss: 0.0113\n",
            "Epoch 192/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0897 - val_loss: 0.0112\n",
            "Epoch 193/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0965 - val_loss: 0.0109\n",
            "Epoch 194/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0106\n",
            "Epoch 195/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0534 - val_loss: 0.0105\n",
            "Epoch 196/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0502 - val_loss: 0.0105\n",
            "Epoch 197/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0533 - val_loss: 0.0103\n",
            "Epoch 198/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0621 - val_loss: 0.0109\n",
            "Epoch 199/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.0102\n",
            "Epoch 200/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0205 - val_loss: 0.0106\n",
            "Epoch 201/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.0107\n",
            "Epoch 202/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0604 - val_loss: 0.0120\n",
            "Epoch 203/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0824 - val_loss: 0.0138\n",
            "Epoch 204/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0953 - val_loss: 0.0105\n",
            "Epoch 205/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0100\n",
            "Epoch 206/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0462 - val_loss: 0.0102\n",
            "Epoch 207/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0103\n",
            "Epoch 208/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.0109\n",
            "Epoch 209/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0811 - val_loss: 0.0101\n",
            "Epoch 210/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0793 - val_loss: 0.0108\n",
            "Epoch 211/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0730 - val_loss: 0.0102\n",
            "Epoch 212/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0301 - val_loss: 0.0100\n",
            "Epoch 213/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0099\n",
            "Epoch 214/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0149 - val_loss: 0.0098\n",
            "Epoch 215/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0224 - val_loss: 0.0101\n",
            "Epoch 216/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0333 - val_loss: 0.0102\n",
            "Epoch 217/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0124\n",
            "Epoch 218/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0855 - val_loss: 0.0106\n",
            "Epoch 219/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0799 - val_loss: 0.0100\n",
            "Epoch 220/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0840 - val_loss: 0.0118\n",
            "Epoch 221/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0605 - val_loss: 0.0101\n",
            "Epoch 222/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0645 - val_loss: 0.0098\n",
            "Epoch 223/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0694 - val_loss: 0.0115\n",
            "Epoch 224/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0617 - val_loss: 0.0104\n",
            "Epoch 225/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0420 - val_loss: 0.0107\n",
            "Epoch 226/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0358 - val_loss: 0.0105\n",
            "Epoch 227/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0102\n",
            "Epoch 228/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.0100\n",
            "Epoch 229/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0386 - val_loss: 0.0100\n",
            "Epoch 230/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0522 - val_loss: 0.0124\n",
            "Epoch 231/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0618 - val_loss: 0.0100\n",
            "Epoch 232/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0772 - val_loss: 0.0116\n",
            "Epoch 233/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0607 - val_loss: 0.0105\n",
            "Epoch 234/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0528 - val_loss: 0.0103\n",
            "Epoch 235/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0095\n",
            "Epoch 236/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0102\n",
            "Epoch 237/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.0101\n",
            "Epoch 238/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0543 - val_loss: 0.0106\n",
            "Epoch 239/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0526 - val_loss: 0.0099\n",
            "Epoch 240/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0594 - val_loss: 0.0107\n",
            "Epoch 241/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0107\n",
            "Epoch 242/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0553 - val_loss: 0.0097\n",
            "Epoch 243/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0530 - val_loss: 0.0100\n",
            "Epoch 244/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0552 - val_loss: 0.0125\n",
            "Epoch 245/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0595 - val_loss: 0.0103\n",
            "Epoch 246/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0100\n",
            "Epoch 247/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0515 - val_loss: 0.0103\n",
            "Epoch 248/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0100\n",
            "Epoch 249/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0483 - val_loss: 0.0105\n",
            "Epoch 250/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0102\n",
            "Epoch 251/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0389 - val_loss: 0.0104\n",
            "Epoch 252/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0358 - val_loss: 0.0098\n",
            "Epoch 253/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0108\n",
            "Epoch 254/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0564 - val_loss: 0.0105\n",
            "Epoch 255/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0669 - val_loss: 0.0105\n",
            "Epoch 256/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0504 - val_loss: 0.0130\n",
            "Epoch 257/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0101\n",
            "Epoch 258/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0099\n",
            "Epoch 259/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0113\n",
            "Epoch 260/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0353 - val_loss: 0.0096\n",
            "Epoch 261/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0100\n",
            "Epoch 262/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0374 - val_loss: 0.0095\n",
            "Epoch 263/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.0112\n",
            "Epoch 264/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0676 - val_loss: 0.0109\n",
            "Epoch 265/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0567 - val_loss: 0.0096\n",
            "Epoch 266/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0597 - val_loss: 0.0133\n",
            "Epoch 267/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0531 - val_loss: 0.0101\n",
            "Epoch 268/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0548 - val_loss: 0.0099\n",
            "Epoch 269/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0563 - val_loss: 0.0110\n",
            "Epoch 270/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0531 - val_loss: 0.0106\n",
            "Epoch 271/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0098\n",
            "Epoch 272/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0212 - val_loss: 0.0105\n",
            "Epoch 273/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0352 - val_loss: 0.0099\n",
            "Epoch 274/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0626 - val_loss: 0.0103\n",
            "Epoch 275/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0534 - val_loss: 0.0101\n",
            "Epoch 276/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0640 - val_loss: 0.0103\n",
            "Epoch 277/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0390 - val_loss: 0.0096\n",
            "Epoch 278/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0099\n",
            "Epoch 279/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0349 - val_loss: 0.0105\n",
            "Epoch 280/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0437 - val_loss: 0.0099\n",
            "Epoch 281/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.0107\n",
            "Epoch 282/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0394 - val_loss: 0.0097\n",
            "Epoch 283/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0379 - val_loss: 0.0096\n",
            "Epoch 284/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0455 - val_loss: 0.0105\n",
            "Epoch 285/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0095\n",
            "Epoch 286/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0104\n",
            "Epoch 287/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0469 - val_loss: 0.0093\n",
            "Epoch 288/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0096\n",
            "Epoch 289/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0109\n",
            "Epoch 290/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0095\n",
            "Epoch 291/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0104\n",
            "Epoch 292/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0092\n",
            "Epoch 293/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.0093\n",
            "Epoch 294/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0116\n",
            "Epoch 295/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0569 - val_loss: 0.0098\n",
            "Epoch 296/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0670 - val_loss: 0.0107\n",
            "Epoch 297/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0817 - val_loss: 0.0103\n",
            "Epoch 298/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0864 - val_loss: 0.0112\n",
            "Epoch 299/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0096\n",
            "Epoch 300/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0092\n",
            "Epoch 301/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0091\n",
            "Epoch 302/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0090\n",
            "Epoch 303/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0090\n",
            "Epoch 304/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0098\n",
            "Epoch 305/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0464 - val_loss: 0.0092\n",
            "Epoch 306/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0548 - val_loss: 0.0094\n",
            "Epoch 307/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0439 - val_loss: 0.0103\n",
            "Epoch 308/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0092\n",
            "Epoch 309/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0115 - val_loss: 0.0091\n",
            "Epoch 310/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0169 - val_loss: 0.0090\n",
            "Epoch 311/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0124\n",
            "Epoch 312/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.0102\n",
            "Epoch 313/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0661 - val_loss: 0.0103\n",
            "Epoch 314/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0801 - val_loss: 0.0114\n",
            "Epoch 315/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0109\n",
            "Epoch 316/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0676 - val_loss: 0.0153\n",
            "Epoch 317/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0487 - val_loss: 0.0103\n",
            "Epoch 318/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0095\n",
            "Epoch 319/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0156 - val_loss: 0.0089\n",
            "Epoch 320/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0213 - val_loss: 0.0091\n",
            "Epoch 321/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0248 - val_loss: 0.0088\n",
            "Epoch 322/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0107\n",
            "Epoch 323/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0394 - val_loss: 0.0107\n",
            "Epoch 324/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0133\n",
            "Epoch 325/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0496 - val_loss: 0.0088\n",
            "Epoch 326/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0654 - val_loss: 0.0093\n",
            "Epoch 327/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0554 - val_loss: 0.0093\n",
            "Epoch 328/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0645 - val_loss: 0.0101\n",
            "Epoch 329/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0432 - val_loss: 0.0094\n",
            "Epoch 330/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0449 - val_loss: 0.0089\n",
            "Epoch 331/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0088\n",
            "Epoch 332/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0089\n",
            "Epoch 333/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0086\n",
            "Epoch 334/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0345 - val_loss: 0.0092\n",
            "Epoch 335/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0386 - val_loss: 0.0086\n",
            "Epoch 336/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0095\n",
            "Epoch 337/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0513 - val_loss: 0.0101\n",
            "Epoch 338/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0721 - val_loss: 0.0095\n",
            "Epoch 339/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.0087\n",
            "Epoch 340/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0091\n",
            "Epoch 341/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0326 - val_loss: 0.0089\n",
            "Epoch 342/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0397 - val_loss: 0.0096\n",
            "Epoch 343/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0371 - val_loss: 0.0090\n",
            "Epoch 344/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0460 - val_loss: 0.0106\n",
            "Epoch 345/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0490 - val_loss: 0.0113\n",
            "Epoch 346/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0472 - val_loss: 0.0101\n",
            "Epoch 347/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0459 - val_loss: 0.0097\n",
            "Epoch 348/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0586 - val_loss: 0.0112\n",
            "Epoch 349/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0362 - val_loss: 0.0097\n",
            "Epoch 350/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.0096\n",
            "Epoch 351/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0353 - val_loss: 0.0096\n",
            "Epoch 352/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0378 - val_loss: 0.0085\n",
            "Epoch 353/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0095\n",
            "Epoch 354/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0087\n",
            "Epoch 355/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0372 - val_loss: 0.0089\n",
            "Epoch 356/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.0088\n",
            "Epoch 357/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0117\n",
            "Epoch 358/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.0091\n",
            "Epoch 359/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0428 - val_loss: 0.0088\n",
            "Epoch 360/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0378 - val_loss: 0.0086\n",
            "Epoch 361/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0529 - val_loss: 0.0107\n",
            "Epoch 362/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0691 - val_loss: 0.0108\n",
            "Epoch 363/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0962 - val_loss: 0.0115\n",
            "Epoch 364/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0089\n",
            "Epoch 365/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0345 - val_loss: 0.0087\n",
            "Epoch 366/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0087\n",
            "Epoch 367/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0087\n",
            "Epoch 368/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0191 - val_loss: 0.0083\n",
            "Epoch 369/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0083\n",
            "Epoch 370/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0317 - val_loss: 0.0085\n",
            "Epoch 371/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0084\n",
            "Epoch 372/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0436 - val_loss: 0.0082\n",
            "Epoch 373/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0441 - val_loss: 0.0110\n",
            "Epoch 374/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0398 - val_loss: 0.0084\n",
            "Epoch 375/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0317 - val_loss: 0.0080\n",
            "Epoch 376/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0086\n",
            "Epoch 377/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0081\n",
            "Epoch 378/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.0090\n",
            "Epoch 379/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0692 - val_loss: 0.0108\n",
            "Epoch 380/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1091 - val_loss: 0.0084\n",
            "Epoch 381/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0589 - val_loss: 0.0092\n",
            "Epoch 382/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0082\n",
            "Epoch 383/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0248 - val_loss: 0.0100\n",
            "Epoch 384/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0078\n",
            "Epoch 385/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0081\n",
            "Epoch 386/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.0081\n",
            "Epoch 387/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0079\n",
            "Epoch 388/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.0088\n",
            "Epoch 389/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0084\n",
            "Epoch 390/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0080\n",
            "Epoch 391/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0413 - val_loss: 0.0082\n",
            "Epoch 392/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0463 - val_loss: 0.0082\n",
            "Epoch 393/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0403 - val_loss: 0.0083\n",
            "Epoch 394/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0551 - val_loss: 0.0082\n",
            "Epoch 395/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0081\n",
            "Epoch 396/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0102\n",
            "Epoch 397/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0084\n",
            "Epoch 398/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0095\n",
            "Epoch 399/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0079\n",
            "Epoch 400/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0481 - val_loss: 0.0078\n",
            "Epoch 401/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0077\n",
            "Epoch 402/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.0089\n",
            "Epoch 403/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0073\n",
            "Epoch 404/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0326 - val_loss: 0.0079\n",
            "Epoch 405/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0306 - val_loss: 0.0081\n",
            "Epoch 406/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.0100\n",
            "Epoch 407/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0078\n",
            "Epoch 408/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0080\n",
            "Epoch 409/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0444 - val_loss: 0.0084\n",
            "Epoch 410/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.0084\n",
            "Epoch 411/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0499 - val_loss: 0.0080\n",
            "Epoch 412/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0574 - val_loss: 0.0090\n",
            "Epoch 413/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0440 - val_loss: 0.0109\n",
            "Epoch 414/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0508 - val_loss: 0.0075\n",
            "Epoch 415/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0340 - val_loss: 0.0071\n",
            "Epoch 416/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0070\n",
            "Epoch 417/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0087\n",
            "Epoch 418/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.3539 - val_loss: 0.0335\n",
            "Epoch 419/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0872 - val_loss: 0.0123\n",
            "Epoch 420/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0148 - val_loss: 0.0091\n",
            "Epoch 421/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0137 - val_loss: 0.0078\n",
            "Epoch 422/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0105 - val_loss: 0.0072\n",
            "Epoch 423/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0093 - val_loss: 0.0070\n",
            "Epoch 424/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0082 - val_loss: 0.0069\n",
            "Epoch 425/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0083 - val_loss: 0.0069\n",
            "Epoch 426/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0088 - val_loss: 0.0067\n",
            "Epoch 427/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0114 - val_loss: 0.0069\n",
            "Epoch 428/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0151 - val_loss: 0.0073\n",
            "Epoch 429/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0267 - val_loss: 0.0068\n",
            "Epoch 430/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0353 - val_loss: 0.0072\n",
            "Epoch 431/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0610 - val_loss: 0.0072\n",
            "Epoch 432/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0615 - val_loss: 0.0091\n",
            "Epoch 433/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0857 - val_loss: 0.0074\n",
            "Epoch 434/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0468 - val_loss: 0.0068\n",
            "Epoch 435/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0410 - val_loss: 0.0067\n",
            "Epoch 436/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0065\n",
            "Epoch 437/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0067\n",
            "Epoch 438/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 0.0240 - val_loss: 0.0065\n",
            "Epoch 439/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0066\n",
            "Epoch 440/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0319 - val_loss: 0.0089\n",
            "Epoch 441/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0478 - val_loss: 0.0067\n",
            "Epoch 442/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0393 - val_loss: 0.0067\n",
            "Epoch 443/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0573 - val_loss: 0.0067\n",
            "Epoch 444/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0063\n",
            "Epoch 445/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0507 - val_loss: 0.0064\n",
            "Epoch 446/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.0064\n",
            "Epoch 447/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0407 - val_loss: 0.0061\n",
            "Epoch 448/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.1997 - val_loss: 0.0091\n",
            "Epoch 449/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0066\n",
            "Epoch 450/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0118 - val_loss: 0.0070\n",
            "Epoch 451/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0069 - val_loss: 0.0061\n",
            "Epoch 452/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0072 - val_loss: 0.0062\n",
            "Epoch 453/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0080 - val_loss: 0.0061\n",
            "Epoch 454/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0104 - val_loss: 0.0067\n",
            "Epoch 455/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0158 - val_loss: 0.0060\n",
            "Epoch 456/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0196 - val_loss: 0.0059\n",
            "Epoch 457/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0061\n",
            "Epoch 458/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.0061\n",
            "Epoch 459/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0608 - val_loss: 0.0061\n",
            "Epoch 460/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0575 - val_loss: 0.0064\n",
            "Epoch 461/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0679 - val_loss: 0.0060\n",
            "Epoch 462/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0062\n",
            "Epoch 463/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0431 - val_loss: 0.0060\n",
            "Epoch 464/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0060\n",
            "Epoch 465/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0064\n",
            "Epoch 466/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0064\n",
            "Epoch 467/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0337 - val_loss: 0.0060\n",
            "Epoch 468/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0072\n",
            "Epoch 469/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0395 - val_loss: 0.0061\n",
            "Epoch 470/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0060\n",
            "Epoch 471/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0068\n",
            "Epoch 472/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0530 - val_loss: 0.0084\n",
            "Epoch 473/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0672 - val_loss: 0.0090\n",
            "Epoch 474/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0405 - val_loss: 0.0059\n",
            "Epoch 475/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0055\n",
            "Epoch 476/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0058\n",
            "Epoch 477/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0371 - val_loss: 0.0055\n",
            "Epoch 478/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0060\n",
            "Epoch 479/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0350 - val_loss: 0.0056\n",
            "Epoch 480/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0342 - val_loss: 0.0106\n",
            "Epoch 481/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0053\n",
            "Epoch 482/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0351 - val_loss: 0.0056\n",
            "Epoch 483/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0465 - val_loss: 0.0056\n",
            "Epoch 484/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0054\n",
            "Epoch 485/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0098\n",
            "Epoch 486/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0455 - val_loss: 0.0051\n",
            "Epoch 487/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0486 - val_loss: 0.0054\n",
            "Epoch 488/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0369 - val_loss: 0.0051\n",
            "Epoch 489/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0475 - val_loss: 0.0053\n",
            "Epoch 490/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0331 - val_loss: 0.0049\n",
            "Epoch 491/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0334 - val_loss: 0.0051\n",
            "Epoch 492/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0052\n",
            "Epoch 493/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.0052\n",
            "Epoch 494/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0050\n",
            "Epoch 495/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0369 - val_loss: 0.0056\n",
            "Epoch 496/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0420 - val_loss: 0.0075\n",
            "Epoch 497/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0678 - val_loss: 0.0076\n",
            "Epoch 498/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0593 - val_loss: 0.0078\n",
            "Epoch 499/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0549 - val_loss: 0.0070\n",
            "Epoch 500/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0053\n",
            "Epoch 501/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0065\n",
            "Epoch 502/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0240 - val_loss: 0.0048\n",
            "Epoch 503/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0054\n",
            "Epoch 504/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0048\n",
            "Epoch 505/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0056\n",
            "Epoch 506/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0051\n",
            "Epoch 507/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0396 - val_loss: 0.0055\n",
            "Epoch 508/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0059\n",
            "Epoch 509/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0729 - val_loss: 0.0097\n",
            "Epoch 510/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0541 - val_loss: 0.0068\n",
            "Epoch 511/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0544 - val_loss: 0.0062\n",
            "Epoch 512/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0324 - val_loss: 0.0064\n",
            "Epoch 513/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0353 - val_loss: 0.0049\n",
            "Epoch 514/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0070\n",
            "Epoch 515/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0302 - val_loss: 0.0054\n",
            "Epoch 516/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0048\n",
            "Epoch 517/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0046\n",
            "Epoch 518/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0050\n",
            "Epoch 519/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0051\n",
            "Epoch 520/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0476 - val_loss: 0.0064\n",
            "Epoch 521/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0627 - val_loss: 0.0053\n",
            "Epoch 522/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0047\n",
            "Epoch 523/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0448 - val_loss: 0.0082\n",
            "Epoch 524/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0046\n",
            "Epoch 525/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.0051\n",
            "Epoch 526/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0319 - val_loss: 0.0050\n",
            "Epoch 527/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0364 - val_loss: 0.0055\n",
            "Epoch 528/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0073\n",
            "Epoch 529/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0362 - val_loss: 0.0052\n",
            "Epoch 530/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0057\n",
            "Epoch 531/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0474 - val_loss: 0.0050\n",
            "Epoch 532/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0084\n",
            "Epoch 533/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0656 - val_loss: 0.0054\n",
            "Epoch 534/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0083\n",
            "Epoch 535/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0477 - val_loss: 0.0046\n",
            "Epoch 536/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.0052\n",
            "Epoch 537/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0043\n",
            "Epoch 538/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0143 - val_loss: 0.0044\n",
            "Epoch 539/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0044\n",
            "Epoch 540/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0047\n",
            "Epoch 541/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0056\n",
            "Epoch 542/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0049\n",
            "Epoch 543/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0509 - val_loss: 0.0047\n",
            "Epoch 544/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0466 - val_loss: 0.0053\n",
            "Epoch 545/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0650 - val_loss: 0.0057\n",
            "Epoch 546/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0484 - val_loss: 0.0061\n",
            "Epoch 547/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0487 - val_loss: 0.0052\n",
            "Epoch 548/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0050\n",
            "Epoch 549/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0317 - val_loss: 0.0043\n",
            "Epoch 550/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0241 - val_loss: 0.0041\n",
            "Epoch 551/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0358 - val_loss: 0.0072\n",
            "Epoch 552/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0042\n",
            "Epoch 553/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0353 - val_loss: 0.0049\n",
            "Epoch 554/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0363 - val_loss: 0.0046\n",
            "Epoch 555/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0467 - val_loss: 0.0046\n",
            "Epoch 556/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0357 - val_loss: 0.0041\n",
            "Epoch 557/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0395 - val_loss: 0.0048\n",
            "Epoch 558/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0347 - val_loss: 0.0048\n",
            "Epoch 559/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0438 - val_loss: 0.0047\n",
            "Epoch 560/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0358 - val_loss: 0.0097\n",
            "Epoch 561/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0516 - val_loss: 0.0046\n",
            "Epoch 562/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0353 - val_loss: 0.0041\n",
            "Epoch 563/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0374 - val_loss: 0.0040\n",
            "Epoch 564/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0050\n",
            "Epoch 565/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0048\n",
            "Epoch 566/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0061\n",
            "Epoch 567/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0501 - val_loss: 0.0044\n",
            "Epoch 568/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0359 - val_loss: 0.0054\n",
            "Epoch 569/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0527 - val_loss: 0.0047\n",
            "Epoch 570/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0049\n",
            "Epoch 571/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0525 - val_loss: 0.0041\n",
            "Epoch 572/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0327 - val_loss: 0.0043\n",
            "Epoch 573/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0390 - val_loss: 0.0051\n",
            "Epoch 574/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0043\n",
            "Epoch 575/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.0043\n",
            "Epoch 576/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0278 - val_loss: 0.0039\n",
            "Epoch 577/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0390 - val_loss: 0.0042\n",
            "Epoch 578/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.0051\n",
            "Epoch 579/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0440 - val_loss: 0.0039\n",
            "Epoch 580/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0057\n",
            "Epoch 581/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0039\n",
            "Epoch 582/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0367 - val_loss: 0.0040\n",
            "Epoch 583/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0039\n",
            "Epoch 584/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0343 - val_loss: 0.0076\n",
            "Epoch 585/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0046\n",
            "Epoch 586/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0351 - val_loss: 0.0040\n",
            "Epoch 587/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0331 - val_loss: 0.0059\n",
            "Epoch 588/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0356 - val_loss: 0.0038\n",
            "Epoch 589/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0420 - val_loss: 0.0045\n",
            "Epoch 590/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0354 - val_loss: 0.0051\n",
            "Epoch 591/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0418 - val_loss: 0.0038\n",
            "Epoch 592/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0036\n",
            "Epoch 593/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0042\n",
            "Epoch 594/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0277 - val_loss: 0.0045\n",
            "Epoch 595/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0089\n",
            "Epoch 596/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0518 - val_loss: 0.0041\n",
            "Epoch 597/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0548 - val_loss: 0.0056\n",
            "Epoch 598/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0381 - val_loss: 0.0037\n",
            "Epoch 599/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0349 - val_loss: 0.0039\n",
            "Epoch 600/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0298 - val_loss: 0.0037\n",
            "Epoch 601/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0367 - val_loss: 0.0045\n",
            "Epoch 602/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0045\n",
            "Epoch 603/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0536 - val_loss: 0.0069\n",
            "Epoch 604/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0411 - val_loss: 0.0037\n",
            "Epoch 605/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0038\n",
            "Epoch 606/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0216 - val_loss: 0.0049\n",
            "Epoch 607/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0340 - val_loss: 0.0043\n",
            "Epoch 608/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0197 - val_loss: 0.0037\n",
            "Epoch 609/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0112 - val_loss: 0.0038\n",
            "Epoch 610/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0179 - val_loss: 0.0036\n",
            "Epoch 611/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0051\n",
            "Epoch 612/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0465 - val_loss: 0.0037\n",
            "Epoch 613/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0732 - val_loss: 0.0039\n",
            "Epoch 614/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0537 - val_loss: 0.0049\n",
            "Epoch 615/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0556 - val_loss: 0.0053\n",
            "Epoch 616/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0322 - val_loss: 0.0064\n",
            "Epoch 617/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0347 - val_loss: 0.0042\n",
            "Epoch 618/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0285 - val_loss: 0.0043\n",
            "Epoch 619/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0358 - val_loss: 0.0056\n",
            "Epoch 620/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0357 - val_loss: 0.0043\n",
            "Epoch 621/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0370 - val_loss: 0.0039\n",
            "Epoch 622/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0354 - val_loss: 0.0035\n",
            "Epoch 623/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0429 - val_loss: 0.0068\n",
            "Epoch 624/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0404 - val_loss: 0.0036\n",
            "Epoch 625/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0391 - val_loss: 0.0043\n",
            "Epoch 626/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0313 - val_loss: 0.0059\n",
            "Epoch 627/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0402 - val_loss: 0.0043\n",
            "Epoch 628/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0037\n",
            "Epoch 629/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0047\n",
            "Epoch 630/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0037\n",
            "Epoch 631/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0393 - val_loss: 0.0043\n",
            "Epoch 632/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0358 - val_loss: 0.0037\n",
            "Epoch 633/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0388 - val_loss: 0.0041\n",
            "Epoch 634/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.0042\n",
            "Epoch 635/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0394 - val_loss: 0.0038\n",
            "Epoch 636/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0036\n",
            "Epoch 637/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0406 - val_loss: 0.0041\n",
            "Epoch 638/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.0049\n",
            "Epoch 639/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0475 - val_loss: 0.0062\n",
            "Epoch 640/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0414 - val_loss: 0.0037\n",
            "Epoch 641/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0396 - val_loss: 0.0042\n",
            "Epoch 642/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.0047\n",
            "Epoch 643/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0452 - val_loss: 0.0036\n",
            "Epoch 644/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0042\n",
            "Epoch 645/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0349 - val_loss: 0.0067\n",
            "Epoch 646/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0034\n",
            "Epoch 647/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0161 - val_loss: 0.0040\n",
            "Epoch 648/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0159 - val_loss: 0.0034\n",
            "Epoch 649/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0174 - val_loss: 0.0037\n",
            "Epoch 650/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0036\n",
            "Epoch 651/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0489 - val_loss: 0.0043\n",
            "Epoch 652/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0072\n",
            "Epoch 653/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0736 - val_loss: 0.0073\n",
            "Epoch 654/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0471 - val_loss: 0.0040\n",
            "Epoch 655/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0509 - val_loss: 0.0040\n",
            "Epoch 656/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.0037\n",
            "Epoch 657/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0307 - val_loss: 0.0037\n",
            "Epoch 658/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0038\n",
            "Epoch 659/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0035\n",
            "Epoch 660/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0038\n",
            "Epoch 661/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0363 - val_loss: 0.0036\n",
            "Epoch 662/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0301 - val_loss: 0.0057\n",
            "Epoch 663/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.0036\n",
            "Epoch 664/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0039\n",
            "Epoch 665/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.0037\n",
            "Epoch 666/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0422 - val_loss: 0.0039\n",
            "Epoch 667/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0481 - val_loss: 0.0040\n",
            "Epoch 668/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0367 - val_loss: 0.0048\n",
            "Epoch 669/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0039\n",
            "Epoch 670/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0036\n",
            "Epoch 671/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0033\n",
            "Epoch 672/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0036\n",
            "Epoch 673/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0034\n",
            "Epoch 674/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0080\n",
            "Epoch 675/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0498 - val_loss: 0.0038\n",
            "Epoch 676/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0488 - val_loss: 0.0044\n",
            "Epoch 677/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0638 - val_loss: 0.0039\n",
            "Epoch 678/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.0034\n",
            "Epoch 679/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0348 - val_loss: 0.0066\n",
            "Epoch 680/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0034\n",
            "Epoch 681/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0272 - val_loss: 0.0038\n",
            "Epoch 682/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0045\n",
            "Epoch 683/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0325 - val_loss: 0.0047\n",
            "Epoch 684/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0036\n",
            "Epoch 685/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0225 - val_loss: 0.0050\n",
            "Epoch 686/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0045\n",
            "Epoch 687/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0517 - val_loss: 0.0060\n",
            "Epoch 688/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0469 - val_loss: 0.0051\n",
            "Epoch 689/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0537 - val_loss: 0.0039\n",
            "Epoch 690/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0045\n",
            "Epoch 691/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0339 - val_loss: 0.0045\n",
            "Epoch 692/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0033\n",
            "Epoch 693/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0041\n",
            "Epoch 694/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0065\n",
            "Epoch 695/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0380 - val_loss: 0.0035\n",
            "Epoch 696/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0033\n",
            "Epoch 697/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.0044\n",
            "Epoch 698/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0385 - val_loss: 0.0034\n",
            "Epoch 699/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0404 - val_loss: 0.0046\n",
            "Epoch 700/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0381 - val_loss: 0.0032\n",
            "Epoch 701/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0416 - val_loss: 0.0036\n",
            "Epoch 702/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0447 - val_loss: 0.0065\n",
            "Epoch 703/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0500 - val_loss: 0.0044\n",
            "Epoch 704/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0036\n",
            "Epoch 705/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0379 - val_loss: 0.0036\n",
            "Epoch 706/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0040\n",
            "Epoch 707/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0345 - val_loss: 0.0040\n",
            "Epoch 708/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0290 - val_loss: 0.0038\n",
            "Epoch 709/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.0041\n",
            "Epoch 710/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.0040\n",
            "Epoch 711/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0452 - val_loss: 0.0037\n",
            "Epoch 712/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0341 - val_loss: 0.0043\n",
            "Epoch 713/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0037\n",
            "Epoch 714/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0046\n",
            "Epoch 715/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.0042\n",
            "Epoch 716/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0055\n",
            "Epoch 717/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0379 - val_loss: 0.0031\n",
            "Epoch 718/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0048\n",
            "Epoch 719/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0030\n",
            "Epoch 720/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0033\n",
            "Epoch 721/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.0032\n",
            "Epoch 722/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0035\n",
            "Epoch 723/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0031\n",
            "Epoch 724/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0286 - val_loss: 0.0034\n",
            "Epoch 725/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0417 - val_loss: 0.0092\n",
            "Epoch 726/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0570 - val_loss: 0.0066\n",
            "Epoch 727/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0613 - val_loss: 0.0044\n",
            "Epoch 728/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0039\n",
            "Epoch 729/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.0036\n",
            "Epoch 730/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0218 - val_loss: 0.0038\n",
            "Epoch 731/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0037\n",
            "Epoch 732/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0034\n",
            "Epoch 733/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0038\n",
            "Epoch 734/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0232 - val_loss: 0.0034\n",
            "Epoch 735/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0273 - val_loss: 0.0037\n",
            "Epoch 736/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0262 - val_loss: 0.0048\n",
            "Epoch 737/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0483 - val_loss: 0.0035\n",
            "Epoch 738/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0591 - val_loss: 0.0037\n",
            "Epoch 739/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0571 - val_loss: 0.0038\n",
            "Epoch 740/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0316 - val_loss: 0.0033\n",
            "Epoch 741/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0038\n",
            "Epoch 742/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0032\n",
            "Epoch 743/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0034\n",
            "Epoch 744/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0247 - val_loss: 0.0062\n",
            "Epoch 745/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0034\n",
            "Epoch 746/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0043\n",
            "Epoch 747/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0032\n",
            "Epoch 748/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0280 - val_loss: 0.0039\n",
            "Epoch 749/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0070\n",
            "Epoch 750/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0506 - val_loss: 0.0034\n",
            "Epoch 751/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0470 - val_loss: 0.0039\n",
            "Epoch 752/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0287 - val_loss: 0.0037\n",
            "Epoch 753/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0297 - val_loss: 0.0039\n",
            "Epoch 754/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0039\n",
            "Epoch 755/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0258 - val_loss: 0.0039\n",
            "Epoch 756/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0222 - val_loss: 0.0036\n",
            "Epoch 757/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0219 - val_loss: 0.0056\n",
            "Epoch 758/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0036\n",
            "Epoch 759/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0040\n",
            "Epoch 760/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0329 - val_loss: 0.0043\n",
            "Epoch 761/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0403 - val_loss: 0.0039\n",
            "Epoch 762/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0252 - val_loss: 0.0043\n",
            "Epoch 763/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0422 - val_loss: 0.0096\n",
            "Epoch 764/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0505 - val_loss: 0.0034\n",
            "Epoch 765/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0424 - val_loss: 0.0037\n",
            "Epoch 766/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0320 - val_loss: 0.0033\n",
            "Epoch 767/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0342 - val_loss: 0.0035\n",
            "Epoch 768/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0291 - val_loss: 0.0049\n",
            "Epoch 769/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.0034\n",
            "Epoch 770/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0251 - val_loss: 0.0031\n",
            "Epoch 771/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0288 - val_loss: 0.0040\n",
            "Epoch 772/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0283 - val_loss: 0.0030\n",
            "Epoch 773/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0336 - val_loss: 0.0038\n",
            "Epoch 774/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0031\n",
            "Epoch 775/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.0051\n",
            "Epoch 776/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0357 - val_loss: 0.0030\n",
            "Epoch 777/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0387 - val_loss: 0.0031\n",
            "Epoch 778/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0029\n",
            "Epoch 779/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0314 - val_loss: 0.0032\n",
            "Epoch 780/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.0073\n",
            "Epoch 781/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0383 - val_loss: 0.0030\n",
            "Epoch 782/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0308 - val_loss: 0.0071\n",
            "Epoch 783/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0363 - val_loss: 0.0030\n",
            "Epoch 784/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0299 - val_loss: 0.0035\n",
            "Epoch 785/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0432 - val_loss: 0.0034\n",
            "Epoch 786/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0372 - val_loss: 0.0051\n",
            "Epoch 787/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0423 - val_loss: 0.0037\n",
            "Epoch 788/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0032\n",
            "Epoch 789/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0036\n",
            "Epoch 790/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0210 - val_loss: 0.0033\n",
            "Epoch 791/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0260 - val_loss: 0.0036\n",
            "Epoch 792/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0228 - val_loss: 0.0034\n",
            "Epoch 793/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0255 - val_loss: 0.0037\n",
            "Epoch 794/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0041\n",
            "Epoch 795/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0064\n",
            "Epoch 796/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0259 - val_loss: 0.0035\n",
            "Epoch 797/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.0043\n",
            "Epoch 798/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0400 - val_loss: 0.0036\n",
            "Epoch 799/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0559 - val_loss: 0.0051\n",
            "Epoch 800/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0446 - val_loss: 0.0035\n",
            "Epoch 801/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0415 - val_loss: 0.0036\n",
            "Epoch 802/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0237 - val_loss: 0.0066\n",
            "Epoch 803/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0110 - val_loss: 0.0031\n",
            "Epoch 804/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0032\n",
            "Epoch 805/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0092 - val_loss: 0.0038\n",
            "Epoch 806/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0032\n",
            "Epoch 807/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0032\n",
            "Epoch 808/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0330 - val_loss: 0.0043\n",
            "Epoch 809/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0264 - val_loss: 0.0041\n",
            "Epoch 810/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0294 - val_loss: 0.0053\n",
            "Epoch 811/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0045\n",
            "Epoch 812/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0630 - val_loss: 0.0066\n",
            "Epoch 813/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0497 - val_loss: 0.0042\n",
            "Epoch 814/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0369 - val_loss: 0.0073\n",
            "Epoch 815/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0038\n",
            "Epoch 816/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0032\n",
            "Epoch 817/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0059 - val_loss: 0.0033\n",
            "Epoch 818/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0098 - val_loss: 0.0029\n",
            "Epoch 819/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0184 - val_loss: 0.0029\n",
            "Epoch 820/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0305 - val_loss: 0.0065\n",
            "Epoch 821/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0522 - val_loss: 0.0059\n",
            "Epoch 822/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0455 - val_loss: 0.0033\n",
            "Epoch 823/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0246 - val_loss: 0.0032\n",
            "Epoch 824/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0312 - val_loss: 0.0041\n",
            "Epoch 825/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0374 - val_loss: 0.0034\n",
            "Epoch 826/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0566 - val_loss: 0.0040\n",
            "Epoch 827/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.0030\n",
            "Epoch 828/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.0038\n",
            "Epoch 829/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0034\n",
            "Epoch 830/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0028\n",
            "Epoch 831/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0202 - val_loss: 0.0028\n",
            "Epoch 832/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0028\n",
            "Epoch 833/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0187 - val_loss: 0.0028\n",
            "Epoch 834/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0027\n",
            "Epoch 835/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0240 - val_loss: 0.0023\n",
            "Epoch 836/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0300 - val_loss: 0.0030\n",
            "Epoch 837/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0295 - val_loss: 0.0029\n",
            "Epoch 838/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0084 - val_loss: 0.0023\n",
            "Epoch 839/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0074 - val_loss: 0.0023\n",
            "Epoch 840/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0099 - val_loss: 0.0025\n",
            "Epoch 841/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0179 - val_loss: 0.0048\n",
            "Epoch 842/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0360 - val_loss: 0.0059\n",
            "Epoch 843/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0349 - val_loss: 0.0049\n",
            "Epoch 844/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0535 - val_loss: 0.0062\n",
            "Epoch 845/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0514 - val_loss: 0.0039\n",
            "Epoch 846/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0469 - val_loss: 0.0050\n",
            "Epoch 847/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0233 - val_loss: 0.0031\n",
            "Epoch 848/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0190 - val_loss: 0.0034\n",
            "Epoch 849/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0134 - val_loss: 0.0028\n",
            "Epoch 850/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0170 - val_loss: 0.0046\n",
            "Epoch 851/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0229 - val_loss: 0.0034\n",
            "Epoch 852/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0303 - val_loss: 0.0060\n",
            "Epoch 853/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0281 - val_loss: 0.0078\n",
            "Epoch 854/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0341 - val_loss: 0.0065\n",
            "Epoch 855/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0227 - val_loss: 0.0043\n",
            "Epoch 856/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0268 - val_loss: 0.0048\n",
            "Epoch 857/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0257 - val_loss: 0.0038\n",
            "Epoch 858/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0328 - val_loss: 0.0040\n",
            "Epoch 859/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0030\n",
            "Epoch 860/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0335 - val_loss: 0.0030\n",
            "Epoch 861/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0033\n",
            "Epoch 862/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0250 - val_loss: 0.0028\n",
            "Epoch 863/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0195 - val_loss: 0.0058\n",
            "Epoch 864/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0265 - val_loss: 0.0028\n",
            "Epoch 865/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0026\n",
            "Epoch 866/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0344 - val_loss: 0.0073\n",
            "Epoch 867/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0315 - val_loss: 0.0032\n",
            "Epoch 868/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0282 - val_loss: 0.0063\n",
            "Epoch 869/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0035\n",
            "Epoch 870/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0241 - val_loss: 0.0063\n",
            "Epoch 871/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0235 - val_loss: 0.0025\n",
            "Epoch 872/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0230 - val_loss: 0.0031\n",
            "Epoch 873/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0271 - val_loss: 0.0040\n",
            "Epoch 874/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0051\n",
            "Epoch 875/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0215 - val_loss: 0.0059\n",
            "Epoch 876/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0255 - val_loss: 0.0041\n",
            "Epoch 877/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0249 - val_loss: 0.0038\n",
            "Epoch 878/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0381 - val_loss: 0.0082\n",
            "Epoch 879/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0378 - val_loss: 0.0029\n",
            "Epoch 880/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0359 - val_loss: 0.0033\n",
            "Epoch 881/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0217 - val_loss: 0.0033\n",
            "Epoch 882/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0252 - val_loss: 0.0045\n",
            "Epoch 883/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0220 - val_loss: 0.0034\n",
            "Epoch 884/1000\n",
            "158/158 [==============================] - 1s 7ms/step - loss: 0.0340 - val_loss: 0.0035\n",
            "Epoch 885/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0274 - val_loss: 0.0034\n",
            "Epoch 886/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0296 - val_loss: 0.0039\n",
            "Epoch 887/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.0169 - val_loss: 0.0027\n",
            "Epoch 888/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0211 - val_loss: 0.0037\n",
            "Epoch 889/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0227 - val_loss: 0.0038\n",
            "Epoch 890/1000\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 0.0329 - val_loss: 0.0053\n",
            "Epoch 891/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0402 - val_loss: 0.0041\n",
            "Epoch 892/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0469 - val_loss: 0.0041\n",
            "Epoch 893/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0333 - val_loss: 0.0029\n",
            "Epoch 894/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0324 - val_loss: 0.0027\n",
            "Epoch 895/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.0255 - val_loss: 0.0057\n",
            "Epoch 896/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0284 - val_loss: 0.0028\n",
            "Epoch 897/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0246 - val_loss: 0.0031\n",
            "Epoch 898/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0269 - val_loss: 0.0024\n",
            "Epoch 899/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0240 - val_loss: 0.0021\n",
            "Epoch 900/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.0240 - val_loss: 0.0023\n",
            "Epoch 901/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0183 - val_loss: 0.0028\n",
            "Epoch 902/1000\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 0.0235 - val_loss: 0.0022\n",
            "Epoch 903/1000\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 0.0245 - val_loss: 0.0027\n",
            "Epoch 904/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0318 - val_loss: 0.0034\n",
            "Epoch 905/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0359 - val_loss: 0.0062\n",
            "Epoch 906/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0377 - val_loss: 0.0031\n",
            "Epoch 907/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0028\n",
            "Epoch 908/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0274 - val_loss: 0.0040\n",
            "Epoch 909/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0244 - val_loss: 0.0032\n",
            "Epoch 910/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0178 - val_loss: 0.0039\n",
            "Epoch 911/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0200 - val_loss: 0.0029\n",
            "Epoch 912/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0311 - val_loss: 0.0028\n",
            "Epoch 913/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0317 - val_loss: 0.0040\n",
            "Epoch 914/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0338 - val_loss: 0.0061\n",
            "Epoch 915/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0323 - val_loss: 0.0048\n",
            "Epoch 916/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0370 - val_loss: 0.0043\n",
            "Epoch 917/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0261 - val_loss: 0.0028\n",
            "Epoch 918/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0382 - val_loss: 0.0030\n",
            "Epoch 919/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0342 - val_loss: 0.0029\n",
            "Epoch 920/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0369 - val_loss: 0.0049\n",
            "Epoch 921/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0021\n",
            "Epoch 922/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0214 - val_loss: 0.0026\n",
            "Epoch 923/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0242 - val_loss: 0.0027\n",
            "Epoch 924/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0350 - val_loss: 0.0038\n",
            "Epoch 925/1000\n",
            "158/158 [==============================] - 1s 7ms/step - loss: 0.0294 - val_loss: 0.0067\n",
            "Epoch 926/1000\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 0.0289 - val_loss: 0.0031\n",
            "Epoch 927/1000\n",
            "158/158 [==============================] - 1s 9ms/step - loss: 0.0214 - val_loss: 0.0023\n",
            "Epoch 928/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.0217 - val_loss: 0.0031\n",
            "Epoch 929/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.0195 - val_loss: 0.0022\n",
            "Epoch 930/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0194 - val_loss: 0.0029\n",
            "Epoch 931/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0220 - val_loss: 0.0059\n",
            "Epoch 932/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0310 - val_loss: 0.0024\n",
            "Epoch 933/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0214 - val_loss: 0.0035\n",
            "Epoch 934/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0252 - val_loss: 0.0035\n",
            "Epoch 935/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0263 - val_loss: 0.0047\n",
            "Epoch 936/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0321 - val_loss: 0.0043\n",
            "Epoch 937/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0294 - val_loss: 0.0036\n",
            "Epoch 938/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0341 - val_loss: 0.0055\n",
            "Epoch 939/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0292 - val_loss: 0.0026\n",
            "Epoch 940/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0319 - val_loss: 0.0027\n",
            "Epoch 941/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0254 - val_loss: 0.0037\n",
            "Epoch 942/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0314 - val_loss: 0.0100\n",
            "Epoch 943/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0303 - val_loss: 0.0023\n",
            "Epoch 944/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0259 - val_loss: 0.0028\n",
            "Epoch 945/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0142 - val_loss: 0.0025\n",
            "Epoch 946/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0149 - val_loss: 0.0023\n",
            "Epoch 947/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.0139 - val_loss: 0.0021\n",
            "Epoch 948/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.0215 - val_loss: 0.0021\n",
            "Epoch 949/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0075\n",
            "Epoch 950/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0492 - val_loss: 0.0022\n",
            "Epoch 951/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0452 - val_loss: 0.0035\n",
            "Epoch 952/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.0024\n",
            "Epoch 953/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0305 - val_loss: 0.0081\n",
            "Epoch 954/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0329 - val_loss: 0.0059\n",
            "Epoch 955/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0190 - val_loss: 0.0029\n",
            "Epoch 956/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0154 - val_loss: 0.0028\n",
            "Epoch 957/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0153 - val_loss: 0.0029\n",
            "Epoch 958/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0231 - val_loss: 0.0025\n",
            "Epoch 959/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0256 - val_loss: 0.0039\n",
            "Epoch 960/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0284 - val_loss: 0.0033\n",
            "Epoch 961/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0221 - val_loss: 0.0039\n",
            "Epoch 962/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0275 - val_loss: 0.0041\n",
            "Epoch 963/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0293 - val_loss: 0.0034\n",
            "Epoch 964/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0372 - val_loss: 0.0025\n",
            "Epoch 965/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0263 - val_loss: 0.0020\n",
            "Epoch 966/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0273 - val_loss: 0.0052\n",
            "Epoch 967/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0240 - val_loss: 0.0025\n",
            "Epoch 968/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0206 - val_loss: 0.0023\n",
            "Epoch 969/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0208 - val_loss: 0.0049\n",
            "Epoch 970/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0309 - val_loss: 0.0023\n",
            "Epoch 971/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0171 - val_loss: 0.0020\n",
            "Epoch 972/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0242 - val_loss: 0.0067\n",
            "Epoch 973/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0279 - val_loss: 0.0035\n",
            "Epoch 974/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0337 - val_loss: 0.0062\n",
            "Epoch 975/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0306 - val_loss: 0.0049\n",
            "Epoch 976/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0403 - val_loss: 0.0033\n",
            "Epoch 977/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0269 - val_loss: 0.0034\n",
            "Epoch 978/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0362 - val_loss: 0.0086\n",
            "Epoch 979/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0407 - val_loss: 0.0036\n",
            "Epoch 980/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.0279 - val_loss: 0.0027\n",
            "Epoch 981/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0193 - val_loss: 0.0036\n",
            "Epoch 982/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0203 - val_loss: 0.0020\n",
            "Epoch 983/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0174 - val_loss: 0.0021\n",
            "Epoch 984/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0211 - val_loss: 0.0021\n",
            "Epoch 985/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0211 - val_loss: 0.0031\n",
            "Epoch 986/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0287 - val_loss: 0.0022\n",
            "Epoch 987/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 0.0253 - val_loss: 0.0025\n",
            "Epoch 988/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0329 - val_loss: 0.0042\n",
            "Epoch 989/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0290 - val_loss: 0.0022\n",
            "Epoch 990/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0427 - val_loss: 0.0027\n",
            "Epoch 991/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0300 - val_loss: 0.0028\n",
            "Epoch 992/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0261 - val_loss: 0.0037\n",
            "Epoch 993/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0210 - val_loss: 0.0041\n",
            "Epoch 994/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0222 - val_loss: 0.0034\n",
            "Epoch 995/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0211 - val_loss: 0.0045\n",
            "Epoch 996/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 0.0310 - val_loss: 0.0026\n",
            "Epoch 997/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0292 - val_loss: 0.0051\n",
            "Epoch 998/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0368 - val_loss: 0.0037\n",
            "Epoch 999/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 0.0270 - val_loss: 0.0026\n",
            "Epoch 1000/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 0.0311 - val_loss: 0.0030\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract the hidden states"
      ],
      "metadata": {
        "id": "GnaHaERuDGk_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xen = np.array(targetdata).reshape(len(targetdata), 99)\n",
        "layer_output=model.get_layer('dense').output #'dense' is the name of the encoder layer, if the algorithm is performed multiple times, the name changes to dense_number\n",
        "intermediate_model=tf.keras.models.Model(inputs=params_input,outputs=layer_output)\n",
        "tussen=intermediate_model.predict(Xen) # = hidden vectors\n",
        "np.savetxt(\"hidden.csv\", tussen, delimiter=\",\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lwXzTjm4Bq49",
        "outputId": "95bea781-5da2-4799-9029-ca8dd76cff7b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "230/230 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Make decoder model"
      ],
      "metadata": {
        "id": "TEi21urNDjHp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "layer_hidden = model.get_layer('dense').output #'dense' is the name of the encoder layer, if the algorithm is performed multiple times, the name changes to dense_number\n",
        "decoder_model = tf.keras.models.Model(inputs=layer_hidden,outputs=decoder)"
      ],
      "metadata": {
        "id": "zmhn4fJGDk4y"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the neural network to predict the hidden states"
      ],
      "metadata": {
        "id": "prddzw4vDqQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#3 layers with 100, 20 and dim_latent_space neurons, as dim_latent_space changes the number of neurons in the layers might need to be changed to obtain an optimal model\n",
        "modinfo_train = modinfo[indexen_trainges]\n",
        "tussen_train = tussen[indexen_trainges]\n",
        "X= np.array(modinfo_train).reshape(len(modinfo_train), dim_modinfo)\n",
        "Y = np.array(tussen_train).reshape(len(tussen_train), dim_latent_space)\n",
        "\n",
        "params_input = keras.Input(shape=(dim_modinfo))\n",
        "lay1 = tf.keras.layers.Dense(100)(params_input)\n",
        "lay2 = tf.keras.layers.Dense(20)(lay1)\n",
        "lay3 = tf.keras.layers.Dense(dim_latent_space)(lay2)\n",
        "\n",
        "modelnn = keras.Model(inputs=params_input,outputs=lay3)\n",
        "modelnn.compile(optimizer='adam', loss='mse')\n",
        "modelnn.summary()\n",
        "hist = modelnn.fit(X,Y,epochs=1000,validation_split=0.2,batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "20Cs4bQ1Dtme",
        "outputId": "1527e65a-1114-47f4-c8d5-955611d00012"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_3 (InputLayer)        [(None, 4)]               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               500       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 20)                2020      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 5)                 105       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,625\n",
            "Trainable params: 2,625\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 49.1446 - val_loss: 9.5388\n",
            "Epoch 2/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 44.4395 - val_loss: 9.5062\n",
            "Epoch 3/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 44.1418 - val_loss: 9.0200\n",
            "Epoch 4/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 43.8564 - val_loss: 8.8961\n",
            "Epoch 5/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 43.7075 - val_loss: 9.0709\n",
            "Epoch 6/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 43.6807 - val_loss: 8.4982\n",
            "Epoch 7/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 43.4314 - val_loss: 8.7329\n",
            "Epoch 8/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 43.1128 - val_loss: 8.1747\n",
            "Epoch 9/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 43.0504 - val_loss: 9.1753\n",
            "Epoch 10/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 43.0005 - val_loss: 8.3918\n",
            "Epoch 11/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 43.0468 - val_loss: 8.2440\n",
            "Epoch 12/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.3257 - val_loss: 14.5243\n",
            "Epoch 13/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 43.4722 - val_loss: 9.1569\n",
            "Epoch 14/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 43.0341 - val_loss: 8.3504\n",
            "Epoch 15/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.7435 - val_loss: 8.0516\n",
            "Epoch 16/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.5535 - val_loss: 13.1151\n",
            "Epoch 17/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.8796 - val_loss: 8.3798\n",
            "Epoch 18/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.7075 - val_loss: 9.6684\n",
            "Epoch 19/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.6920 - val_loss: 8.3714\n",
            "Epoch 20/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.4740 - val_loss: 9.4433\n",
            "Epoch 21/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.9391 - val_loss: 8.1775\n",
            "Epoch 22/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.6032 - val_loss: 9.1937\n",
            "Epoch 23/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.8089 - val_loss: 9.2949\n",
            "Epoch 24/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.5028 - val_loss: 8.1951\n",
            "Epoch 25/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.5764 - val_loss: 8.1840\n",
            "Epoch 26/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.4767 - val_loss: 9.3450\n",
            "Epoch 27/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.5412 - val_loss: 8.0698\n",
            "Epoch 28/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.4662 - val_loss: 8.1086\n",
            "Epoch 29/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.4838 - val_loss: 8.1345\n",
            "Epoch 30/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.4787 - val_loss: 8.0100\n",
            "Epoch 31/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.5157 - val_loss: 8.3114\n",
            "Epoch 32/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.3372 - val_loss: 10.3963\n",
            "Epoch 33/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.5695 - val_loss: 8.4796\n",
            "Epoch 34/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.4747 - val_loss: 8.3005\n",
            "Epoch 35/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.3200 - val_loss: 8.1981\n",
            "Epoch 36/1000\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 42.3882 - val_loss: 8.6499\n",
            "Epoch 37/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 42.3929 - val_loss: 8.1722\n",
            "Epoch 38/1000\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 42.3127 - val_loss: 9.7597\n",
            "Epoch 39/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.5662 - val_loss: 8.2616\n",
            "Epoch 40/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.2209 - val_loss: 8.6630\n",
            "Epoch 41/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.4365 - val_loss: 8.4308\n",
            "Epoch 42/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.3085 - val_loss: 8.6213\n",
            "Epoch 43/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1252 - val_loss: 10.7671\n",
            "Epoch 44/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.5056 - val_loss: 8.2426\n",
            "Epoch 45/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.2704 - val_loss: 8.1389\n",
            "Epoch 46/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.3258 - val_loss: 8.6059\n",
            "Epoch 47/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.3209 - val_loss: 8.0892\n",
            "Epoch 48/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.3119 - val_loss: 8.1393\n",
            "Epoch 49/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.2380 - val_loss: 8.0024\n",
            "Epoch 50/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1984 - val_loss: 8.0025\n",
            "Epoch 51/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.2117 - val_loss: 8.0766\n",
            "Epoch 52/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.2209 - val_loss: 8.1901\n",
            "Epoch 53/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1741 - val_loss: 8.0331\n",
            "Epoch 54/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1347 - val_loss: 8.8148\n",
            "Epoch 55/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.2208 - val_loss: 8.0602\n",
            "Epoch 56/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1916 - val_loss: 8.1012\n",
            "Epoch 57/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1668 - val_loss: 8.2091\n",
            "Epoch 58/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.2290 - val_loss: 8.1787\n",
            "Epoch 59/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1812 - val_loss: 8.0544\n",
            "Epoch 60/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.1865 - val_loss: 8.0019\n",
            "Epoch 61/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1555 - val_loss: 8.0113\n",
            "Epoch 62/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1395 - val_loss: 8.0489\n",
            "Epoch 63/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0969 - val_loss: 8.0750\n",
            "Epoch 64/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1673 - val_loss: 8.2587\n",
            "Epoch 65/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.1325 - val_loss: 8.0432\n",
            "Epoch 66/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0869 - val_loss: 8.0491\n",
            "Epoch 67/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.1019 - val_loss: 8.1612\n",
            "Epoch 68/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1750 - val_loss: 8.0183\n",
            "Epoch 69/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1261 - val_loss: 8.3398\n",
            "Epoch 70/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.1224 - val_loss: 8.2896\n",
            "Epoch 71/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1349 - val_loss: 8.1311\n",
            "Epoch 72/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1582 - val_loss: 8.0624\n",
            "Epoch 73/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1601 - val_loss: 8.6413\n",
            "Epoch 74/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1802 - val_loss: 8.0474\n",
            "Epoch 75/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0836 - val_loss: 8.0027\n",
            "Epoch 76/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0692 - val_loss: 8.0601\n",
            "Epoch 77/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0817 - val_loss: 8.2310\n",
            "Epoch 78/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0999 - val_loss: 7.9741\n",
            "Epoch 79/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0373 - val_loss: 8.5076\n",
            "Epoch 80/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1203 - val_loss: 8.1728\n",
            "Epoch 81/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1730 - val_loss: 8.3497\n",
            "Epoch 82/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0893 - val_loss: 8.0852\n",
            "Epoch 83/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.1130 - val_loss: 8.5027\n",
            "Epoch 84/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.1167 - val_loss: 8.0813\n",
            "Epoch 85/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0797 - val_loss: 8.0211\n",
            "Epoch 86/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.1412 - val_loss: 8.0966\n",
            "Epoch 87/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0600 - val_loss: 8.1430\n",
            "Epoch 88/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0823 - val_loss: 7.9944\n",
            "Epoch 89/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0646 - val_loss: 8.0171\n",
            "Epoch 90/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0816 - val_loss: 8.0751\n",
            "Epoch 91/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0604 - val_loss: 8.1126\n",
            "Epoch 92/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0726 - val_loss: 8.2422\n",
            "Epoch 93/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0601 - val_loss: 8.2036\n",
            "Epoch 94/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.1005 - val_loss: 8.0135\n",
            "Epoch 95/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0454 - val_loss: 7.9843\n",
            "Epoch 96/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0540 - val_loss: 8.0111\n",
            "Epoch 97/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0287 - val_loss: 8.0992\n",
            "Epoch 98/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0479 - val_loss: 8.0915\n",
            "Epoch 99/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0818 - val_loss: 8.2158\n",
            "Epoch 100/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0703 - val_loss: 8.0653\n",
            "Epoch 101/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0746 - val_loss: 8.1471\n",
            "Epoch 102/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0785 - val_loss: 8.2130\n",
            "Epoch 103/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0562 - val_loss: 8.2065\n",
            "Epoch 104/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0559 - val_loss: 7.9892\n",
            "Epoch 105/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0852 - val_loss: 8.1216\n",
            "Epoch 106/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0512 - val_loss: 8.0236\n",
            "Epoch 107/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0678 - val_loss: 8.0143\n",
            "Epoch 108/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0529 - val_loss: 8.0273\n",
            "Epoch 109/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0983 - val_loss: 7.9837\n",
            "Epoch 110/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0498 - val_loss: 8.1831\n",
            "Epoch 111/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0782 - val_loss: 8.0615\n",
            "Epoch 112/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0963 - val_loss: 8.0768\n",
            "Epoch 113/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0405 - val_loss: 7.9866\n",
            "Epoch 114/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0998 - val_loss: 7.9780\n",
            "Epoch 115/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0608 - val_loss: 8.0038\n",
            "Epoch 116/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0361 - val_loss: 8.0718\n",
            "Epoch 117/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0415 - val_loss: 8.0946\n",
            "Epoch 118/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0361 - val_loss: 8.0197\n",
            "Epoch 119/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0317 - val_loss: 8.0025\n",
            "Epoch 120/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0334 - val_loss: 8.0464\n",
            "Epoch 121/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0560 - val_loss: 7.9914\n",
            "Epoch 122/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0617 - val_loss: 7.9843\n",
            "Epoch 123/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0465 - val_loss: 8.0829\n",
            "Epoch 124/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0497 - val_loss: 8.0190\n",
            "Epoch 125/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0369 - val_loss: 8.0564\n",
            "Epoch 126/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0609 - val_loss: 8.1235\n",
            "Epoch 127/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0437 - val_loss: 7.9813\n",
            "Epoch 128/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0390 - val_loss: 7.9602\n",
            "Epoch 129/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0471 - val_loss: 8.0499\n",
            "Epoch 130/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0417 - val_loss: 8.0246\n",
            "Epoch 131/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0303 - val_loss: 8.0971\n",
            "Epoch 132/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0516 - val_loss: 8.0433\n",
            "Epoch 133/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0255 - val_loss: 8.0084\n",
            "Epoch 134/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0435 - val_loss: 8.0329\n",
            "Epoch 135/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0208 - val_loss: 8.0845\n",
            "Epoch 136/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0287 - val_loss: 7.9787\n",
            "Epoch 137/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0551 - val_loss: 8.0298\n",
            "Epoch 138/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0565 - val_loss: 8.1554\n",
            "Epoch 139/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0467 - val_loss: 8.1240\n",
            "Epoch 140/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0532 - val_loss: 8.1156\n",
            "Epoch 141/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0137 - val_loss: 8.0812\n",
            "Epoch 142/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0407 - val_loss: 7.9959\n",
            "Epoch 143/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0411 - val_loss: 8.0709\n",
            "Epoch 144/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0341 - val_loss: 8.0499\n",
            "Epoch 145/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0128 - val_loss: 8.1821\n",
            "Epoch 146/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0379 - val_loss: 8.0430\n",
            "Epoch 147/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0631 - val_loss: 7.9982\n",
            "Epoch 148/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0452 - val_loss: 7.9944\n",
            "Epoch 149/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0134 - val_loss: 8.0613\n",
            "Epoch 150/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0196 - val_loss: 8.0118\n",
            "Epoch 151/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0448 - val_loss: 8.0115\n",
            "Epoch 152/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0625 - val_loss: 8.0664\n",
            "Epoch 153/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0286 - val_loss: 8.1020\n",
            "Epoch 154/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0356 - val_loss: 7.9884\n",
            "Epoch 155/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0065 - val_loss: 8.0666\n",
            "Epoch 156/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0266 - val_loss: 8.0342\n",
            "Epoch 157/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0677 - val_loss: 7.9822\n",
            "Epoch 158/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0213 - val_loss: 8.0413\n",
            "Epoch 159/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0166 - val_loss: 7.9790\n",
            "Epoch 160/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0469 - val_loss: 8.0066\n",
            "Epoch 161/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0365 - val_loss: 7.9931\n",
            "Epoch 162/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9848 - val_loss: 8.0002\n",
            "Epoch 163/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0157 - val_loss: 8.0806\n",
            "Epoch 164/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 42.0344 - val_loss: 8.0416\n",
            "Epoch 165/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0261 - val_loss: 7.9884\n",
            "Epoch 166/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 42.0164 - val_loss: 8.0614\n",
            "Epoch 167/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 42.0283 - val_loss: 7.9766\n",
            "Epoch 168/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0270 - val_loss: 8.0069\n",
            "Epoch 169/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0112 - val_loss: 8.0356\n",
            "Epoch 170/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0263 - val_loss: 7.9668\n",
            "Epoch 171/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0318 - val_loss: 8.0009\n",
            "Epoch 172/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9966 - val_loss: 8.0303\n",
            "Epoch 173/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0450 - val_loss: 7.9716\n",
            "Epoch 174/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0437 - val_loss: 7.9960\n",
            "Epoch 175/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0090 - val_loss: 7.9729\n",
            "Epoch 176/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0416 - val_loss: 8.0097\n",
            "Epoch 177/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0595 - val_loss: 8.0213\n",
            "Epoch 178/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0408 - val_loss: 8.0713\n",
            "Epoch 179/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0233 - val_loss: 8.0019\n",
            "Epoch 180/1000\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 42.0272 - val_loss: 8.0611\n",
            "Epoch 181/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0386 - val_loss: 7.9686\n",
            "Epoch 182/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0164 - val_loss: 8.0712\n",
            "Epoch 183/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0277 - val_loss: 8.0329\n",
            "Epoch 184/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0205 - val_loss: 7.9848\n",
            "Epoch 185/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9985 - val_loss: 8.1006\n",
            "Epoch 186/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0302 - val_loss: 8.0563\n",
            "Epoch 187/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0180 - val_loss: 7.9676\n",
            "Epoch 188/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0161 - val_loss: 7.9951\n",
            "Epoch 189/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0106 - val_loss: 8.0290\n",
            "Epoch 190/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0077 - val_loss: 7.9910\n",
            "Epoch 191/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0310 - val_loss: 8.0364\n",
            "Epoch 192/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9940 - val_loss: 8.0101\n",
            "Epoch 193/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0111 - val_loss: 7.9986\n",
            "Epoch 194/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0313 - val_loss: 8.0315\n",
            "Epoch 195/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0137 - val_loss: 8.0652\n",
            "Epoch 196/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0231 - val_loss: 7.9885\n",
            "Epoch 197/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0185 - val_loss: 7.9775\n",
            "Epoch 198/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0043 - val_loss: 8.0623\n",
            "Epoch 199/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0388 - val_loss: 7.9875\n",
            "Epoch 200/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0584 - val_loss: 8.0447\n",
            "Epoch 201/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0204 - val_loss: 7.9741\n",
            "Epoch 202/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0175 - val_loss: 8.0161\n",
            "Epoch 203/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0133 - val_loss: 7.9884\n",
            "Epoch 204/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0253 - val_loss: 8.0203\n",
            "Epoch 205/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0087 - val_loss: 7.9589\n",
            "Epoch 206/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0166 - val_loss: 8.0169\n",
            "Epoch 207/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0139 - val_loss: 7.9799\n",
            "Epoch 208/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0101 - val_loss: 7.9847\n",
            "Epoch 209/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0058 - val_loss: 8.0079\n",
            "Epoch 210/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0022 - val_loss: 8.0198\n",
            "Epoch 211/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0246 - val_loss: 8.0511\n",
            "Epoch 212/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0125 - val_loss: 8.0055\n",
            "Epoch 213/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0324 - val_loss: 8.0585\n",
            "Epoch 214/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 41.9943 - val_loss: 8.0427\n",
            "Epoch 215/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0301 - val_loss: 7.9869\n",
            "Epoch 216/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0023 - val_loss: 7.9883\n",
            "Epoch 217/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0215 - val_loss: 8.0406\n",
            "Epoch 218/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0235 - val_loss: 8.0292\n",
            "Epoch 219/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0233 - val_loss: 8.0434\n",
            "Epoch 220/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0249 - val_loss: 8.0173\n",
            "Epoch 221/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0254 - val_loss: 8.0007\n",
            "Epoch 222/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0168 - val_loss: 8.0141\n",
            "Epoch 223/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0251 - val_loss: 8.0596\n",
            "Epoch 224/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0162 - val_loss: 7.9838\n",
            "Epoch 225/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0032 - val_loss: 8.0021\n",
            "Epoch 226/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0140 - val_loss: 8.0137\n",
            "Epoch 227/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0247 - val_loss: 7.9967\n",
            "Epoch 228/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9966 - val_loss: 8.0116\n",
            "Epoch 229/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0143 - val_loss: 8.0744\n",
            "Epoch 230/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0159 - val_loss: 8.0334\n",
            "Epoch 231/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0182 - val_loss: 8.0664\n",
            "Epoch 232/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9991 - val_loss: 7.9936\n",
            "Epoch 233/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0070 - val_loss: 8.0337\n",
            "Epoch 234/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0327 - val_loss: 7.9819\n",
            "Epoch 235/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0206 - val_loss: 7.9981\n",
            "Epoch 236/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0144 - val_loss: 8.0361\n",
            "Epoch 237/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9943 - val_loss: 7.9847\n",
            "Epoch 238/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0089 - val_loss: 8.1096\n",
            "Epoch 239/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0221 - val_loss: 8.0726\n",
            "Epoch 240/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0062 - val_loss: 8.0418\n",
            "Epoch 241/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0205 - val_loss: 7.9933\n",
            "Epoch 242/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0261 - val_loss: 7.9986\n",
            "Epoch 243/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0079 - val_loss: 8.0336\n",
            "Epoch 244/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0153 - val_loss: 7.9977\n",
            "Epoch 245/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0394 - val_loss: 8.0360\n",
            "Epoch 246/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0371 - val_loss: 7.9905\n",
            "Epoch 247/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0006 - val_loss: 8.0022\n",
            "Epoch 248/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0281 - val_loss: 7.9999\n",
            "Epoch 249/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0023 - val_loss: 8.0398\n",
            "Epoch 250/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0106 - val_loss: 8.0543\n",
            "Epoch 251/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0112 - val_loss: 7.9999\n",
            "Epoch 252/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 41.9945 - val_loss: 7.9995\n",
            "Epoch 253/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9989 - val_loss: 8.0104\n",
            "Epoch 254/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9888 - val_loss: 8.0053\n",
            "Epoch 255/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9934 - val_loss: 7.9854\n",
            "Epoch 256/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0129 - val_loss: 8.0084\n",
            "Epoch 257/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0324 - val_loss: 8.0581\n",
            "Epoch 258/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0271 - val_loss: 8.0215\n",
            "Epoch 259/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9951 - val_loss: 8.0020\n",
            "Epoch 260/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0049 - val_loss: 8.0046\n",
            "Epoch 261/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0108 - val_loss: 8.0448\n",
            "Epoch 262/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0137 - val_loss: 8.0641\n",
            "Epoch 263/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0131 - val_loss: 7.9795\n",
            "Epoch 264/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0018 - val_loss: 8.0770\n",
            "Epoch 265/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0043 - val_loss: 8.0356\n",
            "Epoch 266/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0124 - val_loss: 8.0378\n",
            "Epoch 267/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0024 - val_loss: 8.0224\n",
            "Epoch 268/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 41.9898 - val_loss: 8.0264\n",
            "Epoch 269/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0154 - val_loss: 8.0567\n",
            "Epoch 270/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0020 - val_loss: 8.1384\n",
            "Epoch 271/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9984 - val_loss: 8.0057\n",
            "Epoch 272/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9946 - val_loss: 8.0349\n",
            "Epoch 273/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9919 - val_loss: 8.0106\n",
            "Epoch 274/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0264 - val_loss: 7.9970\n",
            "Epoch 275/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0043 - val_loss: 8.0152\n",
            "Epoch 276/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0077 - val_loss: 7.9754\n",
            "Epoch 277/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0169 - val_loss: 8.0056\n",
            "Epoch 278/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0185 - val_loss: 8.0338\n",
            "Epoch 279/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9966 - val_loss: 7.9833\n",
            "Epoch 280/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9951 - val_loss: 8.0073\n",
            "Epoch 281/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0147 - val_loss: 8.0987\n",
            "Epoch 282/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0221 - val_loss: 7.9843\n",
            "Epoch 283/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0093 - val_loss: 8.0446\n",
            "Epoch 284/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0272 - val_loss: 8.0042\n",
            "Epoch 285/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0038 - val_loss: 7.9713\n",
            "Epoch 286/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0129 - val_loss: 8.0090\n",
            "Epoch 287/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0062 - val_loss: 8.0350\n",
            "Epoch 288/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9974 - val_loss: 8.0445\n",
            "Epoch 289/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0000 - val_loss: 8.0172\n",
            "Epoch 290/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0096 - val_loss: 7.9933\n",
            "Epoch 291/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0054 - val_loss: 8.0582\n",
            "Epoch 292/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0078 - val_loss: 8.0042\n",
            "Epoch 293/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9878 - val_loss: 8.0034\n",
            "Epoch 294/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0090 - val_loss: 7.9964\n",
            "Epoch 295/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0027 - val_loss: 7.9791\n",
            "Epoch 296/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9773 - val_loss: 8.0502\n",
            "Epoch 297/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0141 - val_loss: 8.0003\n",
            "Epoch 298/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0058 - val_loss: 7.9869\n",
            "Epoch 299/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0144 - val_loss: 8.1062\n",
            "Epoch 300/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0051 - val_loss: 8.0425\n",
            "Epoch 301/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9966 - val_loss: 8.1200\n",
            "Epoch 302/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9911 - val_loss: 8.1898\n",
            "Epoch 303/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9996 - val_loss: 8.0126\n",
            "Epoch 304/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9885 - val_loss: 8.0328\n",
            "Epoch 305/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9930 - val_loss: 7.9968\n",
            "Epoch 306/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0059 - val_loss: 7.9987\n",
            "Epoch 307/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0004 - val_loss: 8.0152\n",
            "Epoch 308/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9933 - val_loss: 8.0374\n",
            "Epoch 309/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 41.9942 - val_loss: 8.0538\n",
            "Epoch 310/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0030 - val_loss: 8.0495\n",
            "Epoch 311/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0049 - val_loss: 7.9726\n",
            "Epoch 312/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0000 - val_loss: 7.9857\n",
            "Epoch 313/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0140 - val_loss: 7.9882\n",
            "Epoch 314/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9966 - val_loss: 8.0377\n",
            "Epoch 315/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0113 - val_loss: 7.9766\n",
            "Epoch 316/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0039 - val_loss: 7.9878\n",
            "Epoch 317/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0255 - val_loss: 8.0786\n",
            "Epoch 318/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9921 - val_loss: 8.0326\n",
            "Epoch 319/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9836 - val_loss: 8.0725\n",
            "Epoch 320/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0087 - val_loss: 7.9904\n",
            "Epoch 321/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9956 - val_loss: 7.9805\n",
            "Epoch 322/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0288 - val_loss: 8.0387\n",
            "Epoch 323/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0181 - val_loss: 8.0006\n",
            "Epoch 324/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9894 - val_loss: 8.0173\n",
            "Epoch 325/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0048 - val_loss: 8.0071\n",
            "Epoch 326/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0053 - val_loss: 7.9798\n",
            "Epoch 327/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0158 - val_loss: 7.9793\n",
            "Epoch 328/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0090 - val_loss: 8.0405\n",
            "Epoch 329/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9931 - val_loss: 7.9891\n",
            "Epoch 330/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0063 - val_loss: 7.9945\n",
            "Epoch 331/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9855 - val_loss: 8.0048\n",
            "Epoch 332/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9989 - val_loss: 8.0571\n",
            "Epoch 333/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0094 - val_loss: 7.9986\n",
            "Epoch 334/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9937 - val_loss: 7.9937\n",
            "Epoch 335/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0044 - val_loss: 8.0080\n",
            "Epoch 336/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9769 - val_loss: 8.0055\n",
            "Epoch 337/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9974 - val_loss: 8.0596\n",
            "Epoch 338/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0118 - val_loss: 8.0762\n",
            "Epoch 339/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0139 - val_loss: 8.0001\n",
            "Epoch 340/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0073 - val_loss: 7.9634\n",
            "Epoch 341/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0100 - val_loss: 8.0072\n",
            "Epoch 342/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0079 - val_loss: 8.0167\n",
            "Epoch 343/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0257 - val_loss: 8.0170\n",
            "Epoch 344/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0068 - val_loss: 8.0437\n",
            "Epoch 345/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0071 - val_loss: 7.9926\n",
            "Epoch 346/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9917 - val_loss: 7.9780\n",
            "Epoch 347/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0017 - val_loss: 8.0495\n",
            "Epoch 348/1000\n",
            "158/158 [==============================] - 0s 2ms/step - loss: 42.0208 - val_loss: 7.9898\n",
            "Epoch 349/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9986 - val_loss: 7.9930\n",
            "Epoch 350/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0034 - val_loss: 8.0161\n",
            "Epoch 351/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9895 - val_loss: 7.9795\n",
            "Epoch 352/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0017 - val_loss: 7.9904\n",
            "Epoch 353/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9866 - val_loss: 8.0830\n",
            "Epoch 354/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9846 - val_loss: 8.0335\n",
            "Epoch 355/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0040 - val_loss: 8.0227\n",
            "Epoch 356/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0185 - val_loss: 7.9879\n",
            "Epoch 357/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0005 - val_loss: 7.9774\n",
            "Epoch 358/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9945 - val_loss: 8.0230\n",
            "Epoch 359/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9888 - val_loss: 8.0025\n",
            "Epoch 360/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0203 - val_loss: 8.1647\n",
            "Epoch 361/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0139 - val_loss: 8.0011\n",
            "Epoch 362/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9971 - val_loss: 7.9898\n",
            "Epoch 363/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0158 - val_loss: 7.9962\n",
            "Epoch 364/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9932 - val_loss: 7.9860\n",
            "Epoch 365/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9895 - val_loss: 8.0265\n",
            "Epoch 366/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9869 - val_loss: 8.0050\n",
            "Epoch 367/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9895 - val_loss: 8.0712\n",
            "Epoch 368/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0133 - val_loss: 8.0159\n",
            "Epoch 369/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9982 - val_loss: 8.0096\n",
            "Epoch 370/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0021 - val_loss: 7.9965\n",
            "Epoch 371/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9964 - val_loss: 7.9940\n",
            "Epoch 372/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9990 - val_loss: 8.0442\n",
            "Epoch 373/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9862 - val_loss: 8.0054\n",
            "Epoch 374/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0071 - val_loss: 8.0203\n",
            "Epoch 375/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9914 - val_loss: 8.0533\n",
            "Epoch 376/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9974 - val_loss: 7.9775\n",
            "Epoch 377/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9955 - val_loss: 8.0427\n",
            "Epoch 378/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0015 - val_loss: 7.9934\n",
            "Epoch 379/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9974 - val_loss: 7.9920\n",
            "Epoch 380/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9986 - val_loss: 8.0635\n",
            "Epoch 381/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9907 - val_loss: 7.9971\n",
            "Epoch 382/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9902 - val_loss: 8.0514\n",
            "Epoch 383/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9972 - val_loss: 8.0381\n",
            "Epoch 384/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0025 - val_loss: 8.0020\n",
            "Epoch 385/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9877 - val_loss: 8.0377\n",
            "Epoch 386/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0175 - val_loss: 8.0550\n",
            "Epoch 387/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9812 - val_loss: 7.9848\n",
            "Epoch 388/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9951 - val_loss: 8.0372\n",
            "Epoch 389/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0089 - val_loss: 7.9982\n",
            "Epoch 390/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0010 - val_loss: 8.0470\n",
            "Epoch 391/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9634 - val_loss: 8.0340\n",
            "Epoch 392/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0178 - val_loss: 7.9645\n",
            "Epoch 393/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9954 - val_loss: 8.0401\n",
            "Epoch 394/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0308 - val_loss: 8.0753\n",
            "Epoch 395/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9918 - val_loss: 7.9762\n",
            "Epoch 396/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9883 - val_loss: 8.0486\n",
            "Epoch 397/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0029 - val_loss: 7.9891\n",
            "Epoch 398/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0095 - val_loss: 8.0244\n",
            "Epoch 399/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9701 - val_loss: 8.0201\n",
            "Epoch 400/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9787 - val_loss: 8.0786\n",
            "Epoch 401/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0110 - val_loss: 7.9802\n",
            "Epoch 402/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9855 - val_loss: 8.0246\n",
            "Epoch 403/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9821 - val_loss: 8.0256\n",
            "Epoch 404/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9920 - val_loss: 8.0020\n",
            "Epoch 405/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9916 - val_loss: 7.9852\n",
            "Epoch 406/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0090 - val_loss: 7.9978\n",
            "Epoch 407/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9766 - val_loss: 8.1687\n",
            "Epoch 408/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0217 - val_loss: 7.9840\n",
            "Epoch 409/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0007 - val_loss: 8.0160\n",
            "Epoch 410/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0082 - val_loss: 8.0480\n",
            "Epoch 411/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9840 - val_loss: 8.0278\n",
            "Epoch 412/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9795 - val_loss: 7.9998\n",
            "Epoch 413/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0089 - val_loss: 7.9980\n",
            "Epoch 414/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9926 - val_loss: 7.9821\n",
            "Epoch 415/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9848 - val_loss: 8.1142\n",
            "Epoch 416/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9809 - val_loss: 8.0484\n",
            "Epoch 417/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0303 - val_loss: 8.0187\n",
            "Epoch 418/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9909 - val_loss: 7.9741\n",
            "Epoch 419/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0009 - val_loss: 7.9855\n",
            "Epoch 420/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9870 - val_loss: 7.9940\n",
            "Epoch 421/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9974 - val_loss: 8.0371\n",
            "Epoch 422/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9954 - val_loss: 8.0161\n",
            "Epoch 423/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0046 - val_loss: 8.0280\n",
            "Epoch 424/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9938 - val_loss: 8.0114\n",
            "Epoch 425/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9933 - val_loss: 8.0201\n",
            "Epoch 426/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0023 - val_loss: 7.9957\n",
            "Epoch 427/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0001 - val_loss: 8.0335\n",
            "Epoch 428/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0000 - val_loss: 8.0416\n",
            "Epoch 429/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0036 - val_loss: 7.9962\n",
            "Epoch 430/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9959 - val_loss: 8.0039\n",
            "Epoch 431/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9867 - val_loss: 7.9853\n",
            "Epoch 432/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9991 - val_loss: 8.0068\n",
            "Epoch 433/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9754 - val_loss: 8.0357\n",
            "Epoch 434/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9974 - val_loss: 8.0022\n",
            "Epoch 435/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9913 - val_loss: 8.0246\n",
            "Epoch 436/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9838 - val_loss: 7.9884\n",
            "Epoch 437/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9954 - val_loss: 8.0082\n",
            "Epoch 438/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9866 - val_loss: 7.9877\n",
            "Epoch 439/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9904 - val_loss: 7.9878\n",
            "Epoch 440/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9893 - val_loss: 7.9922\n",
            "Epoch 441/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9913 - val_loss: 8.0050\n",
            "Epoch 442/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0092 - val_loss: 7.9868\n",
            "Epoch 443/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0056 - val_loss: 7.9999\n",
            "Epoch 444/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0214 - val_loss: 7.9825\n",
            "Epoch 445/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9910 - val_loss: 7.9819\n",
            "Epoch 446/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9840 - val_loss: 7.9969\n",
            "Epoch 447/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0021 - val_loss: 7.9914\n",
            "Epoch 448/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9895 - val_loss: 8.0312\n",
            "Epoch 449/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0074 - val_loss: 7.9831\n",
            "Epoch 450/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9783 - val_loss: 8.1751\n",
            "Epoch 451/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9988 - val_loss: 8.0039\n",
            "Epoch 452/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9900 - val_loss: 8.0156\n",
            "Epoch 453/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9868 - val_loss: 7.9913\n",
            "Epoch 454/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0031 - val_loss: 8.0346\n",
            "Epoch 455/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9913 - val_loss: 8.0000\n",
            "Epoch 456/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0154 - val_loss: 8.0192\n",
            "Epoch 457/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9996 - val_loss: 8.0867\n",
            "Epoch 458/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9973 - val_loss: 8.0756\n",
            "Epoch 459/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0002 - val_loss: 7.9876\n",
            "Epoch 460/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9893 - val_loss: 8.0010\n",
            "Epoch 461/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0048 - val_loss: 8.0168\n",
            "Epoch 462/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0032 - val_loss: 8.0063\n",
            "Epoch 463/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9809 - val_loss: 8.0349\n",
            "Epoch 464/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9904 - val_loss: 8.0212\n",
            "Epoch 465/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0126 - val_loss: 8.0033\n",
            "Epoch 466/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9860 - val_loss: 7.9741\n",
            "Epoch 467/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9956 - val_loss: 7.9955\n",
            "Epoch 468/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0089 - val_loss: 8.0328\n",
            "Epoch 469/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9877 - val_loss: 7.9692\n",
            "Epoch 470/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0091 - val_loss: 8.0383\n",
            "Epoch 471/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9674 - val_loss: 7.9982\n",
            "Epoch 472/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 42.0055 - val_loss: 8.0506\n",
            "Epoch 473/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9934 - val_loss: 7.9956\n",
            "Epoch 474/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9949 - val_loss: 7.9941\n",
            "Epoch 475/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9931 - val_loss: 8.0019\n",
            "Epoch 476/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0045 - val_loss: 7.9800\n",
            "Epoch 477/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9975 - val_loss: 8.0114\n",
            "Epoch 478/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9715 - val_loss: 7.9917\n",
            "Epoch 479/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9905 - val_loss: 7.9937\n",
            "Epoch 480/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9992 - val_loss: 8.0022\n",
            "Epoch 481/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9893 - val_loss: 7.9832\n",
            "Epoch 482/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9971 - val_loss: 7.9766\n",
            "Epoch 483/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9870 - val_loss: 7.9732\n",
            "Epoch 484/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9911 - val_loss: 8.0002\n",
            "Epoch 485/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0034 - val_loss: 7.9784\n",
            "Epoch 486/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9957 - val_loss: 7.9931\n",
            "Epoch 487/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9919 - val_loss: 8.0243\n",
            "Epoch 488/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9968 - val_loss: 8.0015\n",
            "Epoch 489/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9783 - val_loss: 8.0675\n",
            "Epoch 490/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0030 - val_loss: 8.0392\n",
            "Epoch 491/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0034 - val_loss: 8.0407\n",
            "Epoch 492/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9785 - val_loss: 8.0259\n",
            "Epoch 493/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0082 - val_loss: 8.0241\n",
            "Epoch 494/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0073 - val_loss: 8.0037\n",
            "Epoch 495/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9791 - val_loss: 7.9944\n",
            "Epoch 496/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9886 - val_loss: 8.0209\n",
            "Epoch 497/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9908 - val_loss: 8.0301\n",
            "Epoch 498/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9906 - val_loss: 8.0109\n",
            "Epoch 499/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9719 - val_loss: 8.0627\n",
            "Epoch 500/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9883 - val_loss: 7.9893\n",
            "Epoch 501/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0030 - val_loss: 8.0754\n",
            "Epoch 502/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0134 - val_loss: 8.0224\n",
            "Epoch 503/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9817 - val_loss: 7.9981\n",
            "Epoch 504/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9998 - val_loss: 8.0066\n",
            "Epoch 505/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9756 - val_loss: 8.0155\n",
            "Epoch 506/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9842 - val_loss: 8.0257\n",
            "Epoch 507/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9762 - val_loss: 8.0120\n",
            "Epoch 508/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9742 - val_loss: 8.0072\n",
            "Epoch 509/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9927 - val_loss: 8.0096\n",
            "Epoch 510/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9950 - val_loss: 8.0284\n",
            "Epoch 511/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9796 - val_loss: 8.0197\n",
            "Epoch 512/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9870 - val_loss: 7.9847\n",
            "Epoch 513/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9810 - val_loss: 8.0150\n",
            "Epoch 514/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9797 - val_loss: 7.9883\n",
            "Epoch 515/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9907 - val_loss: 7.9849\n",
            "Epoch 516/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0164 - val_loss: 7.9761\n",
            "Epoch 517/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0194 - val_loss: 8.0256\n",
            "Epoch 518/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9956 - val_loss: 8.0951\n",
            "Epoch 519/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9977 - val_loss: 7.9892\n",
            "Epoch 520/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0173 - val_loss: 7.9997\n",
            "Epoch 521/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9864 - val_loss: 8.0572\n",
            "Epoch 522/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9950 - val_loss: 8.0759\n",
            "Epoch 523/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9801 - val_loss: 8.0136\n",
            "Epoch 524/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9914 - val_loss: 8.0512\n",
            "Epoch 525/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0001 - val_loss: 8.0156\n",
            "Epoch 526/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9802 - val_loss: 8.0179\n",
            "Epoch 527/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9812 - val_loss: 8.0273\n",
            "Epoch 528/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9827 - val_loss: 7.9910\n",
            "Epoch 529/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9782 - val_loss: 7.9981\n",
            "Epoch 530/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9855 - val_loss: 7.9892\n",
            "Epoch 531/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9952 - val_loss: 7.9872\n",
            "Epoch 532/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9874 - val_loss: 8.0025\n",
            "Epoch 533/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9944 - val_loss: 8.0026\n",
            "Epoch 534/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9950 - val_loss: 7.9763\n",
            "Epoch 535/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9861 - val_loss: 7.9853\n",
            "Epoch 536/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9980 - val_loss: 8.0068\n",
            "Epoch 537/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9979 - val_loss: 7.9882\n",
            "Epoch 538/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9937 - val_loss: 8.0267\n",
            "Epoch 539/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9967 - val_loss: 8.0330\n",
            "Epoch 540/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9942 - val_loss: 7.9981\n",
            "Epoch 541/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9997 - val_loss: 8.0154\n",
            "Epoch 542/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9928 - val_loss: 8.0042\n",
            "Epoch 543/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9994 - val_loss: 8.0396\n",
            "Epoch 544/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9804 - val_loss: 8.0514\n",
            "Epoch 545/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9811 - val_loss: 7.9785\n",
            "Epoch 546/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9726 - val_loss: 8.0113\n",
            "Epoch 547/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9892 - val_loss: 7.9890\n",
            "Epoch 548/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9966 - val_loss: 8.1509\n",
            "Epoch 549/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9978 - val_loss: 7.9906\n",
            "Epoch 550/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9797 - val_loss: 7.9905\n",
            "Epoch 551/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9917 - val_loss: 7.9821\n",
            "Epoch 552/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9954 - val_loss: 7.9904\n",
            "Epoch 553/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9838 - val_loss: 8.0142\n",
            "Epoch 554/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0138 - val_loss: 7.9845\n",
            "Epoch 555/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9907 - val_loss: 7.9919\n",
            "Epoch 556/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9707 - val_loss: 7.9739\n",
            "Epoch 557/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0077 - val_loss: 7.9893\n",
            "Epoch 558/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9959 - val_loss: 8.1140\n",
            "Epoch 559/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0037 - val_loss: 8.0306\n",
            "Epoch 560/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0030 - val_loss: 8.0114\n",
            "Epoch 561/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9759 - val_loss: 7.9816\n",
            "Epoch 562/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9864 - val_loss: 8.0206\n",
            "Epoch 563/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9971 - val_loss: 8.0130\n",
            "Epoch 564/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9817 - val_loss: 8.0255\n",
            "Epoch 565/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9790 - val_loss: 7.9998\n",
            "Epoch 566/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9867 - val_loss: 7.9906\n",
            "Epoch 567/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9925 - val_loss: 7.9925\n",
            "Epoch 568/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9889 - val_loss: 8.0477\n",
            "Epoch 569/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9759 - val_loss: 8.0447\n",
            "Epoch 570/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9883 - val_loss: 8.0255\n",
            "Epoch 571/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9864 - val_loss: 8.0428\n",
            "Epoch 572/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9884 - val_loss: 7.9772\n",
            "Epoch 573/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9961 - val_loss: 8.0020\n",
            "Epoch 574/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0096 - val_loss: 8.0174\n",
            "Epoch 575/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9873 - val_loss: 8.0124\n",
            "Epoch 576/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9984 - val_loss: 7.9842\n",
            "Epoch 577/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9884 - val_loss: 7.9980\n",
            "Epoch 578/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9897 - val_loss: 8.0065\n",
            "Epoch 579/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0037 - val_loss: 8.0312\n",
            "Epoch 580/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0106 - val_loss: 7.9988\n",
            "Epoch 581/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9822 - val_loss: 7.9729\n",
            "Epoch 582/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9868 - val_loss: 7.9853\n",
            "Epoch 583/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9851 - val_loss: 8.0180\n",
            "Epoch 584/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9973 - val_loss: 7.9839\n",
            "Epoch 585/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9862 - val_loss: 7.9954\n",
            "Epoch 586/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9860 - val_loss: 8.0013\n",
            "Epoch 587/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9845 - val_loss: 7.9960\n",
            "Epoch 588/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9802 - val_loss: 7.9863\n",
            "Epoch 589/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9966 - val_loss: 8.0639\n",
            "Epoch 590/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9989 - val_loss: 8.0139\n",
            "Epoch 591/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9949 - val_loss: 7.9938\n",
            "Epoch 592/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0054 - val_loss: 8.0171\n",
            "Epoch 593/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0004 - val_loss: 7.9729\n",
            "Epoch 594/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9887 - val_loss: 8.0376\n",
            "Epoch 595/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 41.9947 - val_loss: 8.0022\n",
            "Epoch 596/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9842 - val_loss: 8.0237\n",
            "Epoch 597/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9780 - val_loss: 8.0017\n",
            "Epoch 598/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 41.9979 - val_loss: 8.0311\n",
            "Epoch 599/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9944 - val_loss: 8.0143\n",
            "Epoch 600/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9872 - val_loss: 7.9803\n",
            "Epoch 601/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9896 - val_loss: 7.9853\n",
            "Epoch 602/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9738 - val_loss: 8.0244\n",
            "Epoch 603/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9784 - val_loss: 7.9813\n",
            "Epoch 604/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9904 - val_loss: 7.9884\n",
            "Epoch 605/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9785 - val_loss: 7.9919\n",
            "Epoch 606/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9922 - val_loss: 7.9758\n",
            "Epoch 607/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9770 - val_loss: 7.9911\n",
            "Epoch 608/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9874 - val_loss: 7.9830\n",
            "Epoch 609/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9877 - val_loss: 8.0110\n",
            "Epoch 610/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9835 - val_loss: 7.9777\n",
            "Epoch 611/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9796 - val_loss: 7.9951\n",
            "Epoch 612/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9776 - val_loss: 8.0079\n",
            "Epoch 613/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9976 - val_loss: 8.0211\n",
            "Epoch 614/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9926 - val_loss: 7.9941\n",
            "Epoch 615/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0115 - val_loss: 8.0133\n",
            "Epoch 616/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 42.0155 - val_loss: 8.0484\n",
            "Epoch 617/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9860 - val_loss: 8.0961\n",
            "Epoch 618/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 42.0022 - val_loss: 7.9971\n",
            "Epoch 619/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9778 - val_loss: 7.9872\n",
            "Epoch 620/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9795 - val_loss: 8.0183\n",
            "Epoch 621/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9702 - val_loss: 8.0177\n",
            "Epoch 622/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9893 - val_loss: 8.0473\n",
            "Epoch 623/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9921 - val_loss: 7.9962\n",
            "Epoch 624/1000\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 42.0106 - val_loss: 8.0021\n",
            "Epoch 625/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9890 - val_loss: 8.0508\n",
            "Epoch 626/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 42.0041 - val_loss: 8.0036\n",
            "Epoch 627/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9887 - val_loss: 8.0007\n",
            "Epoch 628/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 41.9796 - val_loss: 7.9913\n",
            "Epoch 629/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0011 - val_loss: 8.0091\n",
            "Epoch 630/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0009 - val_loss: 8.0728\n",
            "Epoch 631/1000\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 42.0075 - val_loss: 7.9962\n",
            "Epoch 632/1000\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 41.9882 - val_loss: 7.9724\n",
            "Epoch 633/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 41.9997 - val_loss: 7.9814\n",
            "Epoch 634/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9837 - val_loss: 7.9922\n",
            "Epoch 635/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9915 - val_loss: 8.0348\n",
            "Epoch 636/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 41.9867 - val_loss: 7.9748\n",
            "Epoch 637/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9934 - val_loss: 7.9946\n",
            "Epoch 638/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9869 - val_loss: 7.9997\n",
            "Epoch 639/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9858 - val_loss: 8.0114\n",
            "Epoch 640/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 42.0064 - val_loss: 8.0102\n",
            "Epoch 641/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9897 - val_loss: 8.0591\n",
            "Epoch 642/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9786 - val_loss: 7.9953\n",
            "Epoch 643/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 42.0003 - val_loss: 7.9868\n",
            "Epoch 644/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9741 - val_loss: 8.0165\n",
            "Epoch 645/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9790 - val_loss: 8.0142\n",
            "Epoch 646/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9926 - val_loss: 7.9900\n",
            "Epoch 647/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9949 - val_loss: 8.0150\n",
            "Epoch 648/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9983 - val_loss: 8.0916\n",
            "Epoch 649/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9927 - val_loss: 8.0012\n",
            "Epoch 650/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0022 - val_loss: 8.0221\n",
            "Epoch 651/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9968 - val_loss: 8.0368\n",
            "Epoch 652/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0022 - val_loss: 7.9902\n",
            "Epoch 653/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0109 - val_loss: 7.9731\n",
            "Epoch 654/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9856 - val_loss: 8.0199\n",
            "Epoch 655/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9904 - val_loss: 8.0465\n",
            "Epoch 656/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9878 - val_loss: 8.0069\n",
            "Epoch 657/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9947 - val_loss: 8.0072\n",
            "Epoch 658/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9638 - val_loss: 8.0007\n",
            "Epoch 659/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9758 - val_loss: 7.9960\n",
            "Epoch 660/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9926 - val_loss: 8.0026\n",
            "Epoch 661/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9742 - val_loss: 8.0298\n",
            "Epoch 662/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9844 - val_loss: 8.0055\n",
            "Epoch 663/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9896 - val_loss: 8.0361\n",
            "Epoch 664/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9824 - val_loss: 8.0498\n",
            "Epoch 665/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9668 - val_loss: 7.9856\n",
            "Epoch 666/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9883 - val_loss: 8.0338\n",
            "Epoch 667/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0026 - val_loss: 8.0113\n",
            "Epoch 668/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9852 - val_loss: 7.9883\n",
            "Epoch 669/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9839 - val_loss: 8.0621\n",
            "Epoch 670/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0211 - val_loss: 7.9981\n",
            "Epoch 671/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9893 - val_loss: 8.0075\n",
            "Epoch 672/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9754 - val_loss: 7.9907\n",
            "Epoch 673/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9890 - val_loss: 8.0227\n",
            "Epoch 674/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9771 - val_loss: 8.0342\n",
            "Epoch 675/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9732 - val_loss: 7.9984\n",
            "Epoch 676/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9927 - val_loss: 7.9948\n",
            "Epoch 677/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9737 - val_loss: 7.9899\n",
            "Epoch 678/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9866 - val_loss: 8.0277\n",
            "Epoch 679/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9722 - val_loss: 8.0055\n",
            "Epoch 680/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9846 - val_loss: 8.0183\n",
            "Epoch 681/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9900 - val_loss: 7.9740\n",
            "Epoch 682/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9879 - val_loss: 7.9913\n",
            "Epoch 683/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9969 - val_loss: 7.9890\n",
            "Epoch 684/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9933 - val_loss: 7.9977\n",
            "Epoch 685/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9903 - val_loss: 8.0323\n",
            "Epoch 686/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9942 - val_loss: 8.0522\n",
            "Epoch 687/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9935 - val_loss: 8.0206\n",
            "Epoch 688/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0035 - val_loss: 8.0167\n",
            "Epoch 689/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9935 - val_loss: 7.9807\n",
            "Epoch 690/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9873 - val_loss: 8.0042\n",
            "Epoch 691/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9805 - val_loss: 8.0468\n",
            "Epoch 692/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9805 - val_loss: 7.9931\n",
            "Epoch 693/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9917 - val_loss: 7.9776\n",
            "Epoch 694/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9944 - val_loss: 8.0151\n",
            "Epoch 695/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9809 - val_loss: 8.0346\n",
            "Epoch 696/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9926 - val_loss: 8.0746\n",
            "Epoch 697/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9953 - val_loss: 8.0365\n",
            "Epoch 698/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9825 - val_loss: 8.1014\n",
            "Epoch 699/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9918 - val_loss: 7.9794\n",
            "Epoch 700/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0047 - val_loss: 7.9931\n",
            "Epoch 701/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9850 - val_loss: 8.0052\n",
            "Epoch 702/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9878 - val_loss: 7.9909\n",
            "Epoch 703/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9761 - val_loss: 7.9844\n",
            "Epoch 704/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9852 - val_loss: 7.9985\n",
            "Epoch 705/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9836 - val_loss: 8.0011\n",
            "Epoch 706/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9817 - val_loss: 8.0323\n",
            "Epoch 707/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9910 - val_loss: 7.9824\n",
            "Epoch 708/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9788 - val_loss: 7.9893\n",
            "Epoch 709/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9833 - val_loss: 7.9755\n",
            "Epoch 710/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9912 - val_loss: 7.9875\n",
            "Epoch 711/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9965 - val_loss: 8.0164\n",
            "Epoch 712/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9825 - val_loss: 7.9715\n",
            "Epoch 713/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9964 - val_loss: 7.9744\n",
            "Epoch 714/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9816 - val_loss: 7.9765\n",
            "Epoch 715/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9823 - val_loss: 8.0505\n",
            "Epoch 716/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9877 - val_loss: 8.0446\n",
            "Epoch 717/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9956 - val_loss: 7.9845\n",
            "Epoch 718/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9782 - val_loss: 7.9856\n",
            "Epoch 719/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9850 - val_loss: 7.9794\n",
            "Epoch 720/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9819 - val_loss: 8.0191\n",
            "Epoch 721/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9831 - val_loss: 7.9959\n",
            "Epoch 722/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9720 - val_loss: 7.9900\n",
            "Epoch 723/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0028 - val_loss: 8.0421\n",
            "Epoch 724/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9860 - val_loss: 8.0312\n",
            "Epoch 725/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9771 - val_loss: 8.0670\n",
            "Epoch 726/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9968 - val_loss: 7.9971\n",
            "Epoch 727/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9780 - val_loss: 8.0063\n",
            "Epoch 728/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9910 - val_loss: 7.9915\n",
            "Epoch 729/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9886 - val_loss: 7.9864\n",
            "Epoch 730/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9862 - val_loss: 8.0220\n",
            "Epoch 731/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9779 - val_loss: 8.0457\n",
            "Epoch 732/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9868 - val_loss: 7.9998\n",
            "Epoch 733/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9843 - val_loss: 7.9774\n",
            "Epoch 734/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9926 - val_loss: 8.0092\n",
            "Epoch 735/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9649 - val_loss: 8.0757\n",
            "Epoch 736/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9802 - val_loss: 8.0069\n",
            "Epoch 737/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9767 - val_loss: 7.9983\n",
            "Epoch 738/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9785 - val_loss: 8.0083\n",
            "Epoch 739/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9866 - val_loss: 8.0106\n",
            "Epoch 740/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9811 - val_loss: 7.9900\n",
            "Epoch 741/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9992 - val_loss: 7.9751\n",
            "Epoch 742/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0201 - val_loss: 8.0385\n",
            "Epoch 743/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0101 - val_loss: 8.0228\n",
            "Epoch 744/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9755 - val_loss: 7.9820\n",
            "Epoch 745/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9814 - val_loss: 8.0011\n",
            "Epoch 746/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 42.0058 - val_loss: 8.0264\n",
            "Epoch 747/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9976 - val_loss: 8.0076\n",
            "Epoch 748/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9886 - val_loss: 8.0090\n",
            "Epoch 749/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9946 - val_loss: 8.0578\n",
            "Epoch 750/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9801 - val_loss: 7.9830\n",
            "Epoch 751/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9796 - val_loss: 8.0126\n",
            "Epoch 752/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9931 - val_loss: 7.9841\n",
            "Epoch 753/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9848 - val_loss: 7.9912\n",
            "Epoch 754/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9867 - val_loss: 8.0084\n",
            "Epoch 755/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9746 - val_loss: 8.0110\n",
            "Epoch 756/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 41.9829 - val_loss: 8.0435\n",
            "Epoch 757/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9841 - val_loss: 8.0054\n",
            "Epoch 758/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9995 - val_loss: 8.0531\n",
            "Epoch 759/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9887 - val_loss: 8.0257\n",
            "Epoch 760/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0005 - val_loss: 7.9878\n",
            "Epoch 761/1000\n",
            "158/158 [==============================] - 1s 7ms/step - loss: 41.9991 - val_loss: 7.9952\n",
            "Epoch 762/1000\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 41.9763 - val_loss: 8.0086\n",
            "Epoch 763/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9896 - val_loss: 8.0664\n",
            "Epoch 764/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9819 - val_loss: 8.0026\n",
            "Epoch 765/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9721 - val_loss: 8.0112\n",
            "Epoch 766/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9982 - val_loss: 8.0489\n",
            "Epoch 767/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0033 - val_loss: 7.9890\n",
            "Epoch 768/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9781 - val_loss: 7.9849\n",
            "Epoch 769/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9781 - val_loss: 8.0035\n",
            "Epoch 770/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9800 - val_loss: 7.9934\n",
            "Epoch 771/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9762 - val_loss: 7.9857\n",
            "Epoch 772/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9771 - val_loss: 8.0169\n",
            "Epoch 773/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9813 - val_loss: 7.9832\n",
            "Epoch 774/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9785 - val_loss: 8.0438\n",
            "Epoch 775/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9817 - val_loss: 7.9918\n",
            "Epoch 776/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9859 - val_loss: 8.0143\n",
            "Epoch 777/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9768 - val_loss: 7.9928\n",
            "Epoch 778/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 41.9740 - val_loss: 7.9854\n",
            "Epoch 779/1000\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 41.9838 - val_loss: 7.9786\n",
            "Epoch 780/1000\n",
            "158/158 [==============================] - 1s 8ms/step - loss: 41.9882 - val_loss: 7.9938\n",
            "Epoch 781/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 41.9836 - val_loss: 7.9655\n",
            "Epoch 782/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9960 - val_loss: 8.0353\n",
            "Epoch 783/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9888 - val_loss: 8.0034\n",
            "Epoch 784/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9783 - val_loss: 8.0398\n",
            "Epoch 785/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9833 - val_loss: 8.0054\n",
            "Epoch 786/1000\n",
            "158/158 [==============================] - 1s 9ms/step - loss: 41.9887 - val_loss: 7.9858\n",
            "Epoch 787/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9860 - val_loss: 7.9855\n",
            "Epoch 788/1000\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 41.9799 - val_loss: 7.9911\n",
            "Epoch 789/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9776 - val_loss: 7.9926\n",
            "Epoch 790/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9891 - val_loss: 8.0054\n",
            "Epoch 791/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9849 - val_loss: 8.0239\n",
            "Epoch 792/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0031 - val_loss: 7.9897\n",
            "Epoch 793/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9809 - val_loss: 7.9956\n",
            "Epoch 794/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9778 - val_loss: 8.0105\n",
            "Epoch 795/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9749 - val_loss: 8.0639\n",
            "Epoch 796/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9929 - val_loss: 8.0026\n",
            "Epoch 797/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9921 - val_loss: 8.0373\n",
            "Epoch 798/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9980 - val_loss: 8.0023\n",
            "Epoch 799/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9902 - val_loss: 7.9814\n",
            "Epoch 800/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9755 - val_loss: 8.0404\n",
            "Epoch 801/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9797 - val_loss: 7.9763\n",
            "Epoch 802/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9975 - val_loss: 7.9821\n",
            "Epoch 803/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9798 - val_loss: 7.9890\n",
            "Epoch 804/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9815 - val_loss: 7.9875\n",
            "Epoch 805/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9799 - val_loss: 8.0063\n",
            "Epoch 806/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9684 - val_loss: 8.0033\n",
            "Epoch 807/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9881 - val_loss: 8.0207\n",
            "Epoch 808/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9791 - val_loss: 8.0714\n",
            "Epoch 809/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 41.9893 - val_loss: 8.0464\n",
            "Epoch 810/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9763 - val_loss: 7.9764\n",
            "Epoch 811/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9760 - val_loss: 8.0018\n",
            "Epoch 812/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9674 - val_loss: 8.0120\n",
            "Epoch 813/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9878 - val_loss: 8.0377\n",
            "Epoch 814/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9699 - val_loss: 8.0235\n",
            "Epoch 815/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9881 - val_loss: 8.0169\n",
            "Epoch 816/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9816 - val_loss: 7.9978\n",
            "Epoch 817/1000\n",
            "158/158 [==============================] - 1s 5ms/step - loss: 41.9889 - val_loss: 8.0344\n",
            "Epoch 818/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9796 - val_loss: 8.0015\n",
            "Epoch 819/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9967 - val_loss: 7.9906\n",
            "Epoch 820/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9951 - val_loss: 7.9859\n",
            "Epoch 821/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9840 - val_loss: 7.9945\n",
            "Epoch 822/1000\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 41.9709 - val_loss: 7.9816\n",
            "Epoch 823/1000\n",
            "158/158 [==============================] - 1s 6ms/step - loss: 41.9602 - val_loss: 8.0374\n",
            "Epoch 824/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9856 - val_loss: 7.9904\n",
            "Epoch 825/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9733 - val_loss: 8.0326\n",
            "Epoch 826/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9987 - val_loss: 8.0236\n",
            "Epoch 827/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9874 - val_loss: 7.9875\n",
            "Epoch 828/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9863 - val_loss: 7.9942\n",
            "Epoch 829/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9819 - val_loss: 8.0353\n",
            "Epoch 830/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9862 - val_loss: 8.0000\n",
            "Epoch 831/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9762 - val_loss: 8.0494\n",
            "Epoch 832/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9904 - val_loss: 7.9989\n",
            "Epoch 833/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9753 - val_loss: 7.9689\n",
            "Epoch 834/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0017 - val_loss: 8.0020\n",
            "Epoch 835/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9812 - val_loss: 7.9757\n",
            "Epoch 836/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 42.0055 - val_loss: 7.9996\n",
            "Epoch 837/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9869 - val_loss: 8.0150\n",
            "Epoch 838/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0017 - val_loss: 8.0076\n",
            "Epoch 839/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9727 - val_loss: 8.0073\n",
            "Epoch 840/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9759 - val_loss: 8.0091\n",
            "Epoch 841/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9785 - val_loss: 8.0319\n",
            "Epoch 842/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9834 - val_loss: 8.0100\n",
            "Epoch 843/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9720 - val_loss: 7.9866\n",
            "Epoch 844/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9818 - val_loss: 7.9822\n",
            "Epoch 845/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9740 - val_loss: 7.9895\n",
            "Epoch 846/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9829 - val_loss: 8.0021\n",
            "Epoch 847/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9853 - val_loss: 7.9652\n",
            "Epoch 848/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0071 - val_loss: 7.9940\n",
            "Epoch 849/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9848 - val_loss: 8.0045\n",
            "Epoch 850/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9963 - val_loss: 7.9742\n",
            "Epoch 851/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9813 - val_loss: 8.0293\n",
            "Epoch 852/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9927 - val_loss: 7.9889\n",
            "Epoch 853/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9748 - val_loss: 7.9789\n",
            "Epoch 854/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9866 - val_loss: 7.9907\n",
            "Epoch 855/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9792 - val_loss: 8.0062\n",
            "Epoch 856/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9741 - val_loss: 7.9907\n",
            "Epoch 857/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9779 - val_loss: 8.0041\n",
            "Epoch 858/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9853 - val_loss: 7.9821\n",
            "Epoch 859/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9787 - val_loss: 7.9905\n",
            "Epoch 860/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9838 - val_loss: 8.0560\n",
            "Epoch 861/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9885 - val_loss: 7.9970\n",
            "Epoch 862/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9815 - val_loss: 7.9878\n",
            "Epoch 863/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9632 - val_loss: 8.0628\n",
            "Epoch 864/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9785 - val_loss: 8.0673\n",
            "Epoch 865/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9881 - val_loss: 7.9877\n",
            "Epoch 866/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9996 - val_loss: 7.9989\n",
            "Epoch 867/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9924 - val_loss: 7.9947\n",
            "Epoch 868/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 42.0023 - val_loss: 8.0006\n",
            "Epoch 869/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9777 - val_loss: 8.0174\n",
            "Epoch 870/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9736 - val_loss: 8.0036\n",
            "Epoch 871/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9743 - val_loss: 8.0226\n",
            "Epoch 872/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9739 - val_loss: 8.0127\n",
            "Epoch 873/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9859 - val_loss: 7.9922\n",
            "Epoch 874/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9816 - val_loss: 7.9850\n",
            "Epoch 875/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9796 - val_loss: 7.9963\n",
            "Epoch 876/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9928 - val_loss: 7.9810\n",
            "Epoch 877/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9876 - val_loss: 8.0187\n",
            "Epoch 878/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9871 - val_loss: 8.0007\n",
            "Epoch 879/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9868 - val_loss: 8.0254\n",
            "Epoch 880/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9736 - val_loss: 7.9916\n",
            "Epoch 881/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9914 - val_loss: 8.0192\n",
            "Epoch 882/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9965 - val_loss: 7.9911\n",
            "Epoch 883/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9936 - val_loss: 7.9878\n",
            "Epoch 884/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9991 - val_loss: 8.0119\n",
            "Epoch 885/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9970 - val_loss: 8.0297\n",
            "Epoch 886/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9729 - val_loss: 8.0243\n",
            "Epoch 887/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9779 - val_loss: 8.0378\n",
            "Epoch 888/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9761 - val_loss: 7.9921\n",
            "Epoch 889/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9881 - val_loss: 8.0086\n",
            "Epoch 890/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9718 - val_loss: 7.9920\n",
            "Epoch 891/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9822 - val_loss: 7.9929\n",
            "Epoch 892/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9680 - val_loss: 8.0134\n",
            "Epoch 893/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9849 - val_loss: 7.9916\n",
            "Epoch 894/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9859 - val_loss: 8.0009\n",
            "Epoch 895/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9719 - val_loss: 7.9780\n",
            "Epoch 896/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9849 - val_loss: 8.0377\n",
            "Epoch 897/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9702 - val_loss: 7.9870\n",
            "Epoch 898/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9756 - val_loss: 8.0767\n",
            "Epoch 899/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9851 - val_loss: 8.0166\n",
            "Epoch 900/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9845 - val_loss: 7.9843\n",
            "Epoch 901/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9842 - val_loss: 8.0249\n",
            "Epoch 902/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 42.0002 - val_loss: 8.0164\n",
            "Epoch 903/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9917 - val_loss: 8.0151\n",
            "Epoch 904/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9857 - val_loss: 8.0048\n",
            "Epoch 905/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 42.0008 - val_loss: 8.0116\n",
            "Epoch 906/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9852 - val_loss: 7.9833\n",
            "Epoch 907/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9753 - val_loss: 7.9942\n",
            "Epoch 908/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9952 - val_loss: 8.0050\n",
            "Epoch 909/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9820 - val_loss: 7.9934\n",
            "Epoch 910/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9754 - val_loss: 7.9914\n",
            "Epoch 911/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9962 - val_loss: 7.9801\n",
            "Epoch 912/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9795 - val_loss: 8.0107\n",
            "Epoch 913/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9851 - val_loss: 8.0003\n",
            "Epoch 914/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9762 - val_loss: 7.9810\n",
            "Epoch 915/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9981 - val_loss: 7.9746\n",
            "Epoch 916/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9872 - val_loss: 8.0591\n",
            "Epoch 917/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9710 - val_loss: 7.9873\n",
            "Epoch 918/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9752 - val_loss: 7.9845\n",
            "Epoch 919/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9839 - val_loss: 8.0063\n",
            "Epoch 920/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9773 - val_loss: 8.0039\n",
            "Epoch 921/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9798 - val_loss: 7.9950\n",
            "Epoch 922/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9857 - val_loss: 7.9803\n",
            "Epoch 923/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9916 - val_loss: 7.9984\n",
            "Epoch 924/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9838 - val_loss: 8.0264\n",
            "Epoch 925/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9727 - val_loss: 8.0227\n",
            "Epoch 926/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9897 - val_loss: 8.0354\n",
            "Epoch 927/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9946 - val_loss: 7.9795\n",
            "Epoch 928/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 42.0111 - val_loss: 8.0689\n",
            "Epoch 929/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9893 - val_loss: 8.0007\n",
            "Epoch 930/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9770 - val_loss: 8.0100\n",
            "Epoch 931/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9786 - val_loss: 7.9971\n",
            "Epoch 932/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9914 - val_loss: 8.0382\n",
            "Epoch 933/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9719 - val_loss: 8.0243\n",
            "Epoch 934/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9822 - val_loss: 8.0051\n",
            "Epoch 935/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9809 - val_loss: 8.0001\n",
            "Epoch 936/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9815 - val_loss: 8.0078\n",
            "Epoch 937/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9806 - val_loss: 8.0081\n",
            "Epoch 938/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9915 - val_loss: 7.9795\n",
            "Epoch 939/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9721 - val_loss: 8.0157\n",
            "Epoch 940/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9850 - val_loss: 8.0398\n",
            "Epoch 941/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9890 - val_loss: 8.0336\n",
            "Epoch 942/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9653 - val_loss: 7.9958\n",
            "Epoch 943/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9651 - val_loss: 8.0596\n",
            "Epoch 944/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9870 - val_loss: 7.9902\n",
            "Epoch 945/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9787 - val_loss: 8.0221\n",
            "Epoch 946/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9747 - val_loss: 8.0279\n",
            "Epoch 947/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9819 - val_loss: 7.9939\n",
            "Epoch 948/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9869 - val_loss: 8.0100\n",
            "Epoch 949/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9839 - val_loss: 8.0069\n",
            "Epoch 950/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9838 - val_loss: 7.9812\n",
            "Epoch 951/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 42.0083 - val_loss: 7.9822\n",
            "Epoch 952/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9660 - val_loss: 7.9935\n",
            "Epoch 953/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9787 - val_loss: 7.9880\n",
            "Epoch 954/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9908 - val_loss: 8.0354\n",
            "Epoch 955/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9954 - val_loss: 8.0392\n",
            "Epoch 956/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9766 - val_loss: 8.0305\n",
            "Epoch 957/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9655 - val_loss: 8.0445\n",
            "Epoch 958/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9869 - val_loss: 8.0033\n",
            "Epoch 959/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9783 - val_loss: 7.9856\n",
            "Epoch 960/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9779 - val_loss: 8.0185\n",
            "Epoch 961/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9811 - val_loss: 8.0069\n",
            "Epoch 962/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9712 - val_loss: 8.0102\n",
            "Epoch 963/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9839 - val_loss: 7.9980\n",
            "Epoch 964/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9774 - val_loss: 7.9884\n",
            "Epoch 965/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9872 - val_loss: 8.0051\n",
            "Epoch 966/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9819 - val_loss: 8.0263\n",
            "Epoch 967/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9928 - val_loss: 7.9826\n",
            "Epoch 968/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9886 - val_loss: 8.0242\n",
            "Epoch 969/1000\n",
            "158/158 [==============================] - 1s 4ms/step - loss: 41.9813 - val_loss: 8.0047\n",
            "Epoch 970/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9877 - val_loss: 8.0008\n",
            "Epoch 971/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9798 - val_loss: 7.9806\n",
            "Epoch 972/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9870 - val_loss: 7.9994\n",
            "Epoch 973/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9672 - val_loss: 8.0073\n",
            "Epoch 974/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9809 - val_loss: 8.0032\n",
            "Epoch 975/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9681 - val_loss: 7.9986\n",
            "Epoch 976/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9905 - val_loss: 7.9950\n",
            "Epoch 977/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9630 - val_loss: 8.0089\n",
            "Epoch 978/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9820 - val_loss: 8.0030\n",
            "Epoch 979/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9728 - val_loss: 7.9881\n",
            "Epoch 980/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9794 - val_loss: 8.0775\n",
            "Epoch 981/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9734 - val_loss: 7.9886\n",
            "Epoch 982/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9793 - val_loss: 8.0159\n",
            "Epoch 983/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9764 - val_loss: 8.0107\n",
            "Epoch 984/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9880 - val_loss: 7.9768\n",
            "Epoch 985/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9829 - val_loss: 8.0492\n",
            "Epoch 986/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9844 - val_loss: 8.0196\n",
            "Epoch 987/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9853 - val_loss: 7.9866\n",
            "Epoch 988/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9853 - val_loss: 8.0034\n",
            "Epoch 989/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9996 - val_loss: 7.9823\n",
            "Epoch 990/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9763 - val_loss: 8.0740\n",
            "Epoch 991/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9800 - val_loss: 8.0310\n",
            "Epoch 992/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9839 - val_loss: 8.0100\n",
            "Epoch 993/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9768 - val_loss: 7.9788\n",
            "Epoch 994/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9985 - val_loss: 7.9929\n",
            "Epoch 995/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9968 - val_loss: 8.0525\n",
            "Epoch 996/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9739 - val_loss: 7.9850\n",
            "Epoch 997/1000\n",
            "158/158 [==============================] - 0s 3ms/step - loss: 41.9874 - val_loss: 8.0017\n",
            "Epoch 998/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9756 - val_loss: 7.9836\n",
            "Epoch 999/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9768 - val_loss: 7.9778\n",
            "Epoch 1000/1000\n",
            "158/158 [==============================] - 1s 3ms/step - loss: 41.9761 - val_loss: 8.0363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use the decoder to go back to the full representation "
      ],
      "metadata": {
        "id": "srvIlGbbFb5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xtot = np.array(modinfo).reshape(len(modinfo), dim_modinfo)\n",
        "ouputnn = np.array(modelnn.predict(Xtot))\n",
        "ouputnnsh = np.array(ouputnn).reshape(len(ouputnn),dim_latent_space)\n",
        "predictie = decoder_model.predict(ouputnnsh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njGjxIgaFgES",
        "outputId": "5af6a4d3-d64f-4b5d-b9f8-792e2feb4cf9"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "230/230 [==============================] - 1s 3ms/step\n",
            "230/230 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(predictie[5],'.',label='Predicted timeline')\n",
        "plt.plot(targetdata[5],'.',label='Real timeline')\n",
        "plt.legend()\n",
        "plt.xlabel('Time')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "2_QNj_2JGWam",
        "outputId": "4c467855-35b7-4fcc-81fb-f823600de07d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Time')"
            ]
          },
          "metadata": {},
          "execution_count": 17
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(modinfo[:,0],predictie[:,50],'.',label='Predicted value at 50th time')\n",
        "plt.plot(modinfo[:,0],targetdata[:,50],'.',alpha=0.5,label='Real value at 50th time')\n",
        "plt.legend()\n",
        "plt.xlabel('Depth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "tDVwjeFvG_BE",
        "outputId": "4a80b665-5b46-49c9-bf0f-bd0b78d5c21f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Depth')"
            ]
          },
          "metadata": {},
          "execution_count": 21
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}