{ 
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Import the libraries that are needed"
      ],
      "metadata": {
        "id": "gN35Ae16c7Z7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6MK6jzNccegg",
        "outputId": "a681f0c1-00fc-4791-86ce-e9b3f3c20ef8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.9.2\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import seaborn as sns\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import sklearn\n",
        "from sklearn import preprocessing\n",
        "import scipy as sc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.compose import ColumnTransformer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#initialize the train and test data set + perform the fourier transformation"
      ],
      "metadata": {
        "id": "IBHRRToidq-L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "targetdata = np.loadtxt('verschilgeschaald.csv',dtype=float,delimiter=',') #data that we want to predict\n",
        "dim_targetdata = 99 #number of values that need to be predicted per input point\n",
        "modinfo = np.loadtxt('modinfo.csv',dtype=float,delimiter=',') \n",
        "alleLFs = np.loadtxt('alleLFs.csv',dtype=float,delimiter=',') \n",
        "features = []\n",
        "for ii in range(len(modinfo)): \n",
        "    rij = modinfo[ii]\n",
        "    toetevoegen = np.concatenate([rij, alleLFs[ii]])\n",
        "    features.append(toetevoegen)\n",
        "features = np.array(features) #input data for the model\n",
        "dim_modinfo = 4+99 #number of input parameters per input point\n",
        "train_size = 6300 #number of datapoints in the train dataset\n",
        "test_size = 1000 #number of datapoints in the test dataset\n",
        "dim_latent_space = 5 #dimension of the latent space representation"
      ],
      "metadata": {
        "id": "v2lisNhXdxst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#perform the fourier transform\n",
        "verschilfour = []\n",
        "for ii in range(len(targetdata)):\n",
        "  verschilfour.append(sc.fft.fft(targetdata[ii]))\n",
        "verschilfour = np.array(verschilfour)\n",
        "#split in real and imaginary part\n",
        "re = np.real(verschilfour)\n",
        "im = np.imag(verschilfour)\n",
        "topred = []\n",
        "for ii in range(len(re)):\n",
        "  tijdsding = []\n",
        "  for jj in range(len(re[0])):\n",
        "    elnt = [re[ii,jj],im[ii,jj]]\n",
        "    tijdsding.append(elnt)\n",
        "  topred.append(tijdsding)\n",
        "topred = np.array(topred)\n",
        "\n",
        "indexen = range(len(verschilfour))\n",
        "\n",
        "#split in train and test data set\n",
        "X_trainges, X_testges, indexen_trainges_final, indexen_testges_final = train_test_split(features, indexen, train_size=5000, test_size=177, random_state=333)\n",
        "training_yges = topred[indexen_trainges_final]\n",
        "y_testges = topred[indexen_testges_final]"
      ],
      "metadata": {
        "id": "MSxgPAf7c_qK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Exploit symmetry of the fouriertransform"
      ],
      "metadata": {
        "id": "n-Z65cUhfIwp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "redeel = (topred[:,:,0]).copy()\n",
        "for ii in range(int((dim_targetdata-1)/2),dim_targetdata):\n",
        "  redeel[:,ii] = topred[:,int((dim_targetdata+1)/2-abs((dim_targetdata-1)/2-ii)),0]"
      ],
      "metadata": {
        "id": "_sCyJZ9ZfOL6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imdeel = (topred[:,:,1]).copy()\n",
        "for ii in range(int((dim_targetdata-1)/2),dim_targetdata):\n",
        "  imdeel[:,ii] = -topred[:,int((dim_targetdata+1)/2-abs((dim_targetdata-1)/2-ii)),1]"
      ],
      "metadata": {
        "id": "5bh_Rq_qfuk4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define the fouriercomponents that will be used for the prediction"
      ],
      "metadata": {
        "id": "kFQW9UcVf8QC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "relim = [5,95,99] #[x,y,z]: fouriercomponents from 0 to x and from y to z are taken into account for the real part with the last ones mirrored from the first ones\n",
        "imlim = [4,96,99] #[x,y,z]: fouriercomponents from 0 to x and from y to z are taken into account for the imag part with the last ones mirrored from the first ones"
      ],
      "metadata": {
        "id": "btkWmqTvgFbF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predfour = topred.copy()\n",
        "for jj in range(len(predfour)):\n",
        "  for ii in range(imlim[0],imlim[1]):\n",
        "    predfour[jj][ii][1] = 0\n",
        "  for ii in range(relim[0],relim[1]):\n",
        "    predfour[jj][ii][0] = 0\n",
        "  for ii in range(imlim[1],imlim[2]):\n",
        "    predfour[jj][ii][1] = -topred[jj,np.int((dim_targetdata+1)/2-abs((dim_targetdata-1)/2-ii)),1]\n",
        "  for ii in range(relim[1],relim[2]):\n",
        "    predfour[jj][ii][0] = topred[jj,np.int((dim_targetdata+1)/2-abs((dim_targetdata-1)/2-ii)),0]  "
      ],
      "metadata": {
        "id": "_ISSR_MmgBTx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction based on the limited number of fourier components"
      ],
      "metadata": {
        "id": "QpNmnNKJgbJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pred = []\n",
        "for ii in range(len(predfour)):\n",
        "  tijdsvector = []\n",
        "  for jj in range(len(predfour[0])):\n",
        "    tijdsvector.append(complex(predfour[ii,jj,0],predfour[ii,jj,1]))\n",
        "  pred.append(tijdsvector)\n",
        "predictie = np.real(sc.fft.ifft(pred))"
      ],
      "metadata": {
        "id": "XiqBSnDegeXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use neural network to estimate the difference between the fourierprediction and the real values"
      ],
      "metadata": {
        "id": "IsfpWqB2gpCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "errfour = []\n",
        "for ii in range(len(targetdata)):\n",
        "  errfour.append(targetdata[ii]-predictie[ii])"
      ],
      "metadata": {
        "id": "cUerv673gt8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "split in train and test dataset"
      ],
      "metadata": {
        "id": "cFpXXkD1hDGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indexenfourr = range(len(errfour))\n",
        "errfour_train, errfour_test, indexen_trainges, indexen_testges = train_test_split(errfour, indexenfourr, train_size=5000, test_size=177, random_state=333)"
      ],
      "metadata": {
        "id": "UXbYVuGxhFIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "make and train the neural network"
      ],
      "metadata": {
        "id": "QcXtsD1dhLdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array(errfour_train).reshape(len(errfour_train), dim_targetdata)\n",
        "params_input = keras.Input(shape=(dim_targetdata))\n",
        "encoder = tf.keras.layers.Dense(dim_latent_space,activation = 'tanh')(params_input)\n",
        "decoder = tf.keras.layers.Dense(dim_targetdata)(encoder)\n",
        "modelauto = keras.Model(inputs=params_input,outputs=decoder)\n",
        "modelauto.compile(optimizer='adam', loss='mse')\n",
        "modelauto.summary()\n",
        "hist = modelauto.fit(X,X,epochs=500,validation_split=0.2,batch_size=32)\n",
        "plt.semilogy(hist.history['loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "F850WGw5hLJF",
        "outputId": "a2a5af14-7380-4edc-9abd-0bf2545abce5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 99)]              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 5)                 500       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 99)                594       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,094\n",
            "Trainable params: 1,094\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/500\n",
            "125/125 [==============================] - 1s 3ms/step - loss: 5.1903 - val_loss: 0.0011\n",
            "Epoch 2/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1883 - val_loss: 0.0011\n",
            "Epoch 3/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.1864 - val_loss: 0.0011\n",
            "Epoch 4/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.1844 - val_loss: 0.0010\n",
            "Epoch 5/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.1811 - val_loss: 9.8385e-04\n",
            "Epoch 6/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1793 - val_loss: 9.4624e-04\n",
            "Epoch 7/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1773 - val_loss: 9.0916e-04\n",
            "Epoch 8/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.1754 - val_loss: 8.8314e-04\n",
            "Epoch 9/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1734 - val_loss: 8.6358e-04\n",
            "Epoch 10/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1715 - val_loss: 8.4241e-04\n",
            "Epoch 11/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1696 - val_loss: 8.2706e-04\n",
            "Epoch 12/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1676 - val_loss: 8.2865e-04\n",
            "Epoch 13/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1657 - val_loss: 7.9833e-04\n",
            "Epoch 14/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1637 - val_loss: 7.8426e-04\n",
            "Epoch 15/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1617 - val_loss: 7.7427e-04\n",
            "Epoch 16/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1597 - val_loss: 7.7660e-04\n",
            "Epoch 17/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1651 - val_loss: 7.4901e-04\n",
            "Epoch 18/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1631 - val_loss: 7.4184e-04\n",
            "Epoch 19/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1617 - val_loss: 8.1444e-04\n",
            "Epoch 20/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1593 - val_loss: 8.2057e-04\n",
            "Epoch 21/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1574 - val_loss: 8.0540e-04\n",
            "Epoch 22/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1554 - val_loss: 7.9610e-04\n",
            "Epoch 23/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1534 - val_loss: 7.8251e-04\n",
            "Epoch 24/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1515 - val_loss: 7.7075e-04\n",
            "Epoch 25/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1496 - val_loss: 7.5794e-04\n",
            "Epoch 26/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.1477 - val_loss: 7.4504e-04\n",
            "Epoch 27/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1457 - val_loss: 7.3422e-04\n",
            "Epoch 28/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1438 - val_loss: 7.2281e-04\n",
            "Epoch 29/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1418 - val_loss: 7.1442e-04\n",
            "Epoch 30/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1399 - val_loss: 6.9949e-04\n",
            "Epoch 31/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1653 - val_loss: 6.9056e-04\n",
            "Epoch 32/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1634 - val_loss: 7.0602e-04\n",
            "Epoch 33/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1354 - val_loss: 6.9472e-04\n",
            "Epoch 34/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1335 - val_loss: 6.8334e-04\n",
            "Epoch 35/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1316 - val_loss: 6.7187e-04\n",
            "Epoch 36/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1296 - val_loss: 6.6533e-04\n",
            "Epoch 37/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1276 - val_loss: 6.5179e-04\n",
            "Epoch 38/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1257 - val_loss: 6.4114e-04\n",
            "Epoch 39/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1238 - val_loss: 6.2670e-04\n",
            "Epoch 40/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1222 - val_loss: 6.2129e-04\n",
            "Epoch 41/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1200 - val_loss: 6.1074e-04\n",
            "Epoch 42/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1181 - val_loss: 6.0026e-04\n",
            "Epoch 43/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.1161 - val_loss: 5.9046e-04\n",
            "Epoch 44/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1142 - val_loss: 5.8051e-04\n",
            "Epoch 45/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1124 - val_loss: 5.7440e-04\n",
            "Epoch 46/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1105 - val_loss: 5.7601e-04\n",
            "Epoch 47/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1085 - val_loss: 5.5816e-04\n",
            "Epoch 48/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1066 - val_loss: 5.4454e-04\n",
            "Epoch 49/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1046 - val_loss: 5.3985e-04\n",
            "Epoch 50/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1027 - val_loss: 5.3516e-04\n",
            "Epoch 51/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1008 - val_loss: 5.3060e-04\n",
            "Epoch 52/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0989 - val_loss: 5.1854e-04\n",
            "Epoch 53/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.0970 - val_loss: 5.0661e-04\n",
            "Epoch 54/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0951 - val_loss: 5.0602e-04\n",
            "Epoch 55/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0932 - val_loss: 4.9752e-04\n",
            "Epoch 56/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0913 - val_loss: 4.9366e-04\n",
            "Epoch 57/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0894 - val_loss: 4.8376e-04\n",
            "Epoch 58/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0875 - val_loss: 5.5944e-04\n",
            "Epoch 59/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0857 - val_loss: 5.1536e-04\n",
            "Epoch 60/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1036 - val_loss: 4.9368e-04\n",
            "Epoch 61/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.1016 - val_loss: 4.7598e-04\n",
            "Epoch 62/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0997 - val_loss: 4.6788e-04\n",
            "Epoch 63/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0978 - val_loss: 4.5874e-04\n",
            "Epoch 64/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0959 - val_loss: 4.5187e-04\n",
            "Epoch 65/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0774 - val_loss: 4.3069e-04\n",
            "Epoch 66/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0755 - val_loss: 4.2065e-04\n",
            "Epoch 67/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0737 - val_loss: 4.1560e-04\n",
            "Epoch 68/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0719 - val_loss: 4.7941e-04\n",
            "Epoch 69/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0700 - val_loss: 5.7813e-04\n",
            "Epoch 70/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0681 - val_loss: 4.9196e-04\n",
            "Epoch 71/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.0864 - val_loss: 4.4923e-04\n",
            "Epoch 72/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0846 - val_loss: 6.5140e-04\n",
            "Epoch 73/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0827 - val_loss: 5.3688e-04\n",
            "Epoch 74/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0807 - val_loss: 4.8919e-04\n",
            "Epoch 75/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0788 - val_loss: 4.5961e-04\n",
            "Epoch 76/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0770 - val_loss: 4.3715e-04\n",
            "Epoch 77/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0751 - val_loss: 4.1750e-04\n",
            "Epoch 78/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0732 - val_loss: 4.1412e-04\n",
            "Epoch 79/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0713 - val_loss: 3.9849e-04\n",
            "Epoch 80/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0694 - val_loss: 3.7850e-04\n",
            "Epoch 81/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0676 - val_loss: 3.6406e-04\n",
            "Epoch 82/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0657 - val_loss: 3.6734e-04\n",
            "Epoch 83/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0638 - val_loss: 3.4911e-04\n",
            "Epoch 84/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0620 - val_loss: 3.4423e-04\n",
            "Epoch 85/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0601 - val_loss: 3.3520e-04\n",
            "Epoch 86/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0588 - val_loss: 7.0589e-04\n",
            "Epoch 87/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0565 - val_loss: 6.1723e-04\n",
            "Epoch 88/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0547 - val_loss: 5.2613e-04\n",
            "Epoch 89/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0528 - val_loss: 4.8941e-04\n",
            "Epoch 90/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0509 - val_loss: 4.5659e-04\n",
            "Epoch 91/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0491 - val_loss: 5.1713e-04\n",
            "Epoch 92/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0472 - val_loss: 4.7930e-04\n",
            "Epoch 93/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0454 - val_loss: 4.5798e-04\n",
            "Epoch 94/500\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 5.0377 - val_loss: 4.2892e-04\n",
            "Epoch 95/500\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 5.0358 - val_loss: 4.1181e-04\n",
            "Epoch 96/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.0340 - val_loss: 4.0525e-04\n",
            "Epoch 97/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0321 - val_loss: 3.7953e-04\n",
            "Epoch 98/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0303 - val_loss: 3.7103e-04\n",
            "Epoch 99/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0285 - val_loss: 3.6623e-04\n",
            "Epoch 100/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0267 - val_loss: 3.5175e-04\n",
            "Epoch 101/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.0248 - val_loss: 9.2299e-04\n",
            "Epoch 102/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.0323 - val_loss: 5.1430e-04\n",
            "Epoch 103/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0218 - val_loss: 4.6085e-04\n",
            "Epoch 104/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.0200 - val_loss: 4.2637e-04\n",
            "Epoch 105/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.0181 - val_loss: 4.1476e-04\n",
            "Epoch 106/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.0163 - val_loss: 3.8353e-04\n",
            "Epoch 107/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0144 - val_loss: 3.6832e-04\n",
            "Epoch 108/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0126 - val_loss: 3.4746e-04\n",
            "Epoch 109/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0108 - val_loss: 3.3974e-04\n",
            "Epoch 110/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0089 - val_loss: 3.2835e-04\n",
            "Epoch 111/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0071 - val_loss: 3.2569e-04\n",
            "Epoch 112/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.0052 - val_loss: 3.1309e-04\n",
            "Epoch 113/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0034 - val_loss: 3.1081e-04\n",
            "Epoch 114/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 5.0016 - val_loss: 3.1076e-04\n",
            "Epoch 115/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9998 - val_loss: 2.9921e-04\n",
            "Epoch 116/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9980 - val_loss: 3.5637e-04\n",
            "Epoch 117/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9962 - val_loss: 3.2869e-04\n",
            "Epoch 118/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9945 - val_loss: 5.3604e-04\n",
            "Epoch 119/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9927 - val_loss: 4.4022e-04\n",
            "Epoch 120/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9909 - val_loss: 3.8966e-04\n",
            "Epoch 121/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9891 - val_loss: 3.5632e-04\n",
            "Epoch 122/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9873 - val_loss: 3.3362e-04\n",
            "Epoch 123/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9855 - val_loss: 3.1593e-04\n",
            "Epoch 124/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9837 - val_loss: 3.0392e-04\n",
            "Epoch 125/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9827 - val_loss: 6.8561e-04\n",
            "Epoch 126/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9803 - val_loss: 5.0450e-04\n",
            "Epoch 127/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9785 - val_loss: 4.2573e-04\n",
            "Epoch 128/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9767 - val_loss: 3.8772e-04\n",
            "Epoch 129/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9749 - val_loss: 3.5498e-04\n",
            "Epoch 130/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9732 - val_loss: 3.3086e-04\n",
            "Epoch 131/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9714 - val_loss: 3.1979e-04\n",
            "Epoch 132/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9696 - val_loss: 3.0076e-04\n",
            "Epoch 133/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9678 - val_loss: 3.0208e-04\n",
            "Epoch 134/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9661 - val_loss: 2.9363e-04\n",
            "Epoch 135/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9643 - val_loss: 2.8404e-04\n",
            "Epoch 136/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9624 - val_loss: 2.7963e-04\n",
            "Epoch 137/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9607 - val_loss: 2.7384e-04\n",
            "Epoch 138/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9589 - val_loss: 2.8470e-04\n",
            "Epoch 139/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9571 - val_loss: 2.7401e-04\n",
            "Epoch 140/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9892 - val_loss: 7.3888e-04\n",
            "Epoch 141/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9542 - val_loss: 6.6455e-04\n",
            "Epoch 142/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9524 - val_loss: 6.0946e-04\n",
            "Epoch 143/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9506 - val_loss: 5.6299e-04\n",
            "Epoch 144/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9488 - val_loss: 5.8335e-04\n",
            "Epoch 145/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9471 - val_loss: 5.2691e-04\n",
            "Epoch 146/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9453 - val_loss: 4.9947e-04\n",
            "Epoch 147/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9435 - val_loss: 5.9568e-04\n",
            "Epoch 148/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9418 - val_loss: 5.6902e-04\n",
            "Epoch 149/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9400 - val_loss: 4.9718e-04\n",
            "Epoch 150/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9383 - val_loss: 5.0566e-04\n",
            "Epoch 151/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9366 - val_loss: 4.8702e-04\n",
            "Epoch 152/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9348 - val_loss: 4.9397e-04\n",
            "Epoch 153/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9331 - val_loss: 5.1135e-04\n",
            "Epoch 154/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9314 - val_loss: 4.7747e-04\n",
            "Epoch 155/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9296 - val_loss: 5.1489e-04\n",
            "Epoch 156/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9279 - val_loss: 4.7665e-04\n",
            "Epoch 157/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9261 - val_loss: 4.6027e-04\n",
            "Epoch 158/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 4.9245 - val_loss: 5.7171e-04\n",
            "Epoch 159/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 4.9227 - val_loss: 4.5836e-04\n",
            "Epoch 160/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 4.9210 - val_loss: 4.2728e-04\n",
            "Epoch 161/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9192 - val_loss: 4.2681e-04\n",
            "Epoch 162/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9174 - val_loss: 4.5905e-04\n",
            "Epoch 163/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9157 - val_loss: 4.7631e-04\n",
            "Epoch 164/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9140 - val_loss: 3.9789e-04\n",
            "Epoch 165/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9123 - val_loss: 3.9182e-04\n",
            "Epoch 166/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9105 - val_loss: 4.2978e-04\n",
            "Epoch 167/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9088 - val_loss: 3.8855e-04\n",
            "Epoch 168/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9071 - val_loss: 4.4436e-04\n",
            "Epoch 169/500\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 4.9055 - val_loss: 4.2595e-04\n",
            "Epoch 170/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9037 - val_loss: 3.7786e-04\n",
            "Epoch 171/500\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 4.9019 - val_loss: 3.2721e-04\n",
            "Epoch 172/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 4.9002 - val_loss: 3.2408e-04\n",
            "Epoch 173/500\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 4.8985 - val_loss: 3.3071e-04\n",
            "Epoch 174/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8968 - val_loss: 3.1382e-04\n",
            "Epoch 175/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8951 - val_loss: 2.9926e-04\n",
            "Epoch 176/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8937 - val_loss: 2.8804e-04\n",
            "Epoch 177/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8917 - val_loss: 3.0877e-04\n",
            "Epoch 178/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8900 - val_loss: 2.8957e-04\n",
            "Epoch 179/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8883 - val_loss: 2.8096e-04\n",
            "Epoch 180/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8867 - val_loss: 2.7420e-04\n",
            "Epoch 181/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8850 - val_loss: 2.8621e-04\n",
            "Epoch 182/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8833 - val_loss: 2.6696e-04\n",
            "Epoch 183/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9509 - val_loss: 4.7899e-04\n",
            "Epoch 184/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9857 - val_loss: 3.4918e-04\n",
            "Epoch 185/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9837 - val_loss: 3.3162e-04\n",
            "Epoch 186/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9819 - val_loss: 3.6401e-04\n",
            "Epoch 187/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 4.9800 - val_loss: 3.2618e-04\n",
            "Epoch 188/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9782 - val_loss: 3.6079e-04\n",
            "Epoch 189/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9763 - val_loss: 3.2148e-04\n",
            "Epoch 190/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9745 - val_loss: 3.1726e-04\n",
            "Epoch 191/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9727 - val_loss: 3.1856e-04\n",
            "Epoch 192/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9709 - val_loss: 3.1813e-04\n",
            "Epoch 193/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9691 - val_loss: 3.3130e-04\n",
            "Epoch 194/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9673 - val_loss: 3.3057e-04\n",
            "Epoch 195/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9655 - val_loss: 3.1136e-04\n",
            "Epoch 196/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9637 - val_loss: 3.0417e-04\n",
            "Epoch 197/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9619 - val_loss: 3.0261e-04\n",
            "Epoch 198/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9601 - val_loss: 3.4348e-04\n",
            "Epoch 199/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9584 - val_loss: 3.0124e-04\n",
            "Epoch 200/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9566 - val_loss: 3.0052e-04\n",
            "Epoch 201/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9548 - val_loss: 2.9977e-04\n",
            "Epoch 202/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9531 - val_loss: 3.0942e-04\n",
            "Epoch 203/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 4.9513 - val_loss: 2.9111e-04\n",
            "Epoch 204/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9496 - val_loss: 3.0126e-04\n",
            "Epoch 205/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9478 - val_loss: 2.9134e-04\n",
            "Epoch 206/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9460 - val_loss: 2.8828e-04\n",
            "Epoch 207/500\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 4.9443 - val_loss: 2.8847e-04\n",
            "Epoch 208/500\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 4.9426 - val_loss: 2.9740e-04\n",
            "Epoch 209/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9408 - val_loss: 2.7773e-04\n",
            "Epoch 210/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9391 - val_loss: 3.1260e-04\n",
            "Epoch 211/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9374 - val_loss: 2.7314e-04\n",
            "Epoch 212/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9356 - val_loss: 2.8442e-04\n",
            "Epoch 213/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9338 - val_loss: 2.8555e-04\n",
            "Epoch 214/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9321 - val_loss: 2.8153e-04\n",
            "Epoch 215/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9303 - val_loss: 2.6622e-04\n",
            "Epoch 216/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9286 - val_loss: 2.6208e-04\n",
            "Epoch 217/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9268 - val_loss: 2.5754e-04\n",
            "Epoch 218/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9251 - val_loss: 2.5398e-04\n",
            "Epoch 219/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9234 - val_loss: 2.5244e-04\n",
            "Epoch 220/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9217 - val_loss: 2.5036e-04\n",
            "Epoch 221/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9200 - val_loss: 2.5302e-04\n",
            "Epoch 222/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9183 - val_loss: 2.6170e-04\n",
            "Epoch 223/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.9166 - val_loss: 2.3945e-04\n",
            "Epoch 224/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9149 - val_loss: 2.5178e-04\n",
            "Epoch 225/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9132 - val_loss: 2.5661e-04\n",
            "Epoch 226/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9115 - val_loss: 3.5276e-04\n",
            "Epoch 227/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9097 - val_loss: 2.3547e-04\n",
            "Epoch 228/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 4.9080 - val_loss: 2.2851e-04\n",
            "Epoch 229/500\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 4.9063 - val_loss: 2.1999e-04\n",
            "Epoch 230/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9047 - val_loss: 2.3897e-04\n",
            "Epoch 231/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9029 - val_loss: 2.3178e-04\n",
            "Epoch 232/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9018 - val_loss: 2.5813e-04\n",
            "Epoch 233/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8995 - val_loss: 2.7661e-04\n",
            "Epoch 234/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8980 - val_loss: 2.6639e-04\n",
            "Epoch 235/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8962 - val_loss: 2.5711e-04\n",
            "Epoch 236/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 4.8945 - val_loss: 2.4149e-04\n",
            "Epoch 237/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 4.8928 - val_loss: 2.3707e-04\n",
            "Epoch 238/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 4.8911 - val_loss: 2.3398e-04\n",
            "Epoch 239/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 4.8894 - val_loss: 2.2566e-04\n",
            "Epoch 240/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 4.8877 - val_loss: 2.1316e-04\n",
            "Epoch 241/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 4.8859 - val_loss: 2.1101e-04\n",
            "Epoch 242/500\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 4.8842 - val_loss: 2.6136e-04\n",
            "Epoch 243/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8826 - val_loss: 2.0277e-04\n",
            "Epoch 244/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8809 - val_loss: 2.0701e-04\n",
            "Epoch 245/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8791 - val_loss: 2.0094e-04\n",
            "Epoch 246/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8774 - val_loss: 1.9835e-04\n",
            "Epoch 247/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8758 - val_loss: 1.9419e-04\n",
            "Epoch 248/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8741 - val_loss: 2.0185e-04\n",
            "Epoch 249/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8725 - val_loss: 1.9511e-04\n",
            "Epoch 250/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8708 - val_loss: 2.1135e-04\n",
            "Epoch 251/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8691 - val_loss: 2.6470e-04\n",
            "Epoch 252/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8675 - val_loss: 2.0074e-04\n",
            "Epoch 253/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8657 - val_loss: 1.9345e-04\n",
            "Epoch 254/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8641 - val_loss: 1.9719e-04\n",
            "Epoch 255/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8624 - val_loss: 1.8594e-04\n",
            "Epoch 256/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8607 - val_loss: 2.0867e-04\n",
            "Epoch 257/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8590 - val_loss: 1.9473e-04\n",
            "Epoch 258/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8574 - val_loss: 1.8020e-04\n",
            "Epoch 259/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8557 - val_loss: 1.8793e-04\n",
            "Epoch 260/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8541 - val_loss: 1.9451e-04\n",
            "Epoch 261/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 4.8524 - val_loss: 1.8207e-04\n",
            "Epoch 262/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9199 - val_loss: 3.4528e-04\n",
            "Epoch 263/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 4.8494 - val_loss: 2.9153e-04\n",
            "Epoch 264/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 4.8478 - val_loss: 2.6282e-04\n",
            "Epoch 265/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8461 - val_loss: 2.5681e-04\n",
            "Epoch 266/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8445 - val_loss: 2.3544e-04\n",
            "Epoch 267/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8428 - val_loss: 2.2904e-04\n",
            "Epoch 268/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8412 - val_loss: 2.2441e-04\n",
            "Epoch 269/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8395 - val_loss: 2.2631e-04\n",
            "Epoch 270/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8378 - val_loss: 2.1912e-04\n",
            "Epoch 271/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8362 - val_loss: 2.3977e-04\n",
            "Epoch 272/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8345 - val_loss: 2.1866e-04\n",
            "Epoch 273/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8329 - val_loss: 2.0889e-04\n",
            "Epoch 274/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8312 - val_loss: 2.1636e-04\n",
            "Epoch 275/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8296 - val_loss: 2.1925e-04\n",
            "Epoch 276/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8280 - val_loss: 2.0612e-04\n",
            "Epoch 277/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8263 - val_loss: 2.1033e-04\n",
            "Epoch 278/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8248 - val_loss: 2.0071e-04\n",
            "Epoch 279/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8231 - val_loss: 1.9872e-04\n",
            "Epoch 280/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8215 - val_loss: 2.4800e-04\n",
            "Epoch 281/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8199 - val_loss: 2.1387e-04\n",
            "Epoch 282/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8182 - val_loss: 1.9807e-04\n",
            "Epoch 283/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8166 - val_loss: 1.9828e-04\n",
            "Epoch 284/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8149 - val_loss: 2.0125e-04\n",
            "Epoch 285/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8133 - val_loss: 2.2796e-04\n",
            "Epoch 286/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8117 - val_loss: 2.0486e-04\n",
            "Epoch 287/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8100 - val_loss: 2.0034e-04\n",
            "Epoch 288/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8084 - val_loss: 2.4989e-04\n",
            "Epoch 289/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8068 - val_loss: 1.9223e-04\n",
            "Epoch 290/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8052 - val_loss: 1.9420e-04\n",
            "Epoch 291/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8036 - val_loss: 2.0716e-04\n",
            "Epoch 292/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8020 - val_loss: 2.1006e-04\n",
            "Epoch 293/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8004 - val_loss: 2.0352e-04\n",
            "Epoch 294/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7988 - val_loss: 2.2092e-04\n",
            "Epoch 295/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7972 - val_loss: 2.1755e-04\n",
            "Epoch 296/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7955 - val_loss: 1.9927e-04\n",
            "Epoch 297/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7939 - val_loss: 2.0886e-04\n",
            "Epoch 298/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7924 - val_loss: 2.0175e-04\n",
            "Epoch 299/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7908 - val_loss: 1.9850e-04\n",
            "Epoch 300/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7892 - val_loss: 1.8520e-04\n",
            "Epoch 301/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7876 - val_loss: 2.3472e-04\n",
            "Epoch 302/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7860 - val_loss: 2.0174e-04\n",
            "Epoch 303/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7844 - val_loss: 1.9130e-04\n",
            "Epoch 304/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7829 - val_loss: 1.8306e-04\n",
            "Epoch 305/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7813 - val_loss: 2.3399e-04\n",
            "Epoch 306/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7797 - val_loss: 1.9648e-04\n",
            "Epoch 307/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7781 - val_loss: 1.8695e-04\n",
            "Epoch 308/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7764 - val_loss: 1.9905e-04\n",
            "Epoch 309/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7748 - val_loss: 1.7937e-04\n",
            "Epoch 310/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 4.7732 - val_loss: 1.8844e-04\n",
            "Epoch 311/500\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 4.7716 - val_loss: 2.2498e-04\n",
            "Epoch 312/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 4.7700 - val_loss: 2.2679e-04\n",
            "Epoch 313/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 4.7684 - val_loss: 2.0894e-04\n",
            "Epoch 314/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7669 - val_loss: 2.2530e-04\n",
            "Epoch 315/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7653 - val_loss: 1.8264e-04\n",
            "Epoch 316/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7637 - val_loss: 1.9363e-04\n",
            "Epoch 317/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7622 - val_loss: 2.1085e-04\n",
            "Epoch 318/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7606 - val_loss: 1.7697e-04\n",
            "Epoch 319/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7590 - val_loss: 1.8833e-04\n",
            "Epoch 320/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7574 - val_loss: 2.5266e-04\n",
            "Epoch 321/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7558 - val_loss: 1.9013e-04\n",
            "Epoch 322/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7543 - val_loss: 1.7793e-04\n",
            "Epoch 323/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7527 - val_loss: 1.6515e-04\n",
            "Epoch 324/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7512 - val_loss: 1.7164e-04\n",
            "Epoch 325/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7496 - val_loss: 2.8782e-04\n",
            "Epoch 326/500\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 4.7481 - val_loss: 2.1398e-04\n",
            "Epoch 327/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 4.7465 - val_loss: 1.7195e-04\n",
            "Epoch 328/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7450 - val_loss: 1.5682e-04\n",
            "Epoch 329/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7434 - val_loss: 1.6616e-04\n",
            "Epoch 330/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8047 - val_loss: 3.3536e-04\n",
            "Epoch 331/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 4.8730 - val_loss: 2.4014e-04\n",
            "Epoch 332/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 4.8711 - val_loss: 2.2086e-04\n",
            "Epoch 333/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8693 - val_loss: 2.7888e-04\n",
            "Epoch 334/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8676 - val_loss: 2.2788e-04\n",
            "Epoch 335/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8658 - val_loss: 2.0055e-04\n",
            "Epoch 336/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8640 - val_loss: 2.1384e-04\n",
            "Epoch 337/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8623 - val_loss: 4.4079e-04\n",
            "Epoch 338/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8605 - val_loss: 2.7287e-04\n",
            "Epoch 339/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8588 - val_loss: 2.0377e-04\n",
            "Epoch 340/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8572 - val_loss: 1.8570e-04\n",
            "Epoch 341/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8555 - val_loss: 1.9204e-04\n",
            "Epoch 342/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8538 - val_loss: 2.0145e-04\n",
            "Epoch 343/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8521 - val_loss: 2.1353e-04\n",
            "Epoch 344/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8504 - val_loss: 1.8999e-04\n",
            "Epoch 345/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8487 - val_loss: 2.6304e-04\n",
            "Epoch 346/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8471 - val_loss: 2.3639e-04\n",
            "Epoch 347/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8455 - val_loss: 1.6753e-04\n",
            "Epoch 348/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8438 - val_loss: 1.5974e-04\n",
            "Epoch 349/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8421 - val_loss: 1.7540e-04\n",
            "Epoch 350/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8405 - val_loss: 1.5973e-04\n",
            "Epoch 351/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8388 - val_loss: 1.6180e-04\n",
            "Epoch 352/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8372 - val_loss: 2.3085e-04\n",
            "Epoch 353/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8355 - val_loss: 1.7155e-04\n",
            "Epoch 354/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8340 - val_loss: 1.4866e-04\n",
            "Epoch 355/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8323 - val_loss: 1.4844e-04\n",
            "Epoch 356/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8306 - val_loss: 1.6517e-04\n",
            "Epoch 357/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8290 - val_loss: 1.5388e-04\n",
            "Epoch 358/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 5.0280 - val_loss: 1.6828e-04\n",
            "Epoch 359/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8218 - val_loss: 1.6593e-04\n",
            "Epoch 360/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8203 - val_loss: 5.8027e-04\n",
            "Epoch 361/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8186 - val_loss: 1.8032e-04\n",
            "Epoch 362/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8170 - val_loss: 1.7192e-04\n",
            "Epoch 363/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8154 - val_loss: 1.8755e-04\n",
            "Epoch 364/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8138 - val_loss: 2.2210e-04\n",
            "Epoch 365/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8121 - val_loss: 1.7618e-04\n",
            "Epoch 366/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8105 - val_loss: 1.7223e-04\n",
            "Epoch 367/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8089 - val_loss: 1.5348e-04\n",
            "Epoch 368/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8075 - val_loss: 1.6467e-04\n",
            "Epoch 369/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8057 - val_loss: 1.5400e-04\n",
            "Epoch 370/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8040 - val_loss: 1.6962e-04\n",
            "Epoch 371/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.8030 - val_loss: 1.4373e-04\n",
            "Epoch 372/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.8008 - val_loss: 1.4275e-04\n",
            "Epoch 373/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7992 - val_loss: 1.5606e-04\n",
            "Epoch 374/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7977 - val_loss: 1.5217e-04\n",
            "Epoch 375/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7961 - val_loss: 1.8160e-04\n",
            "Epoch 376/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7945 - val_loss: 1.5328e-04\n",
            "Epoch 377/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7929 - val_loss: 1.5663e-04\n",
            "Epoch 378/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7913 - val_loss: 1.3988e-04\n",
            "Epoch 379/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7897 - val_loss: 1.4667e-04\n",
            "Epoch 380/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.9916 - val_loss: 0.0027\n",
            "Epoch 381/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7879 - val_loss: 0.0016\n",
            "Epoch 382/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7858 - val_loss: 8.4745e-04\n",
            "Epoch 383/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7841 - val_loss: 7.9373e-04\n",
            "Epoch 384/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7825 - val_loss: 6.7793e-04\n",
            "Epoch 385/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7808 - val_loss: 7.5086e-04\n",
            "Epoch 386/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7793 - val_loss: 6.3741e-04\n",
            "Epoch 387/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7777 - val_loss: 5.6942e-04\n",
            "Epoch 388/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7761 - val_loss: 7.2686e-04\n",
            "Epoch 389/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7745 - val_loss: 5.8554e-04\n",
            "Epoch 390/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7729 - val_loss: 5.6948e-04\n",
            "Epoch 391/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7713 - val_loss: 5.7004e-04\n",
            "Epoch 392/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7697 - val_loss: 5.2375e-04\n",
            "Epoch 393/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7681 - val_loss: 4.5383e-04\n",
            "Epoch 394/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7665 - val_loss: 4.9377e-04\n",
            "Epoch 395/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7650 - val_loss: 4.7715e-04\n",
            "Epoch 396/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7634 - val_loss: 4.5411e-04\n",
            "Epoch 397/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7618 - val_loss: 4.5912e-04\n",
            "Epoch 398/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7603 - val_loss: 4.1868e-04\n",
            "Epoch 399/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7587 - val_loss: 4.0406e-04\n",
            "Epoch 400/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7571 - val_loss: 4.4566e-04\n",
            "Epoch 401/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 4.7555 - val_loss: 4.0632e-04\n",
            "Epoch 402/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 4.7540 - val_loss: 3.8583e-04\n",
            "Epoch 403/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7524 - val_loss: 4.0418e-04\n",
            "Epoch 404/500\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 4.7509 - val_loss: 3.7522e-04\n",
            "Epoch 405/500\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 4.7494 - val_loss: 4.5538e-04\n",
            "Epoch 406/500\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 4.7478 - val_loss: 3.0441e-04\n",
            "Epoch 407/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7462 - val_loss: 3.9814e-04\n",
            "Epoch 408/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 4.7447 - val_loss: 3.2984e-04\n",
            "Epoch 409/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 4.7431 - val_loss: 2.9057e-04\n",
            "Epoch 410/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7425 - val_loss: 2.9818e-04\n",
            "Epoch 411/500\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 4.7401 - val_loss: 2.6968e-04\n",
            "Epoch 412/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7385 - val_loss: 2.6860e-04\n",
            "Epoch 413/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7369 - val_loss: 2.8489e-04\n",
            "Epoch 414/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7354 - val_loss: 2.4668e-04\n",
            "Epoch 415/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7338 - val_loss: 3.3043e-04\n",
            "Epoch 416/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7322 - val_loss: 2.5730e-04\n",
            "Epoch 417/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7306 - val_loss: 2.9151e-04\n",
            "Epoch 418/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7291 - val_loss: 2.4542e-04\n",
            "Epoch 419/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7275 - val_loss: 2.1330e-04\n",
            "Epoch 420/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7260 - val_loss: 2.1971e-04\n",
            "Epoch 421/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7245 - val_loss: 2.5330e-04\n",
            "Epoch 422/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7229 - val_loss: 2.0916e-04\n",
            "Epoch 423/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7214 - val_loss: 2.3873e-04\n",
            "Epoch 424/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7199 - val_loss: 2.2282e-04\n",
            "Epoch 425/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7184 - val_loss: 2.0777e-04\n",
            "Epoch 426/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7168 - val_loss: 2.6062e-04\n",
            "Epoch 427/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7153 - val_loss: 2.1670e-04\n",
            "Epoch 428/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7138 - val_loss: 2.9829e-04\n",
            "Epoch 429/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7123 - val_loss: 2.3829e-04\n",
            "Epoch 430/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7107 - val_loss: 2.0970e-04\n",
            "Epoch 431/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7092 - val_loss: 2.0616e-04\n",
            "Epoch 432/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7076 - val_loss: 2.0653e-04\n",
            "Epoch 433/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7061 - val_loss: 2.0974e-04\n",
            "Epoch 434/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7052 - val_loss: 0.0011\n",
            "Epoch 435/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7035 - val_loss: 6.9209e-04\n",
            "Epoch 436/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.7018 - val_loss: 5.6728e-04\n",
            "Epoch 437/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.7002 - val_loss: 5.1946e-04\n",
            "Epoch 438/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6986 - val_loss: 2.9893e-04\n",
            "Epoch 439/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6971 - val_loss: 2.9190e-04\n",
            "Epoch 440/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6956 - val_loss: 3.5308e-04\n",
            "Epoch 441/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6941 - val_loss: 3.2220e-04\n",
            "Epoch 442/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6926 - val_loss: 2.2901e-04\n",
            "Epoch 443/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6910 - val_loss: 2.2664e-04\n",
            "Epoch 444/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.6895 - val_loss: 2.2984e-04\n",
            "Epoch 445/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.6880 - val_loss: 2.1720e-04\n",
            "Epoch 446/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.6865 - val_loss: 2.4730e-04\n",
            "Epoch 447/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6850 - val_loss: 2.3647e-04\n",
            "Epoch 448/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6834 - val_loss: 2.4618e-04\n",
            "Epoch 449/500\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 4.6820 - val_loss: 2.7700e-04\n",
            "Epoch 450/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6805 - val_loss: 2.2591e-04\n",
            "Epoch 451/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6789 - val_loss: 2.1831e-04\n",
            "Epoch 452/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6774 - val_loss: 2.4951e-04\n",
            "Epoch 453/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6759 - val_loss: 2.2202e-04\n",
            "Epoch 454/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6744 - val_loss: 2.1978e-04\n",
            "Epoch 455/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6729 - val_loss: 2.2643e-04\n",
            "Epoch 456/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6714 - val_loss: 2.3437e-04\n",
            "Epoch 457/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6699 - val_loss: 2.4285e-04\n",
            "Epoch 458/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.6683 - val_loss: 2.3410e-04\n",
            "Epoch 459/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6668 - val_loss: 2.3124e-04\n",
            "Epoch 460/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6654 - val_loss: 2.3455e-04\n",
            "Epoch 461/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6639 - val_loss: 2.4067e-04\n",
            "Epoch 462/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.6624 - val_loss: 2.2941e-04\n",
            "Epoch 463/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6609 - val_loss: 2.2337e-04\n",
            "Epoch 464/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.6595 - val_loss: 2.5838e-04\n",
            "Epoch 465/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6580 - val_loss: 2.2279e-04\n",
            "Epoch 466/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6565 - val_loss: 2.2885e-04\n",
            "Epoch 467/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6550 - val_loss: 2.6198e-04\n",
            "Epoch 468/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6535 - val_loss: 2.4546e-04\n",
            "Epoch 469/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6520 - val_loss: 2.2881e-04\n",
            "Epoch 470/500\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 4.6505 - val_loss: 2.3433e-04\n",
            "Epoch 471/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.6490 - val_loss: 3.0591e-04\n",
            "Epoch 472/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6484 - val_loss: 2.5631e-04\n",
            "Epoch 473/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6462 - val_loss: 2.3613e-04\n",
            "Epoch 474/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.6447 - val_loss: 2.2215e-04\n",
            "Epoch 475/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.6432 - val_loss: 3.2339e-04\n",
            "Epoch 476/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6418 - val_loss: 3.0105e-04\n",
            "Epoch 477/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6403 - val_loss: 2.1426e-04\n",
            "Epoch 478/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6388 - val_loss: 2.2713e-04\n",
            "Epoch 479/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6373 - val_loss: 2.7730e-04\n",
            "Epoch 480/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6358 - val_loss: 2.0544e-04\n",
            "Epoch 481/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.6344 - val_loss: 2.0621e-04\n",
            "Epoch 482/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6329 - val_loss: 1.9717e-04\n",
            "Epoch 483/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6315 - val_loss: 1.9264e-04\n",
            "Epoch 484/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6300 - val_loss: 2.6829e-04\n",
            "Epoch 485/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6285 - val_loss: 2.2031e-04\n",
            "Epoch 486/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6271 - val_loss: 1.8652e-04\n",
            "Epoch 487/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6256 - val_loss: 1.7915e-04\n",
            "Epoch 488/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6241 - val_loss: 1.6858e-04\n",
            "Epoch 489/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.6227 - val_loss: 1.6939e-04\n",
            "Epoch 490/500\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 4.6212 - val_loss: 1.7701e-04\n",
            "Epoch 491/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6198 - val_loss: 1.6482e-04\n",
            "Epoch 492/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6184 - val_loss: 1.8440e-04\n",
            "Epoch 493/500\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 4.6169 - val_loss: 1.9458e-04\n",
            "Epoch 494/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6155 - val_loss: 1.9277e-04\n",
            "Epoch 495/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6140 - val_loss: 1.9107e-04\n",
            "Epoch 496/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6126 - val_loss: 1.4695e-04\n",
            "Epoch 497/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6111 - val_loss: 1.4039e-04\n",
            "Epoch 498/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6096 - val_loss: 1.4339e-04\n",
            "Epoch 499/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6082 - val_loss: 1.5533e-04\n",
            "Epoch 500/500\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4.6067 - val_loss: 1.3649e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f340fc8f710>]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediction based on limited number of fourier components and predicted difference"
      ],
      "metadata": {
        "id": "U7AadO2Jhfo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = np.array(errfour).reshape(len(errfour), dim_targetdata)\n",
        "test_output = np.array(modelauto.predict(test_input, verbose=0)) # = echt - fourier"
      ],
      "metadata": {
        "id": "uuhXocmShus5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uiteindelijkeschatting = test_output + predictie"
      ],
      "metadata": {
        "id": "sm_beURKhgRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prediction of the parameters"
      ],
      "metadata": {
        "id": "1t9u9HWOhymf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fourtopred = np.concatenate([predfour[:,0:5,0],predfour[:,1:4,1]],axis = 1) # 1:4 because first one is always 0\n",
        "#obtain the hidden vectors\n",
        "Xen = np.array(errfour).reshape(len(errfour), dim_targetdata)\n",
        "layer_output = modelauto.get_layer('dense').output #dense can need an extra number, depending on how much the algorithm is performed\n",
        "intermediate_model=tf.keras.models.Model(inputs=params_input,outputs=layer_output)\n",
        "tussen=intermediate_model.predict(Xen) # = hidden vectors!\n",
        "tevoorspellen = np.concatenate([fourtopred,tussen],axis = 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QkWZoZnch0lW",
        "outputId": "f2797438-2d33-4ee3-9aee-152b64e225a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "230/230 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "indexen = range(len(features))\n",
        "X_train_four, X_test_four, indexen_train_four, indexen_test_four = train_test_split(features, indexen, train_size=5000, test_size=177, random_state=333)\n",
        "training_y_four = fourtopred[indexen_train_four]\n",
        "y_test_four = fourtopred[indexen_test_four]\n",
        "\n",
        "X = np.array(X_train_four).reshape(len(X_train_four), dim_modinfo)\n",
        "\n",
        "Y = np.array(training_y_four).reshape(len(training_y_four), 8)\n",
        "#using a standardscaler here is advised"
      ],
      "metadata": {
        "id": "J9pXpZTLii0q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Make and train the neural network"
      ],
      "metadata": {
        "id": "HuD7mQsWjRNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params_input = keras.Input(shape=(dim_modinfo)) #less inputparameters can be used in this step\n",
        "dense = tf.keras.layers.Dense(50,activation = 'relu')(params_input)\n",
        "dense1 = tf.keras.layers.Dense(40,activation = 'relu')(dense)\n",
        "dense2 = tf.keras.layers.Dense(30,activation = 'relu')(dense1)\n",
        "dense3 = tf.keras.layers.Dense(15,activation = 'relu')(dense2)\n",
        "dense4 = tf.keras.layers.Dense(30,activation = 'relu')(dense2)\n",
        "dense45 = tf.keras.layers.Dense(40,activation = 'relu')(dense4)\n",
        "dense42 = tf.keras.layers.Dense(25,activation = 'relu')(dense45)\n",
        "dense5 = tf.keras.layers.Dense(relim[0]+imlim[0]-1)(dense42) #-1 since '1:4 because first one is always 0'\n",
        "modelfour = keras.Model(inputs=params_input,outputs=dense5)\n",
        "modelfour.compile(optimizer='adam', loss='mse')\n",
        "modelfour.summary()\n",
        "hist = modelfour.fit(X,Y,epochs=1000,validation_split=0.2,batch_size=32) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pSfgIEsajTdq",
        "outputId": "d6fe7013-9c34-4cc8-e199-df98c643b378"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_4 (InputLayer)        [(None, 103)]             0         \n",
            "                                                                 \n",
            " dense_18 (Dense)            (None, 50)                5200      \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 40)                2040      \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 30)                1230      \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 30)                930       \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 40)                1240      \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 25)                1025      \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 8)                 208       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,873\n",
            "Trainable params: 11,873\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/1000\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1809.8125 - val_loss: 28.1054\n",
            "Epoch 2/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1808.9054 - val_loss: 27.8533\n",
            "Epoch 3/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1808.6160 - val_loss: 27.8304\n",
            "Epoch 4/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1807.6729 - val_loss: 27.7773\n",
            "Epoch 5/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1807.7332 - val_loss: 27.3548\n",
            "Epoch 6/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1806.4348 - val_loss: 25.5894\n",
            "Epoch 7/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1806.2977 - val_loss: 21.7599\n",
            "Epoch 8/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1802.5269 - val_loss: 17.5269\n",
            "Epoch 9/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1800.2961 - val_loss: 17.4567\n",
            "Epoch 10/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1797.5024 - val_loss: 18.2287\n",
            "Epoch 11/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1796.1530 - val_loss: 16.9158\n",
            "Epoch 12/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1797.7985 - val_loss: 21.5396\n",
            "Epoch 13/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1793.2118 - val_loss: 17.1890\n",
            "Epoch 14/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1798.4204 - val_loss: 15.8202\n",
            "Epoch 15/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1798.6969 - val_loss: 17.2907\n",
            "Epoch 16/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1797.8466 - val_loss: 18.6486\n",
            "Epoch 17/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1795.7506 - val_loss: 14.5203\n",
            "Epoch 18/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1793.3362 - val_loss: 14.8822\n",
            "Epoch 19/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1795.4521 - val_loss: 14.5454\n",
            "Epoch 20/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1793.3452 - val_loss: 14.0526\n",
            "Epoch 21/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1793.6611 - val_loss: 14.2902\n",
            "Epoch 22/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1792.6257 - val_loss: 19.7462\n",
            "Epoch 23/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1791.7593 - val_loss: 14.3073\n",
            "Epoch 24/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1793.4548 - val_loss: 20.1891\n",
            "Epoch 25/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1790.1401 - val_loss: 19.4985\n",
            "Epoch 26/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1789.3544 - val_loss: 18.7364\n",
            "Epoch 27/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1788.8401 - val_loss: 20.5797\n",
            "Epoch 28/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1789.5413 - val_loss: 15.7373\n",
            "Epoch 29/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1787.0006 - val_loss: 33.3622\n",
            "Epoch 30/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1800.5917 - val_loss: 28.1401\n",
            "Epoch 31/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1790.2628 - val_loss: 15.7548\n",
            "Epoch 32/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1786.7650 - val_loss: 13.9467\n",
            "Epoch 33/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1786.3558 - val_loss: 19.9652\n",
            "Epoch 34/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1785.0994 - val_loss: 17.1364\n",
            "Epoch 35/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1783.4744 - val_loss: 32.2106\n",
            "Epoch 36/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1780.9481 - val_loss: 13.9349\n",
            "Epoch 37/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1793.7003 - val_loss: 18.5267\n",
            "Epoch 38/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1786.8082 - val_loss: 15.1014\n",
            "Epoch 39/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1781.9407 - val_loss: 12.8451\n",
            "Epoch 40/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1785.0388 - val_loss: 13.4867\n",
            "Epoch 41/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1779.7037 - val_loss: 27.7932\n",
            "Epoch 42/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1780.6991 - val_loss: 18.3040\n",
            "Epoch 43/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1776.4847 - val_loss: 30.8163\n",
            "Epoch 44/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1777.2333 - val_loss: 10.1344\n",
            "Epoch 45/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1792.2699 - val_loss: 12.5489\n",
            "Epoch 46/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1773.9403 - val_loss: 9.6511\n",
            "Epoch 47/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1773.5126 - val_loss: 34.0961\n",
            "Epoch 48/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1779.1312 - val_loss: 36.3311\n",
            "Epoch 49/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1765.1956 - val_loss: 11.2243\n",
            "Epoch 50/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1797.9154 - val_loss: 44.8797\n",
            "Epoch 51/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1787.4204 - val_loss: 32.2586\n",
            "Epoch 52/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1773.2007 - val_loss: 26.5624\n",
            "Epoch 53/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1773.9119 - val_loss: 25.9082\n",
            "Epoch 54/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1759.3152 - val_loss: 11.3573\n",
            "Epoch 55/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1782.1804 - val_loss: 59.9499\n",
            "Epoch 56/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1763.7981 - val_loss: 15.9446\n",
            "Epoch 57/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1776.4679 - val_loss: 18.3448\n",
            "Epoch 58/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1766.3386 - val_loss: 31.9980\n",
            "Epoch 59/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1752.0831 - val_loss: 11.7812\n",
            "Epoch 60/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1773.2817 - val_loss: 24.5260\n",
            "Epoch 61/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1757.7194 - val_loss: 36.4726\n",
            "Epoch 62/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1755.5829 - val_loss: 54.5156\n",
            "Epoch 63/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1746.5856 - val_loss: 14.3865\n",
            "Epoch 64/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1776.8038 - val_loss: 179.5328\n",
            "Epoch 65/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1746.5922 - val_loss: 14.6815\n",
            "Epoch 66/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1770.4895 - val_loss: 17.8802\n",
            "Epoch 67/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1769.0020 - val_loss: 41.7740\n",
            "Epoch 68/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1770.5228 - val_loss: 33.0118\n",
            "Epoch 69/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1752.1907 - val_loss: 54.3840\n",
            "Epoch 70/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1733.9592 - val_loss: 13.4486\n",
            "Epoch 71/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1756.4495 - val_loss: 64.8654\n",
            "Epoch 72/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1735.2981 - val_loss: 16.8244\n",
            "Epoch 73/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1775.3872 - val_loss: 25.8554\n",
            "Epoch 74/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1740.3136 - val_loss: 16.7701\n",
            "Epoch 75/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1746.3009 - val_loss: 35.4029\n",
            "Epoch 76/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1746.6764 - val_loss: 73.8773\n",
            "Epoch 77/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1747.2062 - val_loss: 25.5474\n",
            "Epoch 78/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1753.3779 - val_loss: 32.4944\n",
            "Epoch 79/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1733.8521 - val_loss: 69.3676\n",
            "Epoch 80/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1739.2782 - val_loss: 62.9677\n",
            "Epoch 81/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1696.3799 - val_loss: 9.4282\n",
            "Epoch 82/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1799.0186 - val_loss: 22.5333\n",
            "Epoch 83/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1734.1975 - val_loss: 74.0179\n",
            "Epoch 84/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1727.3978 - val_loss: 27.7628\n",
            "Epoch 85/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1710.8546 - val_loss: 12.4091\n",
            "Epoch 86/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1741.6140 - val_loss: 16.4351\n",
            "Epoch 87/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1812.6869 - val_loss: 37.4616\n",
            "Epoch 88/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1727.0801 - val_loss: 44.8973\n",
            "Epoch 89/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1718.6300 - val_loss: 32.4078\n",
            "Epoch 90/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1701.5217 - val_loss: 16.7333\n",
            "Epoch 91/1000\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1714.2366 - val_loss: 206.5444\n",
            "Epoch 92/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1725.6281 - val_loss: 46.8033\n",
            "Epoch 93/1000\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1714.1072 - val_loss: 28.0419\n",
            "Epoch 94/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1708.9128 - val_loss: 229.2555\n",
            "Epoch 95/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1741.2418 - val_loss: 31.7710\n",
            "Epoch 96/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1705.5667 - val_loss: 60.8609\n",
            "Epoch 97/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1699.1923 - val_loss: 287.7994\n",
            "Epoch 98/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1767.6708 - val_loss: 120.9550\n",
            "Epoch 99/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1695.1676 - val_loss: 22.5356\n",
            "Epoch 100/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1683.1970 - val_loss: 142.5358\n",
            "Epoch 101/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1702.9635 - val_loss: 42.1656\n",
            "Epoch 102/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1656.9357 - val_loss: 11.1783\n",
            "Epoch 103/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1704.7620 - val_loss: 143.2717\n",
            "Epoch 104/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1749.2544 - val_loss: 94.9060\n",
            "Epoch 105/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1678.6884 - val_loss: 30.9193\n",
            "Epoch 106/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1685.7655 - val_loss: 45.6513\n",
            "Epoch 107/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1668.8623 - val_loss: 20.7103\n",
            "Epoch 108/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1690.6694 - val_loss: 12.4402\n",
            "Epoch 109/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1681.6758 - val_loss: 409.4447\n",
            "Epoch 110/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1643.3865 - val_loss: 20.1305\n",
            "Epoch 111/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1651.7244 - val_loss: 74.3223\n",
            "Epoch 112/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1729.9215 - val_loss: 76.5482\n",
            "Epoch 113/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1650.5298 - val_loss: 27.5165\n",
            "Epoch 114/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1666.8971 - val_loss: 146.3016\n",
            "Epoch 115/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1631.5396 - val_loss: 21.9402\n",
            "Epoch 116/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1759.7758 - val_loss: 1180.5157\n",
            "Epoch 117/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1795.1200 - val_loss: 73.2912\n",
            "Epoch 118/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1681.8153 - val_loss: 78.4719\n",
            "Epoch 119/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1643.7074 - val_loss: 50.2348\n",
            "Epoch 120/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1606.0104 - val_loss: 22.1536\n",
            "Epoch 121/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1704.7429 - val_loss: 190.7467\n",
            "Epoch 122/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1686.3513 - val_loss: 64.2161\n",
            "Epoch 123/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1523.8300 - val_loss: 6.4013\n",
            "Epoch 124/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1714.1810 - val_loss: 22.1420\n",
            "Epoch 125/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1810.3462 - val_loss: 36.0938\n",
            "Epoch 126/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1661.1504 - val_loss: 57.1796\n",
            "Epoch 127/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1607.9111 - val_loss: 108.9545\n",
            "Epoch 128/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1626.1302 - val_loss: 173.3689\n",
            "Epoch 129/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1586.9893 - val_loss: 7.0027\n",
            "Epoch 130/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1618.2992 - val_loss: 243.8056\n",
            "Epoch 131/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1547.1687 - val_loss: 11.3401\n",
            "Epoch 132/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1677.3088 - val_loss: 38.8702\n",
            "Epoch 133/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1637.9967 - val_loss: 39.6951\n",
            "Epoch 134/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1609.2876 - val_loss: 18.7348\n",
            "Epoch 135/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1528.4329 - val_loss: 7.1360\n",
            "Epoch 136/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1726.8199 - val_loss: 10.5508\n",
            "Epoch 137/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1524.6978 - val_loss: 6.2673\n",
            "Epoch 138/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1609.8176 - val_loss: 280.6783\n",
            "Epoch 139/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1862.2612 - val_loss: 87.4567\n",
            "Epoch 140/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1568.3741 - val_loss: 79.3967\n",
            "Epoch 141/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1468.4292 - val_loss: 5.9225\n",
            "Epoch 142/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1516.4854 - val_loss: 178.5094\n",
            "Epoch 143/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1759.8435 - val_loss: 469.6457\n",
            "Epoch 144/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1702.6152 - val_loss: 119.9503\n",
            "Epoch 145/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1609.7664 - val_loss: 204.5795\n",
            "Epoch 146/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1545.4014 - val_loss: 75.3277\n",
            "Epoch 147/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1427.1283 - val_loss: 5.6450\n",
            "Epoch 148/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1516.7218 - val_loss: 418.3396\n",
            "Epoch 149/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1490.6633 - val_loss: 43.8969\n",
            "Epoch 150/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1376.7056 - val_loss: 5.7820\n",
            "Epoch 151/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1768.8168 - val_loss: 8.7191\n",
            "Epoch 152/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1450.3127 - val_loss: 6.1281\n",
            "Epoch 153/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1762.7295 - val_loss: 10.2286\n",
            "Epoch 154/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1430.5393 - val_loss: 80.8851\n",
            "Epoch 155/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1299.2769 - val_loss: 5.9376\n",
            "Epoch 156/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1347.9883 - val_loss: 219.1252\n",
            "Epoch 157/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1483.7703 - val_loss: 825.7784\n",
            "Epoch 158/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1983.6515 - val_loss: 25.1391\n",
            "Epoch 159/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1784.6577 - val_loss: 22.5317\n",
            "Epoch 160/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1780.1923 - val_loss: 9.6409\n",
            "Epoch 161/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1776.1543 - val_loss: 11.2866\n",
            "Epoch 162/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1768.1499 - val_loss: 10.8920\n",
            "Epoch 163/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1753.2991 - val_loss: 11.8221\n",
            "Epoch 164/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1741.8768 - val_loss: 16.1072\n",
            "Epoch 165/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1740.0359 - val_loss: 21.3449\n",
            "Epoch 166/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1713.2219 - val_loss: 12.4610\n",
            "Epoch 167/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1707.5049 - val_loss: 15.4935\n",
            "Epoch 168/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1659.0269 - val_loss: 9.2514\n",
            "Epoch 169/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1725.3020 - val_loss: 46.5675\n",
            "Epoch 170/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1649.3739 - val_loss: 57.6262\n",
            "Epoch 171/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1584.4446 - val_loss: 12.7203\n",
            "Epoch 172/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1753.1882 - val_loss: 12.2384\n",
            "Epoch 173/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1660.7876 - val_loss: 131.4507\n",
            "Epoch 174/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1636.6990 - val_loss: 80.6637\n",
            "Epoch 175/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1594.7883 - val_loss: 19.7856\n",
            "Epoch 176/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1669.7483 - val_loss: 124.2141\n",
            "Epoch 177/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1740.4730 - val_loss: 15.9925\n",
            "Epoch 178/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1741.4797 - val_loss: 115.2544\n",
            "Epoch 179/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1563.3958 - val_loss: 14.5361\n",
            "Epoch 180/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1545.6132 - val_loss: 329.9921\n",
            "Epoch 181/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1437.7325 - val_loss: 11.3206\n",
            "Epoch 182/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1766.6434 - val_loss: 168.5354\n",
            "Epoch 183/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1718.8234 - val_loss: 87.4868\n",
            "Epoch 184/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1543.9845 - val_loss: 356.5099\n",
            "Epoch 185/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1499.8074 - val_loss: 9.9862\n",
            "Epoch 186/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2104.5315 - val_loss: 98.4426\n",
            "Epoch 187/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1571.0072 - val_loss: 32.8464\n",
            "Epoch 188/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1517.2458 - val_loss: 91.2862\n",
            "Epoch 189/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1452.5990 - val_loss: 33.3672\n",
            "Epoch 190/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1484.3043 - val_loss: 539.0565\n",
            "Epoch 191/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1638.0189 - val_loss: 120.0083\n",
            "Epoch 192/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1458.0428 - val_loss: 716.0670\n",
            "Epoch 193/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1917.6388 - val_loss: 11.5147\n",
            "Epoch 194/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1797.9983 - val_loss: 376.4016\n",
            "Epoch 195/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1496.8595 - val_loss: 8.5985\n",
            "Epoch 196/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1812.5688 - val_loss: 150.3197\n",
            "Epoch 197/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1492.4574 - val_loss: 25.1130\n",
            "Epoch 198/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1482.4967 - val_loss: 238.9007\n",
            "Epoch 199/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1340.1453 - val_loss: 9.4793\n",
            "Epoch 200/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1551.0082 - val_loss: 9.1503\n",
            "Epoch 201/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1846.3682 - val_loss: 335.9937\n",
            "Epoch 202/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1443.9961 - val_loss: 15.2804\n",
            "Epoch 203/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1872.6868 - val_loss: 85.4512\n",
            "Epoch 204/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1514.9882 - val_loss: 15.2438\n",
            "Epoch 205/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1362.3236 - val_loss: 56.3586\n",
            "Epoch 206/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1411.3773 - val_loss: 33.5969\n",
            "Epoch 207/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1219.9908 - val_loss: 8.6304\n",
            "Epoch 208/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1636.1964 - val_loss: 8.7832\n",
            "Epoch 209/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1355.5333 - val_loss: 1535.8752\n",
            "Epoch 210/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1673.5140 - val_loss: 48.5601\n",
            "Epoch 211/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1208.2521 - val_loss: 8.2477\n",
            "Epoch 212/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1352.2076 - val_loss: 8.6435\n",
            "Epoch 213/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1372.4666 - val_loss: 7.9840\n",
            "Epoch 214/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1781.9395 - val_loss: 32.4634\n",
            "Epoch 215/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1394.6124 - val_loss: 249.3383\n",
            "Epoch 216/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 985.6439 - val_loss: 10.1888\n",
            "Epoch 217/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1679.0002 - val_loss: 11.8469\n",
            "Epoch 218/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1405.4330 - val_loss: 12.2530\n",
            "Epoch 219/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1060.4047 - val_loss: 7.0595\n",
            "Epoch 220/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 860.0668 - val_loss: 488.7459\n",
            "Epoch 221/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1893.1334 - val_loss: 9.0767\n",
            "Epoch 222/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1783.8510 - val_loss: 8.5056\n",
            "Epoch 223/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2157.2446 - val_loss: 10.3744\n",
            "Epoch 224/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1567.0569 - val_loss: 796.6856\n",
            "Epoch 225/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1060.0795 - val_loss: 7.0800\n",
            "Epoch 226/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1596.1516 - val_loss: 92.9449\n",
            "Epoch 227/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1776.5319 - val_loss: 104.1323\n",
            "Epoch 228/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1217.7432 - val_loss: 18.8395\n",
            "Epoch 229/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1366.0999 - val_loss: 7.4642\n",
            "Epoch 230/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1653.6333 - val_loss: 154.8853\n",
            "Epoch 231/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1007.5904 - val_loss: 38.1549\n",
            "Epoch 232/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 766.0730 - val_loss: 7.8746\n",
            "Epoch 233/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 888.8356 - val_loss: 7.7121\n",
            "Epoch 234/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1429.5166 - val_loss: 9.1528\n",
            "Epoch 235/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1779.8018 - val_loss: 9.1299\n",
            "Epoch 236/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1493.6356 - val_loss: 1448.6429\n",
            "Epoch 237/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1738.7712 - val_loss: 187.7742\n",
            "Epoch 238/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1541.8318 - val_loss: 782.3055\n",
            "Epoch 239/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 997.7151 - val_loss: 7.8188\n",
            "Epoch 240/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1789.2899 - val_loss: 7.6432\n",
            "Epoch 241/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1787.7025 - val_loss: 7.5923\n",
            "Epoch 242/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1786.9391 - val_loss: 8.0680\n",
            "Epoch 243/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1786.9199 - val_loss: 8.1578\n",
            "Epoch 244/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1785.6891 - val_loss: 8.0676\n",
            "Epoch 245/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1784.2634 - val_loss: 7.5705\n",
            "Epoch 246/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1783.0006 - val_loss: 8.8293\n",
            "Epoch 247/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1782.4739 - val_loss: 7.0817\n",
            "Epoch 248/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1774.2233 - val_loss: 8.4930\n",
            "Epoch 249/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1984.2683 - val_loss: 7.9399\n",
            "Epoch 250/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1410.4749 - val_loss: 455.6057\n",
            "Epoch 251/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1359.7850 - val_loss: 8.2605\n",
            "Epoch 252/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1168.3199 - val_loss: 7.5577\n",
            "Epoch 253/1000\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 1752.2220 - val_loss: 8.3582\n",
            "Epoch 254/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1209.2416 - val_loss: 6.4590\n",
            "Epoch 255/1000\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 891.4022 - val_loss: 6.4584\n",
            "Epoch 256/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 888.7169 - val_loss: 8.5545\n",
            "Epoch 257/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1789.1285 - val_loss: 11.4246\n",
            "Epoch 258/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1786.6676 - val_loss: 9.6396\n",
            "Epoch 259/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1783.8290 - val_loss: 9.2550\n",
            "Epoch 260/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1781.4640 - val_loss: 12.3208\n",
            "Epoch 261/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1776.2501 - val_loss: 8.8896\n",
            "Epoch 262/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1768.3542 - val_loss: 13.0237\n",
            "Epoch 263/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1765.0583 - val_loss: 24.3747\n",
            "Epoch 264/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1754.8998 - val_loss: 16.2668\n",
            "Epoch 265/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1739.1960 - val_loss: 11.0007\n",
            "Epoch 266/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1729.7446 - val_loss: 20.3581\n",
            "Epoch 267/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1695.1755 - val_loss: 10.3887\n",
            "Epoch 268/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1695.0520 - val_loss: 17.0465\n",
            "Epoch 269/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1655.5880 - val_loss: 33.7298\n",
            "Epoch 270/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1568.8260 - val_loss: 12.1739\n",
            "Epoch 271/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1630.0841 - val_loss: 127.4081\n",
            "Epoch 272/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1672.9183 - val_loss: 29.8556\n",
            "Epoch 273/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1555.2395 - val_loss: 93.1876\n",
            "Epoch 274/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1509.9417 - val_loss: 13.8706\n",
            "Epoch 275/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1627.7830 - val_loss: 16.9891\n",
            "Epoch 276/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2056.0518 - val_loss: 15.7496\n",
            "Epoch 277/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1695.8990 - val_loss: 361.2448\n",
            "Epoch 278/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1795.8041 - val_loss: 164.7067\n",
            "Epoch 279/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2412.5723 - val_loss: 13.5586\n",
            "Epoch 280/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1793.1771 - val_loss: 13.5167\n",
            "Epoch 281/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1776.2983 - val_loss: 11.4063\n",
            "Epoch 282/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1652.8297 - val_loss: 16.9100\n",
            "Epoch 283/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1565.0250 - val_loss: 15.0287\n",
            "Epoch 284/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1470.0557 - val_loss: 20.3801\n",
            "Epoch 285/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1434.8770 - val_loss: 138.2597\n",
            "Epoch 286/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1337.9788 - val_loss: 17.0191\n",
            "Epoch 287/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1497.1696 - val_loss: 61.7839\n",
            "Epoch 288/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1483.4664 - val_loss: 1341.7439\n",
            "Epoch 289/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1674.1284 - val_loss: 11.9643\n",
            "Epoch 290/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1791.2985 - val_loss: 202.4129\n",
            "Epoch 291/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1301.3890 - val_loss: 29.0265\n",
            "Epoch 292/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1101.0640 - val_loss: 10.9676\n",
            "Epoch 293/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1447.7441 - val_loss: 336.1928\n",
            "Epoch 294/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1226.6986 - val_loss: 49.1943\n",
            "Epoch 295/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1149.3722 - val_loss: 11.4416\n",
            "Epoch 296/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1828.9790 - val_loss: 345.8750\n",
            "Epoch 297/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1540.6104 - val_loss: 120.6998\n",
            "Epoch 298/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1427.3168 - val_loss: 450.8355\n",
            "Epoch 299/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1585.6101 - val_loss: 563.3085\n",
            "Epoch 300/1000\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1616.6938 - val_loss: 46.9755\n",
            "Epoch 301/1000\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 957.1611 - val_loss: 64.3176\n",
            "Epoch 302/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 872.0385 - val_loss: 49.7268\n",
            "Epoch 303/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 530.3506 - val_loss: 32.7018\n",
            "Epoch 304/1000\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 277.3330 - val_loss: 258.5473\n",
            "Epoch 305/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 4185.2822 - val_loss: 13.2455\n",
            "Epoch 306/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1794.2889 - val_loss: 10.5907\n",
            "Epoch 307/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1792.5665 - val_loss: 10.4727\n",
            "Epoch 308/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1791.8513 - val_loss: 10.1446\n",
            "Epoch 309/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1790.7579 - val_loss: 9.8846\n",
            "Epoch 310/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1789.7356 - val_loss: 9.7661\n",
            "Epoch 311/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1789.7677 - val_loss: 10.0060\n",
            "Epoch 312/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1788.2616 - val_loss: 10.3636\n",
            "Epoch 313/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1787.2896 - val_loss: 9.8549\n",
            "Epoch 314/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1785.4852 - val_loss: 10.1831\n",
            "Epoch 315/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1776.1282 - val_loss: 10.7001\n",
            "Epoch 316/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1491.6323 - val_loss: 305.4993\n",
            "Epoch 317/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 930.1995 - val_loss: 10.3442\n",
            "Epoch 318/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1779.0869 - val_loss: 10.7801\n",
            "Epoch 319/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1757.5032 - val_loss: 10.8762\n",
            "Epoch 320/1000\n",
            "125/125 [==============================] - 2s 13ms/step - loss: 1723.9281 - val_loss: 12.3630\n",
            "Epoch 321/1000\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 1608.0997 - val_loss: 14.3362\n",
            "Epoch 322/1000\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1393.1832 - val_loss: 13.6314\n",
            "Epoch 323/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1201.0959 - val_loss: 47.8211\n",
            "Epoch 324/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1204.6613 - val_loss: 12.5287\n",
            "Epoch 325/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 867.6906 - val_loss: 11.3405\n",
            "Epoch 326/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1634.8326 - val_loss: 16.8480\n",
            "Epoch 327/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1796.9653 - val_loss: 25.8352\n",
            "Epoch 328/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1796.4205 - val_loss: 13.9849\n",
            "Epoch 329/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1794.5596 - val_loss: 11.7826\n",
            "Epoch 330/1000\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 1794.0525 - val_loss: 13.5828\n",
            "Epoch 331/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1793.2184 - val_loss: 12.4810\n",
            "Epoch 332/1000\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1794.1010 - val_loss: 13.6655\n",
            "Epoch 333/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1791.8193 - val_loss: 10.1416\n",
            "Epoch 334/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1790.4858 - val_loss: 11.0833\n",
            "Epoch 335/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1790.3003 - val_loss: 9.9395\n",
            "Epoch 336/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1789.2261 - val_loss: 10.9309\n",
            "Epoch 337/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1788.7202 - val_loss: 10.2393\n",
            "Epoch 338/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1789.3525 - val_loss: 9.8016\n",
            "Epoch 339/1000\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1788.3090 - val_loss: 11.1997\n",
            "Epoch 340/1000\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1786.4896 - val_loss: 10.0314\n",
            "Epoch 341/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1786.4592 - val_loss: 9.2902\n",
            "Epoch 342/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1783.7490 - val_loss: 9.3277\n",
            "Epoch 343/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1779.5000 - val_loss: 13.1958\n",
            "Epoch 344/1000\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1777.7886 - val_loss: 9.0660\n",
            "Epoch 345/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1780.9231 - val_loss: 10.2010\n",
            "Epoch 346/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1773.9921 - val_loss: 10.5378\n",
            "Epoch 347/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1768.2643 - val_loss: 11.9180\n",
            "Epoch 348/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1764.3464 - val_loss: 10.3025\n",
            "Epoch 349/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1764.2496 - val_loss: 10.5864\n",
            "Epoch 350/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1756.2115 - val_loss: 10.7174\n",
            "Epoch 351/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1746.3159 - val_loss: 10.6264\n",
            "Epoch 352/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1746.5211 - val_loss: 12.4134\n",
            "Epoch 353/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1745.9454 - val_loss: 13.4607\n",
            "Epoch 354/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1728.8706 - val_loss: 16.6427\n",
            "Epoch 355/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1717.8890 - val_loss: 11.0889\n",
            "Epoch 356/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1708.6300 - val_loss: 49.3229\n",
            "Epoch 357/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1738.3102 - val_loss: 19.5172\n",
            "Epoch 358/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1706.0768 - val_loss: 15.2534\n",
            "Epoch 359/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1682.2985 - val_loss: 56.6278\n",
            "Epoch 360/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1651.4543 - val_loss: 24.6555\n",
            "Epoch 361/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1686.7612 - val_loss: 19.9202\n",
            "Epoch 362/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1713.4604 - val_loss: 208.3788\n",
            "Epoch 363/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1646.8696 - val_loss: 27.7748\n",
            "Epoch 364/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1785.9569 - val_loss: 69.2757\n",
            "Epoch 365/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1616.2908 - val_loss: 70.1755\n",
            "Epoch 366/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1570.5240 - val_loss: 19.3513\n",
            "Epoch 367/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1684.9258 - val_loss: 47.0609\n",
            "Epoch 368/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1614.8269 - val_loss: 314.2070\n",
            "Epoch 369/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1675.8953 - val_loss: 212.6067\n",
            "Epoch 370/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1610.8198 - val_loss: 54.4012\n",
            "Epoch 371/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1662.5652 - val_loss: 270.5928\n",
            "Epoch 372/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1657.3016 - val_loss: 21.5725\n",
            "Epoch 373/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1656.0988 - val_loss: 12.7129\n",
            "Epoch 374/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1544.0317 - val_loss: 156.0480\n",
            "Epoch 375/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1552.1703 - val_loss: 45.3358\n",
            "Epoch 376/1000\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1648.2523 - val_loss: 97.2159\n",
            "Epoch 377/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1879.3868 - val_loss: 158.9971\n",
            "Epoch 378/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1460.9821 - val_loss: 11.9090\n",
            "Epoch 379/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1789.6423 - val_loss: 11.5278\n",
            "Epoch 380/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1786.2604 - val_loss: 11.5310\n",
            "Epoch 381/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1783.3563 - val_loss: 17.2799\n",
            "Epoch 382/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1784.1504 - val_loss: 10.3275\n",
            "Epoch 383/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1772.1882 - val_loss: 37.7547\n",
            "Epoch 384/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1674.1945 - val_loss: 18.2283\n",
            "Epoch 385/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1756.0464 - val_loss: 105.3711\n",
            "Epoch 386/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1678.1931 - val_loss: 20.9672\n",
            "Epoch 387/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1799.3015 - val_loss: 19.0151\n",
            "Epoch 388/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2510.2593 - val_loss: 18.2809\n",
            "Epoch 389/1000\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1795.4705 - val_loss: 11.8198\n",
            "Epoch 390/1000\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1792.0044 - val_loss: 11.0688\n",
            "Epoch 391/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1791.1251 - val_loss: 11.0800\n",
            "Epoch 392/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1790.6560 - val_loss: 11.3409\n",
            "Epoch 393/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1790.1732 - val_loss: 13.3833\n",
            "Epoch 394/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1789.9421 - val_loss: 11.4947\n",
            "Epoch 395/1000\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1789.3754 - val_loss: 11.4577\n",
            "Epoch 396/1000\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 1789.2140 - val_loss: 11.0021\n",
            "Epoch 397/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1789.0299 - val_loss: 11.3402\n",
            "Epoch 398/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1788.3231 - val_loss: 11.8042\n",
            "Epoch 399/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1788.6611 - val_loss: 11.7399\n",
            "Epoch 400/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1787.8522 - val_loss: 11.2746\n",
            "Epoch 401/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1786.9738 - val_loss: 12.4654\n",
            "Epoch 402/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1787.1738 - val_loss: 11.4463\n",
            "Epoch 403/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1786.6149 - val_loss: 14.5706\n",
            "Epoch 404/1000\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1786.7837 - val_loss: 12.5474\n",
            "Epoch 405/1000\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1785.3042 - val_loss: 11.5065\n",
            "Epoch 406/1000\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 1786.1093 - val_loss: 12.0162\n",
            "Epoch 407/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1784.8301 - val_loss: 11.7920\n",
            "Epoch 408/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1783.5371 - val_loss: 12.6905\n",
            "Epoch 409/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1783.8751 - val_loss: 13.0004\n",
            "Epoch 410/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1783.0559 - val_loss: 12.5230\n",
            "Epoch 411/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1781.4207 - val_loss: 12.2182\n",
            "Epoch 412/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1782.4985 - val_loss: 12.0302\n",
            "Epoch 413/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1779.6387 - val_loss: 27.0731\n",
            "Epoch 414/1000\n",
            "125/125 [==============================] - 1s 10ms/step - loss: 1782.9194 - val_loss: 21.9788\n",
            "Epoch 415/1000\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 1777.9895 - val_loss: 12.4493\n",
            "Epoch 416/1000\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 1777.5236 - val_loss: 23.9674\n",
            "Epoch 417/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1777.3871 - val_loss: 13.6221\n",
            "Epoch 418/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1778.2941 - val_loss: 20.2723\n",
            "Epoch 419/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1777.4882 - val_loss: 14.7808\n",
            "Epoch 420/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1774.6146 - val_loss: 16.1014\n",
            "Epoch 421/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1769.3926 - val_loss: 16.2255\n",
            "Epoch 422/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1771.5448 - val_loss: 17.1156\n",
            "Epoch 423/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1766.1180 - val_loss: 16.5622\n",
            "Epoch 424/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1761.1847 - val_loss: 56.0217\n",
            "Epoch 425/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1747.8965 - val_loss: 17.6824\n",
            "Epoch 426/1000\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 1765.0741 - val_loss: 30.0507\n",
            "Epoch 427/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1725.2024 - val_loss: 32.7791\n",
            "Epoch 428/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1701.6396 - val_loss: 43.6093\n",
            "Epoch 429/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1660.5215 - val_loss: 14.9439\n",
            "Epoch 430/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1669.1451 - val_loss: 649.6709\n",
            "Epoch 431/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1596.6171 - val_loss: 14.3298\n",
            "Epoch 432/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1971.9556 - val_loss: 57.0212\n",
            "Epoch 433/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1595.7534 - val_loss: 16.1292\n",
            "Epoch 434/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1697.2524 - val_loss: 161.0072\n",
            "Epoch 435/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1624.7014 - val_loss: 20.9983\n",
            "Epoch 436/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1644.3325 - val_loss: 403.5644\n",
            "Epoch 437/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1592.9927 - val_loss: 20.8508\n",
            "Epoch 438/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1693.2411 - val_loss: 38.6407\n",
            "Epoch 439/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1557.8901 - val_loss: 185.1642\n",
            "Epoch 440/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1721.0511 - val_loss: 86.7799\n",
            "Epoch 441/1000\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 1498.9321 - val_loss: 12.4638\n",
            "Epoch 442/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1488.1876 - val_loss: 666.3250\n",
            "Epoch 443/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1652.5383 - val_loss: 13.4184\n",
            "Epoch 444/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1499.3096 - val_loss: 63.5041\n",
            "Epoch 445/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1786.6714 - val_loss: 606.9814\n",
            "Epoch 446/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1650.8580 - val_loss: 57.4888\n",
            "Epoch 447/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 1627.7429 - val_loss: 473.5036\n",
            "Epoch 448/1000\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 1582.5931 - val_loss: 25.3830\n",
            "Epoch 449/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1490.6880 - val_loss: 16.8825\n",
            "Epoch 450/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1409.9945 - val_loss: 223.0890\n",
            "Epoch 451/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1562.7217 - val_loss: 16.3238\n",
            "Epoch 452/1000\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 1378.0846 - val_loss: 643.9179\n",
            "Epoch 453/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1802.5289 - val_loss: 39.4306\n",
            "Epoch 454/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1559.6735 - val_loss: 12.9613\n",
            "Epoch 455/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1842.1807 - val_loss: 33.8989\n",
            "Epoch 456/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1442.2798 - val_loss: 13.1154\n",
            "Epoch 457/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1437.6000 - val_loss: 53.5515\n",
            "Epoch 458/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1328.2791 - val_loss: 99.9579\n",
            "Epoch 459/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1294.7374 - val_loss: 56.2668\n",
            "Epoch 460/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1288.1603 - val_loss: 509.1022\n",
            "Epoch 461/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1442.6526 - val_loss: 16.6589\n",
            "Epoch 462/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1877.6559 - val_loss: 12.0668\n",
            "Epoch 463/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1303.3657 - val_loss: 239.9603\n",
            "Epoch 464/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1302.3008 - val_loss: 36.7427\n",
            "Epoch 465/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1359.9293 - val_loss: 14.3164\n",
            "Epoch 466/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2015.1025 - val_loss: 208.9620\n",
            "Epoch 467/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1300.4965 - val_loss: 61.6694\n",
            "Epoch 468/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1158.1057 - val_loss: 11.2406\n",
            "Epoch 469/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1598.7468 - val_loss: 465.3850\n",
            "Epoch 470/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1330.1981 - val_loss: 11.2216\n",
            "Epoch 471/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1313.7866 - val_loss: 12.4959\n",
            "Epoch 472/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1622.3090 - val_loss: 12.3053\n",
            "Epoch 473/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1789.0765 - val_loss: 13.3589\n",
            "Epoch 474/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1144.8275 - val_loss: 32.4330\n",
            "Epoch 475/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1017.6854 - val_loss: 11.0797\n",
            "Epoch 476/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1627.7537 - val_loss: 12.4294\n",
            "Epoch 477/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1785.5781 - val_loss: 11.2905\n",
            "Epoch 478/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1799.6169 - val_loss: 848.1153\n",
            "Epoch 479/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1636.3002 - val_loss: 11.7866\n",
            "Epoch 480/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1427.7750 - val_loss: 13.6573\n",
            "Epoch 481/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1248.6152 - val_loss: 10.1832\n",
            "Epoch 482/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1101.9999 - val_loss: 131.9052\n",
            "Epoch 483/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1057.0150 - val_loss: 9.9464\n",
            "Epoch 484/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 854.0127 - val_loss: 11.9768\n",
            "Epoch 485/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 826.0797 - val_loss: 843.5691\n",
            "Epoch 486/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 639.0187 - val_loss: 11.1525\n",
            "Epoch 487/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1991.1602 - val_loss: 18.8715\n",
            "Epoch 488/1000\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1773.1688 - val_loss: 10.9105\n",
            "Epoch 489/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1738.4650 - val_loss: 13.5769\n",
            "Epoch 490/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1458.8195 - val_loss: 458.8717\n",
            "Epoch 491/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 861.6974 - val_loss: 11.2511\n",
            "Epoch 492/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2343.8054 - val_loss: 17.9128\n",
            "Epoch 493/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1106.2815 - val_loss: 10.4632\n",
            "Epoch 494/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 833.2139 - val_loss: 15.1468\n",
            "Epoch 495/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 670.0292 - val_loss: 15.0674\n",
            "Epoch 496/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 524.4246 - val_loss: 10.1952\n",
            "Epoch 497/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 900.8056 - val_loss: 10.1670\n",
            "Epoch 498/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1535.9720 - val_loss: 10.3438\n",
            "Epoch 499/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1315.3279 - val_loss: 10.4096\n",
            "Epoch 500/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 597.9617 - val_loss: 10.3314\n",
            "Epoch 501/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 565.0878 - val_loss: 11.1132\n",
            "Epoch 502/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1769.3108 - val_loss: 9.3786\n",
            "Epoch 503/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 979.5119 - val_loss: 2988.3049\n",
            "Epoch 504/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 927.6473 - val_loss: 9.4983\n",
            "Epoch 505/1000\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 1488.7581 - val_loss: 1384.7993\n",
            "Epoch 506/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 397.9590 - val_loss: 8.9519\n",
            "Epoch 507/1000\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 842.6218 - val_loss: 2449.6516\n",
            "Epoch 508/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 999.2023 - val_loss: 11.6466\n",
            "Epoch 509/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1791.7303 - val_loss: 9.7945\n",
            "Epoch 510/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1779.0950 - val_loss: 9.4764\n",
            "Epoch 511/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1767.4753 - val_loss: 12.8132\n",
            "Epoch 512/1000\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 1756.3826 - val_loss: 9.3159\n",
            "Epoch 513/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1742.6609 - val_loss: 14.5976\n",
            "Epoch 514/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1725.7073 - val_loss: 10.7804\n",
            "Epoch 515/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1706.1360 - val_loss: 12.4789\n",
            "Epoch 516/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1673.1550 - val_loss: 17.7778\n",
            "Epoch 517/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1198.7015 - val_loss: 688.6430\n",
            "Epoch 518/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1398.6669 - val_loss: 23.5195\n",
            "Epoch 519/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2360.2922 - val_loss: 11.6017\n",
            "Epoch 520/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1737.6067 - val_loss: 9.8556\n",
            "Epoch 521/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1486.4762 - val_loss: 181.9536\n",
            "Epoch 522/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 883.5692 - val_loss: 516.8309\n",
            "Epoch 523/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 425.1990 - val_loss: 1102.0256\n",
            "Epoch 524/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 102.2762 - val_loss: 19.3629\n",
            "Epoch 525/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 104.4227 - val_loss: 14.5319\n",
            "Epoch 526/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2086.1250 - val_loss: 13.5668\n",
            "Epoch 527/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1757.5863 - val_loss: 12.5079\n",
            "Epoch 528/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1737.6290 - val_loss: 16.8602\n",
            "Epoch 529/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1721.2092 - val_loss: 12.1817\n",
            "Epoch 530/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1699.0902 - val_loss: 13.3622\n",
            "Epoch 531/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1677.9530 - val_loss: 14.4856\n",
            "Epoch 532/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1656.1979 - val_loss: 17.5492\n",
            "Epoch 533/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2375.7988 - val_loss: 24.0410\n",
            "Epoch 534/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1695.0940 - val_loss: 14.7995\n",
            "Epoch 535/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1675.1970 - val_loss: 21.6897\n",
            "Epoch 536/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1629.9784 - val_loss: 56.0509\n",
            "Epoch 537/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1093.5543 - val_loss: 80.7682\n",
            "Epoch 538/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 812.7337 - val_loss: 61.5865\n",
            "Epoch 539/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 533.6594 - val_loss: 18.5509\n",
            "Epoch 540/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 429.6039 - val_loss: 45.8586\n",
            "Epoch 541/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 208.6873 - val_loss: 70.1960\n",
            "Epoch 542/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 114.3199 - val_loss: 25.2718\n",
            "Epoch 543/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 3815.1941 - val_loss: 19.3626\n",
            "Epoch 544/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1180.8392 - val_loss: 14.0854\n",
            "Epoch 545/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 675.0920 - val_loss: 20.5780\n",
            "Epoch 546/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 489.6280 - val_loss: 114.2863\n",
            "Epoch 547/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 308.0587 - val_loss: 29.2504\n",
            "Epoch 548/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 197.8273 - val_loss: 21.6318\n",
            "Epoch 549/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 118.7517 - val_loss: 291.3999\n",
            "Epoch 550/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 57.4689 - val_loss: 29.3516\n",
            "Epoch 551/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 38.2600 - val_loss: 25.9780\n",
            "Epoch 552/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 25.2503 - val_loss: 29.6090\n",
            "Epoch 553/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 19.4794 - val_loss: 17.8979\n",
            "Epoch 554/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 16.8053 - val_loss: 18.6308\n",
            "Epoch 555/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 14.2783 - val_loss: 15.0042\n",
            "Epoch 556/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 12.5871 - val_loss: 12.8376\n",
            "Epoch 557/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 12.9701 - val_loss: 13.5080\n",
            "Epoch 558/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 10.9459 - val_loss: 12.3469\n",
            "Epoch 559/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 10.4991 - val_loss: 11.8744\n",
            "Epoch 560/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 10.0499 - val_loss: 11.7333\n",
            "Epoch 561/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 9.5196 - val_loss: 11.3081\n",
            "Epoch 562/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 9.9775 - val_loss: 11.2393\n",
            "Epoch 563/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 9.7419 - val_loss: 11.8043\n",
            "Epoch 564/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 9.5033 - val_loss: 10.6130\n",
            "Epoch 565/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 12.0659 - val_loss: 18.9756\n",
            "Epoch 566/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 9.8412 - val_loss: 11.2413\n",
            "Epoch 567/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 14.5520 - val_loss: 20.1240\n",
            "Epoch 568/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 32.7255 - val_loss: 9.5403\n",
            "Epoch 569/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4795.5151 - val_loss: 14.5317\n",
            "Epoch 570/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1678.2998 - val_loss: 102.6759\n",
            "Epoch 571/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1620.1404 - val_loss: 587.9344\n",
            "Epoch 572/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1255.2242 - val_loss: 12.2015\n",
            "Epoch 573/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1870.7404 - val_loss: 11.8455\n",
            "Epoch 574/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1355.6091 - val_loss: 49.1498\n",
            "Epoch 575/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 859.3423 - val_loss: 14.4520\n",
            "Epoch 576/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1822.0120 - val_loss: 12.6983\n",
            "Epoch 577/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2025.8650 - val_loss: 47.0273\n",
            "Epoch 578/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1255.6812 - val_loss: 83.5380\n",
            "Epoch 579/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 885.8061 - val_loss: 39.8571\n",
            "Epoch 580/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 561.3179 - val_loss: 362.2993\n",
            "Epoch 581/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 250.9668 - val_loss: 10.6983\n",
            "Epoch 582/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 411.9446 - val_loss: 14.3696\n",
            "Epoch 583/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1085.9717 - val_loss: 10.5227\n",
            "Epoch 584/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2855.9402 - val_loss: 10.0882\n",
            "Epoch 585/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 627.2038 - val_loss: 124.1618\n",
            "Epoch 586/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 431.3824 - val_loss: 10.0023\n",
            "Epoch 587/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 839.1422 - val_loss: 9.9616\n",
            "Epoch 588/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 437.9350 - val_loss: 48.4415\n",
            "Epoch 589/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 14.1287 - val_loss: 17.0835\n",
            "Epoch 590/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 12.2659 - val_loss: 25.0251\n",
            "Epoch 591/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 12.2121 - val_loss: 9.5943\n",
            "Epoch 592/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 16.4706 - val_loss: 29.8917\n",
            "Epoch 593/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 19.5991 - val_loss: 8.1292\n",
            "Epoch 594/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 42.2711 - val_loss: 53.9347\n",
            "Epoch 595/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 37.4725 - val_loss: 9.3215\n",
            "Epoch 596/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 104.0084 - val_loss: 8.9303\n",
            "Epoch 597/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 12.1130 - val_loss: 8.8062\n",
            "Epoch 598/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 24.1435 - val_loss: 15.0931\n",
            "Epoch 599/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 60.6989 - val_loss: 10.8649\n",
            "Epoch 600/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 204.8506 - val_loss: 713.6425\n",
            "Epoch 601/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 250.6358 - val_loss: 13.4538\n",
            "Epoch 602/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1798.1155 - val_loss: 11.2153\n",
            "Epoch 603/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1791.8281 - val_loss: 62.2487\n",
            "Epoch 604/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1796.9446 - val_loss: 9.8677\n",
            "Epoch 605/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1786.4969 - val_loss: 18.3920\n",
            "Epoch 606/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1788.3221 - val_loss: 10.9925\n",
            "Epoch 607/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1784.1776 - val_loss: 10.7867\n",
            "Epoch 608/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1779.7012 - val_loss: 16.3824\n",
            "Epoch 609/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1778.6240 - val_loss: 10.5139\n",
            "Epoch 610/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1774.2679 - val_loss: 12.8190\n",
            "Epoch 611/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1767.8468 - val_loss: 67.1302\n",
            "Epoch 612/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1760.0967 - val_loss: 15.6515\n",
            "Epoch 613/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1726.9291 - val_loss: 11.8637\n",
            "Epoch 614/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1682.7323 - val_loss: 15.2671\n",
            "Epoch 615/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 4351.9844 - val_loss: 16.4862\n",
            "Epoch 616/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1714.2662 - val_loss: 22.0907\n",
            "Epoch 617/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1653.1146 - val_loss: 24.3952\n",
            "Epoch 618/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1501.8562 - val_loss: 27.3391\n",
            "Epoch 619/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1325.2552 - val_loss: 29.7388\n",
            "Epoch 620/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 960.3776 - val_loss: 98.5794\n",
            "Epoch 621/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 658.9937 - val_loss: 114.5274\n",
            "Epoch 622/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 641.8855 - val_loss: 19.8391\n",
            "Epoch 623/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1808.1827 - val_loss: 134.4491\n",
            "Epoch 624/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1807.1066 - val_loss: 120.1541\n",
            "Epoch 625/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1809.9744 - val_loss: 14.5439\n",
            "Epoch 626/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1797.6985 - val_loss: 14.3660\n",
            "Epoch 627/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1796.0529 - val_loss: 13.8953\n",
            "Epoch 628/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1796.4954 - val_loss: 13.6836\n",
            "Epoch 629/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1796.0908 - val_loss: 16.0077\n",
            "Epoch 630/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1796.2500 - val_loss: 91.0527\n",
            "Epoch 631/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1799.9980 - val_loss: 14.5469\n",
            "Epoch 632/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1795.8586 - val_loss: 14.2798\n",
            "Epoch 633/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1794.7224 - val_loss: 14.1028\n",
            "Epoch 634/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1791.5193 - val_loss: 13.7823\n",
            "Epoch 635/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1794.1177 - val_loss: 17.3366\n",
            "Epoch 636/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1792.1545 - val_loss: 14.5362\n",
            "Epoch 637/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1789.7722 - val_loss: 14.0478\n",
            "Epoch 638/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1789.9259 - val_loss: 15.8074\n",
            "Epoch 639/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1788.4542 - val_loss: 15.0551\n",
            "Epoch 640/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1786.3104 - val_loss: 15.3242\n",
            "Epoch 641/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1784.6008 - val_loss: 17.6670\n",
            "Epoch 642/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1779.2882 - val_loss: 64.2353\n",
            "Epoch 643/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1780.1370 - val_loss: 18.7543\n",
            "Epoch 644/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1725.5134 - val_loss: 59.1587\n",
            "Epoch 645/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 3073.6355 - val_loss: 19.4287\n",
            "Epoch 646/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1767.9719 - val_loss: 75.8391\n",
            "Epoch 647/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1761.7294 - val_loss: 26.6198\n",
            "Epoch 648/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1744.4626 - val_loss: 88.6799\n",
            "Epoch 649/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1651.8748 - val_loss: 30.1126\n",
            "Epoch 650/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1371.6444 - val_loss: 3878.3613\n",
            "Epoch 651/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1476.6600 - val_loss: 17.4306\n",
            "Epoch 652/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1657.7209 - val_loss: 37.8286\n",
            "Epoch 653/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1176.0175 - val_loss: 18.9917\n",
            "Epoch 654/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1411.7733 - val_loss: 18.9593\n",
            "Epoch 655/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 3631.2185 - val_loss: 19.9780\n",
            "Epoch 656/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1785.6311 - val_loss: 16.6888\n",
            "Epoch 657/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1771.8884 - val_loss: 16.9875\n",
            "Epoch 658/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1755.2301 - val_loss: 22.4497\n",
            "Epoch 659/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1711.9418 - val_loss: 28.9132\n",
            "Epoch 660/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1653.9031 - val_loss: 22.9222\n",
            "Epoch 661/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1540.6382 - val_loss: 60.1376\n",
            "Epoch 662/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1322.0481 - val_loss: 31.5167\n",
            "Epoch 663/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1074.4825 - val_loss: 71.8810\n",
            "Epoch 664/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 777.2021 - val_loss: 27.5601\n",
            "Epoch 665/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2213.0112 - val_loss: 81.2264\n",
            "Epoch 666/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1186.5780 - val_loss: 77.1905\n",
            "Epoch 667/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 760.3745 - val_loss: 17.5718\n",
            "Epoch 668/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 351.9826 - val_loss: 2319.8604\n",
            "Epoch 669/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1406.0801 - val_loss: 18.1284\n",
            "Epoch 670/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 549.4778 - val_loss: 37.3740\n",
            "Epoch 671/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 40.1320 - val_loss: 1211.9617\n",
            "Epoch 672/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 163.9604 - val_loss: 13.3442\n",
            "Epoch 673/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 455.8638 - val_loss: 15.2370\n",
            "Epoch 674/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1796.4261 - val_loss: 13.1723\n",
            "Epoch 675/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1789.7056 - val_loss: 13.0139\n",
            "Epoch 676/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1788.2249 - val_loss: 16.7452\n",
            "Epoch 677/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1786.7428 - val_loss: 14.4768\n",
            "Epoch 678/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1782.9697 - val_loss: 19.9679\n",
            "Epoch 679/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1782.5222 - val_loss: 12.7019\n",
            "Epoch 680/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1782.1349 - val_loss: 13.3684\n",
            "Epoch 681/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1775.0386 - val_loss: 13.8126\n",
            "Epoch 682/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1766.0050 - val_loss: 14.6377\n",
            "Epoch 683/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 4199.4175 - val_loss: 15.5827\n",
            "Epoch 684/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1507.5808 - val_loss: 16.8032\n",
            "Epoch 685/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1204.9335 - val_loss: 15.8206\n",
            "Epoch 686/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 877.5040 - val_loss: 14.5868\n",
            "Epoch 687/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 519.8065 - val_loss: 14.9697\n",
            "Epoch 688/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 296.7515 - val_loss: 15.4368\n",
            "Epoch 689/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 94.3845 - val_loss: 16.1011\n",
            "Epoch 690/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 15.1630 - val_loss: 14.0688\n",
            "Epoch 691/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 14.7344 - val_loss: 13.7032\n",
            "Epoch 692/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 14.1793 - val_loss: 14.2971\n",
            "Epoch 693/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 13.8329 - val_loss: 12.9182\n",
            "Epoch 694/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 13.0834 - val_loss: 12.5770\n",
            "Epoch 695/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 12.7886 - val_loss: 12.6153\n",
            "Epoch 696/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 12.5576 - val_loss: 13.4217\n",
            "Epoch 697/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 12.4100 - val_loss: 11.8233\n",
            "Epoch 698/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 11.8354 - val_loss: 12.1575\n",
            "Epoch 699/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 12.6726 - val_loss: 11.5624\n",
            "Epoch 700/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 14.3498 - val_loss: 12.1875\n",
            "Epoch 701/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 22.4442 - val_loss: 14.6050\n",
            "Epoch 702/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 34.1837 - val_loss: 13.8191\n",
            "Epoch 703/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 989.5256 - val_loss: 12.7233\n",
            "Epoch 704/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1795.5039 - val_loss: 11.7809\n",
            "Epoch 705/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1795.4271 - val_loss: 12.2729\n",
            "Epoch 706/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1793.2903 - val_loss: 32.4283\n",
            "Epoch 707/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1793.0876 - val_loss: 12.4658\n",
            "Epoch 708/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1790.9159 - val_loss: 44.0759\n",
            "Epoch 709/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1793.5864 - val_loss: 12.6641\n",
            "Epoch 710/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1790.2762 - val_loss: 17.0274\n",
            "Epoch 711/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1790.6692 - val_loss: 13.9592\n",
            "Epoch 712/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1789.0482 - val_loss: 12.4466\n",
            "Epoch 713/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1788.0107 - val_loss: 13.1203\n",
            "Epoch 714/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1787.0566 - val_loss: 24.7582\n",
            "Epoch 715/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1786.7729 - val_loss: 30.3721\n",
            "Epoch 716/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1785.5675 - val_loss: 12.6111\n",
            "Epoch 717/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1784.2433 - val_loss: 13.1500\n",
            "Epoch 718/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1779.6967 - val_loss: 13.1819\n",
            "Epoch 719/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1773.3514 - val_loss: 13.4017\n",
            "Epoch 720/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1764.3185 - val_loss: 25.8953\n",
            "Epoch 721/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2129.6174 - val_loss: 45.2827\n",
            "Epoch 722/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1686.6157 - val_loss: 47.1961\n",
            "Epoch 723/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1416.1317 - val_loss: 219.3991\n",
            "Epoch 724/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1173.6285 - val_loss: 13.6144\n",
            "Epoch 725/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1231.9438 - val_loss: 450.2917\n",
            "Epoch 726/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2148.9736 - val_loss: 35.2039\n",
            "Epoch 727/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1155.2262 - val_loss: 14.6571\n",
            "Epoch 728/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 929.9016 - val_loss: 12.3374\n",
            "Epoch 729/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2084.5039 - val_loss: 13.6447\n",
            "Epoch 730/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1792.7509 - val_loss: 12.5481\n",
            "Epoch 731/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1789.2662 - val_loss: 12.4548\n",
            "Epoch 732/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1786.7654 - val_loss: 12.8963\n",
            "Epoch 733/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1783.4369 - val_loss: 11.9140\n",
            "Epoch 734/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1780.4071 - val_loss: 12.1977\n",
            "Epoch 735/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1763.9514 - val_loss: 12.2181\n",
            "Epoch 736/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1768.1305 - val_loss: 17.4076\n",
            "Epoch 737/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1787.4368 - val_loss: 13.9867\n",
            "Epoch 738/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1452.2814 - val_loss: 13.3686\n",
            "Epoch 739/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 641.1219 - val_loss: 1261.6962\n",
            "Epoch 740/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 91.6606 - val_loss: 12.1921\n",
            "Epoch 741/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1459.3535 - val_loss: 12.9645\n",
            "Epoch 742/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1931.6895 - val_loss: 15.5518\n",
            "Epoch 743/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 871.5410 - val_loss: 529.0615\n",
            "Epoch 744/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 589.0989 - val_loss: 13.4681\n",
            "Epoch 745/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1424.5419 - val_loss: 19.2305\n",
            "Epoch 746/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 736.8954 - val_loss: 13.7282\n",
            "Epoch 747/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 130.5621 - val_loss: 11.5199\n",
            "Epoch 748/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 21.3603 - val_loss: 10.9406\n",
            "Epoch 749/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 21.1844 - val_loss: 12.1833\n",
            "Epoch 750/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 27.9379 - val_loss: 11.0877\n",
            "Epoch 751/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 31.6063 - val_loss: 10.6875\n",
            "Epoch 752/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 50.2080 - val_loss: 12.1072\n",
            "Epoch 753/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 51.3441 - val_loss: 10.4618\n",
            "Epoch 754/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 116.1462 - val_loss: 11.6233\n",
            "Epoch 755/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 46.7227 - val_loss: 10.6130\n",
            "Epoch 756/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1477.0001 - val_loss: 13.7880\n",
            "Epoch 757/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1800.7507 - val_loss: 11.4961\n",
            "Epoch 758/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1797.3802 - val_loss: 13.2158\n",
            "Epoch 759/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1796.8687 - val_loss: 19.6373\n",
            "Epoch 760/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1796.8579 - val_loss: 12.4277\n",
            "Epoch 761/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1794.2219 - val_loss: 11.3942\n",
            "Epoch 762/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1792.9363 - val_loss: 22.0093\n",
            "Epoch 763/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1793.9321 - val_loss: 13.9019\n",
            "Epoch 764/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1793.4998 - val_loss: 12.5858\n",
            "Epoch 765/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1793.6135 - val_loss: 11.7465\n",
            "Epoch 766/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1792.9989 - val_loss: 11.6242\n",
            "Epoch 767/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1792.3943 - val_loss: 11.1194\n",
            "Epoch 768/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1792.0695 - val_loss: 11.3095\n",
            "Epoch 769/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1792.2078 - val_loss: 11.3685\n",
            "Epoch 770/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1791.2324 - val_loss: 11.3183\n",
            "Epoch 771/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1791.6025 - val_loss: 11.1512\n",
            "Epoch 772/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1791.2791 - val_loss: 11.4392\n",
            "Epoch 773/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1790.3314 - val_loss: 11.4392\n",
            "Epoch 774/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1790.3171 - val_loss: 11.4210\n",
            "Epoch 775/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1790.2999 - val_loss: 10.8192\n",
            "Epoch 776/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1789.5499 - val_loss: 25.1962\n",
            "Epoch 777/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1791.3250 - val_loss: 11.0159\n",
            "Epoch 778/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1790.0012 - val_loss: 11.4980\n",
            "Epoch 779/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1789.0759 - val_loss: 11.1094\n",
            "Epoch 780/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1789.6580 - val_loss: 10.8401\n",
            "Epoch 781/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1789.5554 - val_loss: 14.5160\n",
            "Epoch 782/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1792.2667 - val_loss: 14.2537\n",
            "Epoch 783/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1791.1106 - val_loss: 12.4834\n",
            "Epoch 784/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1790.5476 - val_loss: 12.7504\n",
            "Epoch 785/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1790.3585 - val_loss: 12.1572\n",
            "Epoch 786/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1790.3210 - val_loss: 12.2303\n",
            "Epoch 787/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1789.9606 - val_loss: 13.2502\n",
            "Epoch 788/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1788.4664 - val_loss: 31.7073\n",
            "Epoch 789/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1790.1266 - val_loss: 12.3188\n",
            "Epoch 790/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1788.3875 - val_loss: 23.8689\n",
            "Epoch 791/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1790.9196 - val_loss: 12.6268\n",
            "Epoch 792/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1788.2632 - val_loss: 15.5989\n",
            "Epoch 793/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1787.7413 - val_loss: 12.6960\n",
            "Epoch 794/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1786.7584 - val_loss: 13.1322\n",
            "Epoch 795/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1786.6870 - val_loss: 13.0938\n",
            "Epoch 796/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1783.8634 - val_loss: 57.8002\n",
            "Epoch 797/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1787.3385 - val_loss: 12.9353\n",
            "Epoch 798/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1786.1298 - val_loss: 13.6097\n",
            "Epoch 799/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1785.9810 - val_loss: 13.3098\n",
            "Epoch 800/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1783.8137 - val_loss: 12.9227\n",
            "Epoch 801/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1780.6932 - val_loss: 12.9547\n",
            "Epoch 802/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1780.0989 - val_loss: 30.7145\n",
            "Epoch 803/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1780.0485 - val_loss: 14.4753\n",
            "Epoch 804/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1776.9227 - val_loss: 17.1411\n",
            "Epoch 805/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1775.6458 - val_loss: 16.9999\n",
            "Epoch 806/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1766.0160 - val_loss: 13.7433\n",
            "Epoch 807/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1770.0055 - val_loss: 15.4654\n",
            "Epoch 808/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1765.5779 - val_loss: 19.8684\n",
            "Epoch 809/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1755.4048 - val_loss: 15.5192\n",
            "Epoch 810/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1764.0817 - val_loss: 20.2486\n",
            "Epoch 811/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1748.1195 - val_loss: 54.4252\n",
            "Epoch 812/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1749.8245 - val_loss: 21.5088\n",
            "Epoch 813/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1749.8456 - val_loss: 23.7089\n",
            "Epoch 814/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1743.1213 - val_loss: 105.2341\n",
            "Epoch 815/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1729.0909 - val_loss: 19.6126\n",
            "Epoch 816/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1748.6520 - val_loss: 45.6050\n",
            "Epoch 817/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1725.0504 - val_loss: 24.5571\n",
            "Epoch 818/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1718.0573 - val_loss: 75.3961\n",
            "Epoch 819/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1716.0138 - val_loss: 29.0394\n",
            "Epoch 820/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1697.0211 - val_loss: 160.5335\n",
            "Epoch 821/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1691.4484 - val_loss: 19.4541\n",
            "Epoch 822/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1713.0691 - val_loss: 19.9271\n",
            "Epoch 823/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1677.9652 - val_loss: 213.8493\n",
            "Epoch 824/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1646.5890 - val_loss: 16.9404\n",
            "Epoch 825/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1690.4431 - val_loss: 162.8732\n",
            "Epoch 826/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1676.7622 - val_loss: 76.1787\n",
            "Epoch 827/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1594.9259 - val_loss: 14.1080\n",
            "Epoch 828/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1677.5194 - val_loss: 225.1880\n",
            "Epoch 829/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1696.3790 - val_loss: 60.4667\n",
            "Epoch 830/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1654.6409 - val_loss: 140.6523\n",
            "Epoch 831/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1579.9938 - val_loss: 20.1756\n",
            "Epoch 832/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1630.5050 - val_loss: 39.4007\n",
            "Epoch 833/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1612.5845 - val_loss: 20.5480\n",
            "Epoch 834/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1533.9091 - val_loss: 174.6406\n",
            "Epoch 835/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1593.6934 - val_loss: 46.1814\n",
            "Epoch 836/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1530.7031 - val_loss: 13.5821\n",
            "Epoch 837/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1684.2126 - val_loss: 67.6806\n",
            "Epoch 838/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1537.1351 - val_loss: 203.3155\n",
            "Epoch 839/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1529.7562 - val_loss: 25.0480\n",
            "Epoch 840/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1505.2246 - val_loss: 25.9041\n",
            "Epoch 841/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1417.6620 - val_loss: 150.9236\n",
            "Epoch 842/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1326.5020 - val_loss: 13.4228\n",
            "Epoch 843/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1451.3260 - val_loss: 2462.4006\n",
            "Epoch 844/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1824.0399 - val_loss: 62.7247\n",
            "Epoch 845/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1256.0490 - val_loss: 12.8147\n",
            "Epoch 846/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1515.3062 - val_loss: 17.4834\n",
            "Epoch 847/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1656.9209 - val_loss: 412.1148\n",
            "Epoch 848/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1445.1021 - val_loss: 340.2394\n",
            "Epoch 849/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1560.1493 - val_loss: 23.7299\n",
            "Epoch 850/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1251.7061 - val_loss: 160.9677\n",
            "Epoch 851/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1534.4188 - val_loss: 65.7559\n",
            "Epoch 852/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1268.2181 - val_loss: 123.5885\n",
            "Epoch 853/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1252.6477 - val_loss: 356.4733\n",
            "Epoch 854/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1338.2141 - val_loss: 14.4955\n",
            "Epoch 855/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1352.1444 - val_loss: 14.3235\n",
            "Epoch 856/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1344.0020 - val_loss: 13.3079\n",
            "Epoch 857/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1292.2352 - val_loss: 18.9632\n",
            "Epoch 858/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1323.9335 - val_loss: 134.8059\n",
            "Epoch 859/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1266.4150 - val_loss: 402.3580\n",
            "Epoch 860/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1074.4362 - val_loss: 14.0114\n",
            "Epoch 861/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1686.0178 - val_loss: 88.4711\n",
            "Epoch 862/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1177.1996 - val_loss: 13.2330\n",
            "Epoch 863/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 935.9827 - val_loss: 12.7236\n",
            "Epoch 864/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 775.7766 - val_loss: 446.6450\n",
            "Epoch 865/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2274.1262 - val_loss: 15.4456\n",
            "Epoch 866/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1787.7638 - val_loss: 16.8064\n",
            "Epoch 867/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1772.1819 - val_loss: 16.1810\n",
            "Epoch 868/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1756.2351 - val_loss: 23.8734\n",
            "Epoch 869/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1751.3438 - val_loss: 24.0591\n",
            "Epoch 870/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1737.6372 - val_loss: 44.0405\n",
            "Epoch 871/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1728.5269 - val_loss: 30.8060\n",
            "Epoch 872/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1718.5247 - val_loss: 27.0018\n",
            "Epoch 873/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1712.7898 - val_loss: 26.1014\n",
            "Epoch 874/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1701.2106 - val_loss: 54.1023\n",
            "Epoch 875/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1678.4797 - val_loss: 48.5684\n",
            "Epoch 876/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1672.5752 - val_loss: 32.1282\n",
            "Epoch 877/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1669.1556 - val_loss: 51.4213\n",
            "Epoch 878/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1645.9604 - val_loss: 43.3095\n",
            "Epoch 879/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1654.1105 - val_loss: 108.1598\n",
            "Epoch 880/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1649.2640 - val_loss: 115.2258\n",
            "Epoch 881/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1345.2684 - val_loss: 16.6173\n",
            "Epoch 882/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1730.6213 - val_loss: 14.9601\n",
            "Epoch 883/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1686.0305 - val_loss: 33.7552\n",
            "Epoch 884/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1628.2443 - val_loss: 46.3287\n",
            "Epoch 885/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1604.4816 - val_loss: 20.5202\n",
            "Epoch 886/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1618.7153 - val_loss: 41.1749\n",
            "Epoch 887/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1204.6665 - val_loss: 40.2852\n",
            "Epoch 888/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1028.1639 - val_loss: 144.6978\n",
            "Epoch 889/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 899.4241 - val_loss: 16.6989\n",
            "Epoch 890/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1024.6808 - val_loss: 13.3242\n",
            "Epoch 891/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1687.4241 - val_loss: 25.4399\n",
            "Epoch 892/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1143.4423 - val_loss: 392.5596\n",
            "Epoch 893/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1265.8500 - val_loss: 13.2506\n",
            "Epoch 894/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 989.6155 - val_loss: 692.2639\n",
            "Epoch 895/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 757.4736 - val_loss: 13.2532\n",
            "Epoch 896/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 646.5446 - val_loss: 1379.3990\n",
            "Epoch 897/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 632.5948 - val_loss: 12.7939\n",
            "Epoch 898/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1521.1625 - val_loss: 14.5544\n",
            "Epoch 899/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1758.5239 - val_loss: 12.1916\n",
            "Epoch 900/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1636.8284 - val_loss: 13.2583\n",
            "Epoch 901/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 582.5001 - val_loss: 194.6541\n",
            "Epoch 902/1000\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 632.3666 - val_loss: 47.1649\n",
            "Epoch 903/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 416.9430 - val_loss: 11.4356\n",
            "Epoch 904/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 2231.5374 - val_loss: 13.2216\n",
            "Epoch 905/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1763.3027 - val_loss: 165.1420\n",
            "Epoch 906/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1696.4518 - val_loss: 12.2721\n",
            "Epoch 907/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1617.4861 - val_loss: 50.9750\n",
            "Epoch 908/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1512.9172 - val_loss: 87.8312\n",
            "Epoch 909/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 770.2630 - val_loss: 882.2308\n",
            "Epoch 910/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1840.4587 - val_loss: 14.4894\n",
            "Epoch 911/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 551.5630 - val_loss: 13.3200\n",
            "Epoch 912/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 430.3969 - val_loss: 58.2206\n",
            "Epoch 913/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1755.7178 - val_loss: 20.9196\n",
            "Epoch 914/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 291.3604 - val_loss: 18.5242\n",
            "Epoch 915/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 401.9164 - val_loss: 28.3921\n",
            "Epoch 916/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1088.0018 - val_loss: 19.5450\n",
            "Epoch 917/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 123.2001 - val_loss: 13.7894\n",
            "Epoch 918/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 46.1291 - val_loss: 14.6407\n",
            "Epoch 919/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 30.6274 - val_loss: 11.8496\n",
            "Epoch 920/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 26.9281 - val_loss: 12.1774\n",
            "Epoch 921/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 21.5638 - val_loss: 11.8236\n",
            "Epoch 922/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 20.0270 - val_loss: 10.8198\n",
            "Epoch 923/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 16.4059 - val_loss: 10.5169\n",
            "Epoch 924/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 14.5361 - val_loss: 10.3333\n",
            "Epoch 925/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 15.2959 - val_loss: 11.4655\n",
            "Epoch 926/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 13.3784 - val_loss: 10.1045\n",
            "Epoch 927/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 13.2340 - val_loss: 10.1370\n",
            "Epoch 928/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 14.0170 - val_loss: 9.6644\n",
            "Epoch 929/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 11.5254 - val_loss: 9.9479\n",
            "Epoch 930/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 11.1473 - val_loss: 9.4328\n",
            "Epoch 931/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 11.4701 - val_loss: 9.6080\n",
            "Epoch 932/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 13.0492 - val_loss: 10.4040\n",
            "Epoch 933/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 15.2947 - val_loss: 9.7566\n",
            "Epoch 934/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 20.5572 - val_loss: 9.3469\n",
            "Epoch 935/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 76.5017 - val_loss: 11.9666\n",
            "Epoch 936/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 4316.2363 - val_loss: 13.7071\n",
            "Epoch 937/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 945.4565 - val_loss: 12.3650\n",
            "Epoch 938/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1801.0491 - val_loss: 16.4082\n",
            "Epoch 939/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1796.3219 - val_loss: 42.7356\n",
            "Epoch 940/1000\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1796.2617 - val_loss: 11.2743\n",
            "Epoch 941/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1791.2283 - val_loss: 11.4251\n",
            "Epoch 942/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1787.7875 - val_loss: 18.6105\n",
            "Epoch 943/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1786.4325 - val_loss: 11.3773\n",
            "Epoch 944/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1774.8251 - val_loss: 44.7401\n",
            "Epoch 945/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1780.5891 - val_loss: 12.0878\n",
            "Epoch 946/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1765.9785 - val_loss: 13.5492\n",
            "Epoch 947/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1768.8278 - val_loss: 19.4515\n",
            "Epoch 948/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1754.2405 - val_loss: 14.5502\n",
            "Epoch 949/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1745.5316 - val_loss: 19.9444\n",
            "Epoch 950/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1726.7075 - val_loss: 19.9597\n",
            "Epoch 951/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1707.7781 - val_loss: 37.0159\n",
            "Epoch 952/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1687.9606 - val_loss: 13.6377\n",
            "Epoch 953/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1695.7676 - val_loss: 17.6647\n",
            "Epoch 954/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1632.3143 - val_loss: 11.9104\n",
            "Epoch 955/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1604.7302 - val_loss: 169.7947\n",
            "Epoch 956/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1500.0413 - val_loss: 48.7916\n",
            "Epoch 957/1000\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1380.8911 - val_loss: 13.4075\n",
            "Epoch 958/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1308.6498 - val_loss: 1611.0405\n",
            "Epoch 959/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2162.6584 - val_loss: 21.9654\n",
            "Epoch 960/1000\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1623.4874 - val_loss: 20.5019\n",
            "Epoch 961/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1362.7457 - val_loss: 16.7726\n",
            "Epoch 962/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1300.1859 - val_loss: 19.4907\n",
            "Epoch 963/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1129.4415 - val_loss: 16.3360\n",
            "Epoch 964/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1116.2500 - val_loss: 58.3005\n",
            "Epoch 965/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1097.1660 - val_loss: 15.5300\n",
            "Epoch 966/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1127.7303 - val_loss: 33.5706\n",
            "Epoch 967/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1680.5997 - val_loss: 14.8450\n",
            "Epoch 968/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1159.6377 - val_loss: 13.9684\n",
            "Epoch 969/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 735.0116 - val_loss: 14.3711\n",
            "Epoch 970/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 600.7255 - val_loss: 14.9924\n",
            "Epoch 971/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 766.2123 - val_loss: 12.7904\n",
            "Epoch 972/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1756.0310 - val_loss: 12.4734\n",
            "Epoch 973/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 927.4480 - val_loss: 13.1616\n",
            "Epoch 974/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1764.7874 - val_loss: 11.8375\n",
            "Epoch 975/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 555.2579 - val_loss: 12.7295\n",
            "Epoch 976/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 339.0362 - val_loss: 11.9352\n",
            "Epoch 977/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1574.8582 - val_loss: 13.4916\n",
            "Epoch 978/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1057.2164 - val_loss: 11.9235\n",
            "Epoch 979/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1777.6516 - val_loss: 14.4140\n",
            "Epoch 980/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1391.8130 - val_loss: 95.5876\n",
            "Epoch 981/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 923.2087 - val_loss: 11.1017\n",
            "Epoch 982/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1642.7081 - val_loss: 12.8998\n",
            "Epoch 983/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 595.2061 - val_loss: 496.7149\n",
            "Epoch 984/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 2511.9021 - val_loss: 12.0198\n",
            "Epoch 985/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1687.5667 - val_loss: 21.2651\n",
            "Epoch 986/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1511.5232 - val_loss: 26.3656\n",
            "Epoch 987/1000\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1290.6969 - val_loss: 196.7384\n",
            "Epoch 988/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 977.7655 - val_loss: 123.5144\n",
            "Epoch 989/1000\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 1140.3441 - val_loss: 246.2132\n",
            "Epoch 990/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1452.7888 - val_loss: 352.1913\n",
            "Epoch 991/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 1641.7729 - val_loss: 15.3089\n",
            "Epoch 992/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 754.4931 - val_loss: 67.5953\n",
            "Epoch 993/1000\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 535.3536 - val_loss: 35.6105\n",
            "Epoch 994/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 370.0621 - val_loss: 14.6440\n",
            "Epoch 995/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 78.2788 - val_loss: 12.3475\n",
            "Epoch 996/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 28.0852 - val_loss: 12.5311\n",
            "Epoch 997/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 14.0139 - val_loss: 12.5530\n",
            "Epoch 998/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 10.5487 - val_loss: 11.6603\n",
            "Epoch 999/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 10.4549 - val_loss: 11.7286\n",
            "Epoch 1000/1000\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 9.3633 - val_loss: 11.2910\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = np.array(features).reshape(len(features), dim_modinfo)\n",
        "test_output = np.array(modelfour.predict(test_input, verbose=0))\n",
        "fourpredictienn = np.vstack(np.transpose(np.array((test_output[:,0],test_output[:,1],test_output[:,2],test_output[:,3],test_output[:,4],np.zeros(len(test_output)),test_output[:,5],test_output[:,6],test_output[:,7]))))"
      ],
      "metadata": {
        "id": "_pAk4Vpqjnbx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Predict the hidden state"
      ],
      "metadata": {
        "id": "l3kTVUZJjy6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "indexen = range(len(features))\n",
        "feathid = []\n",
        "#add the predicted fouriercomponents to the input of hiddenstate prediction\n",
        "for ii in range(len(features)):\n",
        "  feathid.append(np.concatenate([features[ii], fourpredictienn[ii]]))\n",
        "\n",
        "\n",
        "X_train_hid, X_test_hid, indexen_train_hid, indexen_test_hid = train_test_split(feathid, indexen, train_size=5000, test_size=177, random_state=333)\n",
        "training_y_hid = tussen[indexen_train_hid]\n",
        "y_test_hid = tussen[indexen_test_hid]\n",
        "\n",
        "\n",
        "X = np.array(X_train_hid).reshape(len(X_train_hid), dim_modinfo+relim[0]+imlim[0]) #dim = modinfo + number of fouriercomponents\n",
        "\n",
        "Y = np.array(training_y_hid).reshape(len(training_y_hid), dim_latent_space)\n",
        "#again its better to standardscale"
      ],
      "metadata": {
        "id": "cwFPmBoTj0hp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_input = keras.Input(shape=(dim_modinfo+relim[0]+imlim[0]))\n",
        "dense2 = tf.keras.layers.Dense(100,activation = 'relu')(params_input)\n",
        "dense3 = tf.keras.layers.Dense(20,activation = 'relu')(dense2)\n",
        "dense4 = tf.keras.layers.Dense(dim_latent_space)(dense3)\n",
        "modelhid = keras.Model(inputs=params_input,outputs=dense4)\n",
        "modelhid.compile(optimizer='adam', loss='mse')\n",
        "modelhid.summary()\n",
        "hist = modelhid.fit(X,Y,epochs=100,validation_split=0.2,batch_size=32)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_TTV6w9j-jp",
        "outputId": "ce2eb4d0-24c6-4a9e-c1dc-a7cfe529970b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_5 (InputLayer)        [(None, 112)]             0         \n",
            "                                                                 \n",
            " dense_26 (Dense)            (None, 100)               11300     \n",
            "                                                                 \n",
            " dense_27 (Dense)            (None, 20)                2020      \n",
            "                                                                 \n",
            " dense_28 (Dense)            (None, 5)                 105       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13,425\n",
            "Trainable params: 13,425\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/100\n",
            "125/125 [==============================] - 1s 3ms/step - loss: 24.5943 - val_loss: 0.1440\n",
            "Epoch 2/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 35.5065 - val_loss: 0.1010\n",
            "Epoch 3/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 169.3561 - val_loss: 0.0977\n",
            "Epoch 4/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 37.5513 - val_loss: 0.0288\n",
            "Epoch 5/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 14.0111 - val_loss: 0.0225\n",
            "Epoch 6/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 1.9872 - val_loss: 0.0181\n",
            "Epoch 7/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.6330 - val_loss: 0.0151\n",
            "Epoch 8/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.1128 - val_loss: 0.0146\n",
            "Epoch 9/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0110 - val_loss: 0.0123\n",
            "Epoch 10/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0100 - val_loss: 0.0109\n",
            "Epoch 11/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0091 - val_loss: 0.0100\n",
            "Epoch 12/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0085 - val_loss: 0.0100\n",
            "Epoch 13/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0079 - val_loss: 0.0088\n",
            "Epoch 14/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0075 - val_loss: 0.0086\n",
            "Epoch 15/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0071 - val_loss: 0.0085\n",
            "Epoch 16/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0068 - val_loss: 0.0079\n",
            "Epoch 17/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0063 - val_loss: 0.0076\n",
            "Epoch 18/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0060 - val_loss: 0.0074\n",
            "Epoch 19/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0058 - val_loss: 0.0068\n",
            "Epoch 20/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0057 - val_loss: 0.0071\n",
            "Epoch 21/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0056 - val_loss: 0.0064\n",
            "Epoch 22/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0052 - val_loss: 0.0063\n",
            "Epoch 23/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0051 - val_loss: 0.0061\n",
            "Epoch 24/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0050 - val_loss: 0.0063\n",
            "Epoch 25/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0063\n",
            "Epoch 26/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0048 - val_loss: 0.0061\n",
            "Epoch 27/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0049 - val_loss: 0.0068\n",
            "Epoch 28/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0049 - val_loss: 0.0060\n",
            "Epoch 29/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0053\n",
            "Epoch 30/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0045 - val_loss: 0.0057\n",
            "Epoch 31/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0046 - val_loss: 0.0054\n",
            "Epoch 32/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0050\n",
            "Epoch 33/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0055\n",
            "Epoch 34/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0043 - val_loss: 0.0056\n",
            "Epoch 35/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0043 - val_loss: 0.0053\n",
            "Epoch 36/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0049\n",
            "Epoch 37/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0058\n",
            "Epoch 38/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0049\n",
            "Epoch 39/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0044 - val_loss: 0.0054\n",
            "Epoch 40/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0045 - val_loss: 0.0054\n",
            "Epoch 41/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0050\n",
            "Epoch 42/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0054\n",
            "Epoch 43/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0042 - val_loss: 0.0050\n",
            "Epoch 44/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0044\n",
            "Epoch 45/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0125 - val_loss: 0.0051\n",
            "Epoch 46/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0046\n",
            "Epoch 47/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0046\n",
            "Epoch 48/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0040 - val_loss: 0.0048\n",
            "Epoch 49/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0045\n",
            "Epoch 50/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0044\n",
            "Epoch 51/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0043\n",
            "Epoch 52/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0043\n",
            "Epoch 53/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0037 - val_loss: 0.0046\n",
            "Epoch 54/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0037 - val_loss: 0.0043\n",
            "Epoch 55/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0036 - val_loss: 0.0050\n",
            "Epoch 56/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0049\n",
            "Epoch 57/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0042 - val_loss: 0.0043\n",
            "Epoch 58/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0041\n",
            "Epoch 59/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0043\n",
            "Epoch 60/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0036 - val_loss: 0.0044\n",
            "Epoch 61/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0040\n",
            "Epoch 62/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0043\n",
            "Epoch 63/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0040\n",
            "Epoch 64/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0040\n",
            "Epoch 65/100\n",
            "125/125 [==============================] - 1s 4ms/step - loss: 0.0035 - val_loss: 0.0041\n",
            "Epoch 66/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0036 - val_loss: 0.0041\n",
            "Epoch 67/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0048\n",
            "Epoch 68/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0033 - val_loss: 0.0041\n",
            "Epoch 69/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0034 - val_loss: 0.0040\n",
            "Epoch 70/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0043\n",
            "Epoch 71/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0035 - val_loss: 0.0044\n",
            "Epoch 72/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 73/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0033 - val_loss: 0.0046\n",
            "Epoch 74/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0043\n",
            "Epoch 75/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0044\n",
            "Epoch 76/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0047\n",
            "Epoch 77/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0042\n",
            "Epoch 78/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0034 - val_loss: 0.0049\n",
            "Epoch 79/100\n",
            "125/125 [==============================] - 0s 2ms/step - loss: 0.0039 - val_loss: 0.0044\n",
            "Epoch 80/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0047\n",
            "Epoch 81/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0043\n",
            "Epoch 82/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0039\n",
            "Epoch 83/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 84/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0033 - val_loss: 0.0047\n",
            "Epoch 85/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0043\n",
            "Epoch 86/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0036 - val_loss: 0.0040\n",
            "Epoch 87/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0033 - val_loss: 0.0045\n",
            "Epoch 88/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0042\n",
            "Epoch 89/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0036 - val_loss: 0.0048\n",
            "Epoch 90/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0034 - val_loss: 0.0041\n",
            "Epoch 91/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0041 - val_loss: 0.0057\n",
            "Epoch 92/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0038 - val_loss: 0.0053\n",
            "Epoch 93/100\n",
            "125/125 [==============================] - 0s 3ms/step - loss: 0.0039 - val_loss: 0.0041\n",
            "Epoch 94/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0035 - val_loss: 0.0037\n",
            "Epoch 95/100\n",
            "125/125 [==============================] - 1s 6ms/step - loss: 0.0034 - val_loss: 0.0045\n",
            "Epoch 96/100\n",
            "125/125 [==============================] - 1s 7ms/step - loss: 0.0035 - val_loss: 0.0046\n",
            "Epoch 97/100\n",
            "125/125 [==============================] - 1s 9ms/step - loss: 0.0034 - val_loss: 0.0054\n",
            "Epoch 98/100\n",
            "125/125 [==============================] - 1s 8ms/step - loss: 0.0040 - val_loss: 0.0041\n",
            "Epoch 99/100\n",
            "125/125 [==============================] - 1s 5ms/step - loss: 0.0036 - val_loss: 0.0050\n",
            "Epoch 100/100\n",
            "125/125 [==============================] - 0s 4ms/step - loss: 0.0039 - val_loss: 0.0042\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputhid = np.array(feathid).reshape(len(feathid), dim_modinfo+relim[0]+imlim[0]) #dim = modinfo + number of fouriercomponents\n",
        "hidpredictienn = np.array(modelhid.predict(inputhid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PaohPQVwZxN",
        "outputId": "451c9403-df84-4a52-96be-4b91825b08a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "230/230 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# From estimated parameters back to prediction"
      ],
      "metadata": {
        "id": "r3PTnuockA9J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fourpred = fourpredictienn\n",
        "hiddenpred = hidpredictienn"
      ],
      "metadata": {
        "id": "ZgVdY902kD88"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "allefourpredtussen = []\n",
        "for jj in range(len(topred)):\n",
        "  toetevoegen = np.zeros((99,2))\n",
        "  for ii in range(imlim[0],imlim[1]):\n",
        "    toetevoegen[ii][1] = 0\n",
        "  for ii in range(relim[0],relim[1]):\n",
        "    toetevoegen[ii][0] = 0\n",
        "  for ii in range(0,relim[0]):\n",
        "    toetevoegen[ii][0] = fourpred[jj,ii]\n",
        "  for ii in range(0,imlim[0]):\n",
        "    toetevoegen[ii][1] = fourpred[jj,ii+5]\n",
        "  allefourpredtussen.append(toetevoegen)\n",
        "\n",
        "allefourpred = allefourpredtussen.copy()\n",
        "for jj in range(len(topred)):\n",
        "  for ii in range(imlim[1],imlim[2]):\n",
        "    allefourpred[jj][ii][1] = -allefourpredtussen[jj][np.int((dim_targetdata+1)/2-abs((dim_targetdata-1)/2-ii))][1]\n",
        "  for ii in range(relim[1],relim[2]):\n",
        "    allefourpred[jj][ii][0] = allefourpredtussen[jj][np.int((dim_targetdata+1)/2-abs((dim_targetdata-1)/2-ii))][0]  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYdgp3Q3kKMm",
        "outputId": "60d2ba16-10b2-4ce7-f942-437e5d06977b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:17: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "allefourpredcompl = []\n",
        "for jj in range(len(allefourpred)):\n",
        "  tijdsvector = []\n",
        "  for ii in range(len(allefourpred[0])):\n",
        "      tijdsvector.append(complex(allefourpred[jj][ii][0],allefourpred[jj][ii][1]))\n",
        "  allefourpredcompl.append(tijdsvector)"
      ],
      "metadata": {
        "id": "MCj0B0eOkM76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inverse fouriertransform"
      ],
      "metadata": {
        "id": "XHqU60AaxAJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tijdslijntjenafour = np.real(sc.fft.ifft(allefourpredcompl))"
      ],
      "metadata": {
        "id": "0_kp-AdLkOiQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding the auto-encoder"
      ],
      "metadata": {
        "id": "xUO8lhM_kQ8G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Xen = np.array(hiddenpred).reshape(len(hiddenpred), dim_latent_space)\n",
        "layer_output = modelauto.get_layer('dense_1').output #last laag\n",
        "layer_input = modelauto.get_layer('dense').output #first dense layer\n",
        "automoduit =tf.keras.models.Model(inputs=layer_input,outputs=layer_output)\n",
        "correctiepred=automoduit.predict(Xen) # = hidden vectors!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBWwq6j3kTf5",
        "outputId": "d2bd7704-97f2-4d65-80ea-23c19d13aaca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "230/230 [==============================] - 0s 1ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "finalepred = correctiepred + tijdslijntjenafour"
      ],
      "metadata": {
        "id": "tLQe5qyvkVM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(finalepred[190],'.',label='Predicted timeline')\n",
        "plt.plot(targetdata[190],'.',label='Real timeline')\n",
        "plt.legend()\n",
        "plt.xlabel('Time')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "axuhxvOBxQ3Y",
        "outputId": "c436310c-7a03-4aba-f93b-e18d63f923d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Time')"
            ]
          },
          "metadata": {},
          "execution_count": 64
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(modinfo[:,0],finalepred[:,50],'.',label='Predicted value at 50th time')\n",
        "plt.plot(modinfo[:,0],targetdata[:,50],'.',alpha=0.5,label='Real value at 50th time')\n",
        "plt.legend()\n",
        "plt.xlabel('Depth')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "id": "EgApFpT2xSpi",
        "outputId": "84333f20-499a-4858-f4e9-d97826abd8e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Depth')"
            ]
          },
          "metadata": {},
          "execution_count": 65
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}
